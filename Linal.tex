\documentclass[a4paper, 14pt]{extarticle}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts, amsmath, amssymb}
\usepackage[none]{hyphenat}
\usepackage{fancyhdr} %create a custom header and footer
\usepackage[utf8]{inputenc}
\usepackage[english, main=ukrainian]{babel}
\usepackage{pgfplots}
\usepgfplotslibrary{fillbetween}
\usepackage{bm}
\usepackage{physics}
\usepackage[unicode]{hyperref}
\usepackage{scalerel,stackengine}
\usepackage{multicol}
\usepackage{tikz-cd}
\usetikzlibrary{fit,matrix}

\usepackage{caption}
\usepackage{float}
\usepackage{physics}
\usetikzlibrary{spy}

\fancyhead{}
\fancyfoot{}
\parindent 0ex
\def\huge{\displaystyle}
\def\defin#1{\textbf{Definition {#1}}}
\def\ex#1{\textbf{Example {#1}}}
\def\rm#1{\textbf{Remark {#1}}}
\def\prp#1{\textbf{Proposition {#1}}}
\def\lm#1{\textbf{Lemma {#1}}}
\def\th#1{\textbf{Theorem {#1}}}
\def\crl#1{\textbf{Corollary {#1}}}
\def\proof{\textbf{Proof.}\\}
\def\proofMI{\textbf{Proof MI.}\\}
\def\bigline{\vspace{5mm}\\}
\def\qed{$\blacksquare$}
\def\dim#1{\textrm{dim} {#1}}
\def\ker#1{\textrm{Ker} {#1}}
\def\contra{\textbf{! }}


\begin{document}
	\begin{titlepage}
		\begin{center}
		\hfill
		\vfill
		\line(1,0){400}\\
		\large{\textbf{Лінійна алгебра}}\\[1mm]
		{\textbf{Семестр 2}}\\[1mm]
		\line(1,0){400}\\
		\vfill
        	\end{center}
    	\end{titlepage}
\tableofcontents
\newpage
    	
	\section{Лінійні простори}
	\subsection{Основні означення лінійних просторів}
	\defin{1.1.1.} \textbf{Лінійним простором} називається множина $L$, на якій задані дві операції:\\
	1. $\forall x,y \in L: \exists! z \in L: z = x + y$ - операція додавання;\\
	2. $\forall x \in L, \forall \lambda \in \mathbb{R}: \exists! w \in L: w = \lambda x$ - операція множення на скаляр;\\
	та які задовільняють наступним аксіомам:\\
	1) $\forall x,y \in L: x + y = y + x$\\
	2) $\forall x,y,z \in L: (x + y) + z = x + (y + z)$\\
	3) $\exists 0 \in L: \forall x \in L: 0 + x = x$\\
	4) $\forall x \in L: \exists \tilde{x} \in L: x + \tilde{x} = 0$\\
	5) $\forall \alpha, \beta \in \mathbb{R}: \forall x \in L: (\alpha + \beta) x = \alpha x + \beta x$\\
	6) $\forall \alpha \in \mathbb{R}: \forall x,y \in L: \alpha (x+y) = \alpha x + \alpha y$\\
	7) $\forall \alpha, \beta \in \mathbb{R}: \forall x \in L: (\alpha \beta) x = \alpha (\beta x)$\\
	8) $\forall x \in L: 1 \cdot x = x$\\
	\bigline
	\rm{1.1.1.} Якщо $\alpha, \beta \in \mathbb{R}$, то лінійний простір називається  \textbf{виключно дійсним}. При $\mathbb{C}$ - \textbf{комплексним}. \\ (я далі лише буду вказувати множину $\mathbb{R}$, для $\mathbb{C}$ теж можна)\\
	\bigline
	 \ex{1.1.2.(1)} $L = \mathbb{R}^3$ - вектори в просторі - є лінійним простором.\\
	 \ex{1.1.2.(2)} $L = Mat(n \cross m)$ - матриці - є лінійним простором.\\
	 \ex{1.1.2.(3)} $L = \mathbb{R}[x]$ - многочлени з дійсними коефіцієнтами - є лінійним простором.\\
	\ex{1.1.2.(4)} $L = C(A)$ - неперервні функції на множині $A$ - є лінійним простором.\\
	\bigline
	\prp{1.1.3.} \textbf{Властивості лінійних просторів:}\\
	1) $\exists !0 \in L: \forall x \in L: x + 0 = x$\\
	2) $\forall x \in L: \exists! x: x + \tilde{x} = 0$\\
	3) $\underset{\in \mathbb{R}}{0} \cdot x = \underset{\in L}{0}$\\
	4) $\tilde{x} = (-1) \cdot x = -x$\\
	\proof
	1) \textbf{!}Припустимо, що $\exists \tilde{0} \in L: x + \tilde{0} = x$ - ще один нуль\\
	Тоді $\tilde{0} = 0 + \tilde{0} = 0$\\
	Суперечність\textbf{!} Отже, елемент - єдиний\\
	\\
	2) \textbf{!}Припустимо, що $\exists \tilde{\tilde{x}} \in L: x + \tilde{\tilde{x}} = 0$ - ще один обернений елемент\\
	Тоді $\tilde{\tilde{x}} = 0 + \tilde{\tilde{x}} = (\tilde{x} + x) + \tilde{\tilde{x}} = \tilde{x} + (x + \tilde{\tilde{x}}) = \tilde{x} + 0 = \tilde{x}$\\
	Суперечність\textbf{!} Отже, елемент - єдиний\\
	\\
	3) $0 \cdot x = (0 + 0)x = 0\cdot x + 0 \cdot x \Rightarrow 0 \cdot x = 0$\\
	У нас остання рівність каже, що до елементу $0 \cdot x$ додається щось, що дорівнює $0 \cdot x$. І ось це щось буде рівне $0$ \\
	\\
	4) $x + (-x) = 1 \cdot x + (-1) \cdot x = (1 + (-1))x = 0 \cdot x = 0$ \qed
	\\
	
	\subsection{Лінійні підпростори}
	\defin{1.2.1.} Підмножина $M$ лінійного простору $L$ називається \textbf{лінійним підпростором}, якщо:\\
	1) $\forall x, y \in M: x + y \in M$\\
	2) $\forall x \in M: \forall \lambda \in \mathbb{R}: \lambda x \in M$\\
	Тобто $M$ - замкнена відносно операцій на $L$\\
	\\
	\th{1.2.2.} Задані $L$ - лінійний простір та $M$ - лінійний підпростір\\
	Тоді $M$ - лінійний простір\\
	\proof
	На множині $M$ вже задані операції за означенням\\
	Перевіримо всі 8 аксіом: $\forall x,y,z \in M \Rightarrow x,y,z \in L: \forall \alpha, \beta \in \mathbb{R} \Rightarrow$\\
	1) $x+y=y+x$\\
	2) $x+(y+z)=(x+y)+z$\\
	3) $0\cdot x \in M \Rightarrow 0 \cdot x = 0 \in L \Rightarrow x + 0 = x$. Отже, $\exists 0 \in M$\\
	4) $\tilde{x} = (-1)\cdot x \in M \Rightarrow \tilde{x} = (-1)\cdot x \in L \Rightarrow x + \tilde{x} = 0 \Rightarrow \exists \tilde{x} \in M$\\
	5) $(\alpha + \beta)x = \alpha x + \beta x$\\
	6) $\alpha (x+y)= \alpha x + \alpha y$\\
	7) $(\alpha \beta) x = \alpha (\beta x)$\\
	8) $1 \cdot x = 1$\\
	Отже, $M$ - лінійний простір \qed \\
	\bigline
	\ex{1.2.3.} $M = \mathbb{R}_n[x]$ - многочлен степені $\leq n$ - лінійний підпростір $L = \mathbb{R}[x]$. А тому є й лінійним простором\\
	
	\subsection{Лінійна залежність/незалежність}
	\defin{1.3.1.} Задано $L$ - лінійний простір\\
	Система елементів $\{x_1, \dots, x_n\} \subset L$ називається:\\
	- \textbf{лінійно незалежною}, якщо з рівності $\alpha_1 x_1 + \dots + \alpha_n x_n = 0$, де $\alpha_1, \dots, \alpha_n \in \mathbb{R}$, випливає $\alpha_1 = \dots = \alpha_n = 0$\\
	- \textbf{лінійно залежною}, якщо $\exists \alpha_1, \dots, \alpha_n \in \mathbb{R}: |\alpha_1| + \dots + |\alpha_n| \neq 0: \alpha_1 x_1 + \dots + \alpha_n x_n = 0$\\
	\\
	\defin{1.3.2.} Вираз $\gamma_1 y_1 + \dots + \gamma_n y_n$, де $\gamma_1, \dots, \gamma_n \in \mathbb{R}$. називається \textbf{лінійною комбінацією}\\
	\\
	\ex{1.3.3.(0)} Будь-які вектори $\{\vec{a}, \vec{b} \}$ - л.н.з. в $\mathbb{R}^2 \iff $ не колінеарні\\
	\ex{1.3.3.(1)} Задано лінійний простір $L = \mathbb{R}^4$ і вектори:\\
	$\vec{x_1} =\begin{pmatrix} 1\\ 0\\ 2\\ 3 \end{pmatrix} $, $\vec{x_2} =\begin{pmatrix} 4\\ -1\\ 2\\ 1 \end{pmatrix} $, $\vec{x_3} =\begin{pmatrix} 2\\ 1\\ -1\\ 3 \end{pmatrix} $, $\vec{x_4} =\begin{pmatrix} 1\\ -2\\ 1\\ -5 \end{pmatrix}$\\
	Перевіримо, чи будуть вони л.н.з.\\
	$\alpha_1 \vec{x_1} + \alpha_2 \vec{x_2} + \alpha_3 \vec{x_3} + \alpha_4 \vec{x_4} = 0$\\
	$\alpha_1 \begin{pmatrix} 1\\ 0\\ 2\\ 3 \end{pmatrix} + \alpha_2 \begin{pmatrix} 4\\ -1\\ 2\\ 1 \end{pmatrix} + \alpha_3 \begin{pmatrix} 2\\ 1\\ -1\\ 3 \end{pmatrix} + \alpha_4 \begin{pmatrix} 1\\ -2\\ 1\\ -5 \end{pmatrix} = \begin{pmatrix} 0\\ 0\\ 0\\ 0 \end{pmatrix}$\\
	$\begin{cases}
	(1): \alpha_1 + 4\alpha_2 + 2\alpha_3 + \alpha_4 = 0\\
	(2): -\alpha_2 + \alpha_3 - 2\alpha_4 = 0\\
	(3): 2\alpha_1 + 2\alpha_2 - \alpha_3 + \alpha_4 = 0\\
	(4): 3\alpha_1 + \alpha_2 + 3\alpha_3 - 5\alpha_4 = 0
	\end{cases}$\\

	$\begin{cases}
	(1): \alpha_1 + 4\alpha_2 + 2\alpha_3 + \alpha_4 = 0\\
	(2): \alpha_2 - \alpha_3 + 2\alpha_4 = 0\\
	(3)-2(1): 6\alpha_2 + 5\alpha_3 + \alpha_4 = 0\\
	(4)-3(1): 11\alpha_2 + 3\alpha_3 + 8\alpha_4 = 0
	\end{cases}$\\
	
	$\begin{cases}
	(1): \alpha_1 + 4\alpha_2 + 2\alpha_3 + \alpha_4 = 0\\
	(2): \alpha_2 - \alpha_3 + 2\alpha_4 = 0\\
	-6(2)+(3): 11\alpha_3 - 11\alpha_4 = 0\\
	-11(4)+(4): 14\alpha_3 - 14\alpha_4 = 0
	\end{cases} 
	\Rightarrow
	\begin{cases}
	\alpha_1 = 9\alpha_4\\
	\alpha_2 = -3\alpha_4\\
	\alpha_3 = \alpha_4
	\end{cases} 
	$\\
	Звісно, є нульовий розв'язок, але такий розв'язок не буде єдиним. Можна взяти $(9,-3,1,1)$, щоб наша лінійна комбінація була нулевою\\
	Отже, $\{\vec{x_1},\vec{x_2},\vec{x_3},\vec{x_4}\}$ - л.з.
	\\ \\
	\textbf{Example 1.3.3.(2)} Перевіримо, чи буде система $\{\sin x, \cos x, \cos 2x\}$ - л.н.з.
	\bigline
	\textbf{Remark.} Тут не можна використовувати цю тотожність: \\ $\cos 2x = \cos ^2 x - \sin ^2 x$. \\ 
	Тому що - "квадрат": нема множення в лінійному просторі (лише на скаляр), $\cos^2 x$ або $\sin^2 x$ - це вже абсолютно інший елемент
	\bigline
	$\alpha_1 \sin x + \alpha_2 \cos x + \alpha_3 \cos 2x = 0(x)$, причому $\forall x \in \mathbb{R}$\\
	Тут типу $0(x) = 0$ $\forall x \in \mathbb{R}$\\
	Якщо ця рівність виконується для довільних $x$, то зокрема має виконуватись й для конкретних\\
	При $\huge x = 0: \alpha_2 + \alpha_3 = 0$\\
	При $\huge x = \frac{\pi}{2}: \alpha_1 - \alpha_3 = 0$\\
	При $\huge x = \frac{\pi}{4}: \frac{\sqrt{2}}{2} \alpha_1 + \frac{\sqrt{2}}{2} \alpha_2 = 0$\\
	Отже, виникає система:\\
	$\begin{cases}
	\alpha_2 + \alpha_3 = 0\\
	\alpha_1 - \alpha_3 = 0\\
	\alpha_1 + \alpha_2 = 0
	\end{cases}
	\Rightarrow
	\begin{cases}
	\alpha_2 =  -\alpha_3\\
	\alpha_1 = \alpha_3\\
	\end{cases}
	$\\
	Тут вже можуть виникати думки, що це - л.з. система, але...\\
	Візьмемо ще один $\huge x = \frac{\pi}{3}: \frac{\sqrt{3}}{2}\alpha_1 + \frac{1}{2}\alpha_2 + \frac{1}{2}\alpha_3 = 0$\\
	У це рівняння підставимо отримані $\alpha_1,\alpha_2$:\\
	$\sqrt{3}\alpha_3 - \alpha_3 + \alpha_3 = 0 \Rightarrow \alpha_3 = 0$\\
	А отже, $\alpha_1 = \alpha_2 = 0$\\
	Якщо для таких $x$ ми отримали нульові розв'язки, то для решта обраних буде така сама картина\\
	Остаточно: $\{\sin x, \cos x, \cos 2x\}$ - л.н.з.
	\bigline
	\prp{1.3.4.} \textbf{Властивості л.н.з. та л.з. систем:}\\
	1) Якщо система $\{x_1 \dots, x_n\}$ містить підсистему $\{x_{j_1} \dots, x_{j_k}\}$ - що є л.з., то вся система - л.з.\\
	2) Якщо система $\{x_1, \dots, x_n\}$ - л.н.з., то будь-яка підсистема - л.н.з.\\
	3) Якщо $\{x_1 \dots, x_n\}$ містить принаймні один нульовий елемент, то ця система - л.з.\\
	4) Система $\{x_1 \dots, x_n\}$ - л.з. $\iff$ будь-який елемент можна виразити як лінійну комбінацію від інших\\
		5) Задано систему $\{x_1, \dots, x_n\}$ і елемент $y$, що є лінійною комбінацією елементів системи\\
		$\{x_1, \dots, x_n\}$ - л.н.з. $\iff$ розклад елемента $y$ є єдиним\\
	\proof
	1) $\{x_{j_1} \dots, x_{j_k}\}$ - л.з., тобто $\exists \alpha_1, \dots, \alpha_k$ ненулеві: $\alpha_1 x_{j_1} + \dots + \alpha_k x_{j_k} = 0$\\
	Звідси випливає, що:\\
	$0x_1 + 0x_2 + \dots + 0x_{j_1-1} + \alpha_1 x_{j_1} + 0x_{j_1 + 1} + \dots + \alpha_k x_{j_k} + \dots + 0 x_n = 0$\\
	При цьому всі коефіцієнти в новій лінійної комбінації - ненулеві.\\
	Отже, $\{x_1 \dots, x_n\}$ - л.з.\\
	\\
	2) \textit{наслідок 1)} \\
	\\
	3) $\alpha_1 x_1 + \dots + \alpha_j \underset{=0}{x_j} + \alpha_n x_n = 0$\\
	Можна взяти $\alpha_1 = \dots = \alpha_n = 0$, але $\alpha_j = 1$. Тому буде л.з.\\
	\\
	4) В обидва боки доведення\\
	$\boxed{\Rightarrow}$ Дано: $\{x_1, \dots, x_n\}$ - л.з., тобто $\exists \beta_1, \dots, \beta_n$ не всі нулеві: \\$\beta_1 x_1 + \dots + \beta_n x_n = 0$\\
	Не всі нулеві, тобто $\exists \beta_j \neq 0$. Тоді\\
	$\beta_j x_j = -\beta_1 x_1 - \dots - \beta_{j-1} x_{j-1} - \beta_{j+1} x_{j+1} - \dots - \beta_n x_n$\\
	$\huge x_j = \frac{-\beta_1}{\beta_j}x_1 - \dots - \frac{-\beta_n}{\beta_j}x_n$\\
	А це й є розклад в лінійну комбінацію інших
	\bigline
	$\boxed{\Leftarrow}$ Дано: $\exists x_j: \exists \alpha_1, \dots, \alpha_{j-1}, \alpha_{j+1}, \dots, \alpha_n:$\\
	$x_j = \alpha_1 x_1 + \dots + \alpha_{j-1} x_{j-1} + \alpha_{j+1} x_{j+1} + \dots + \alpha_n x_n$\\
	$\Rightarrow \alpha_1 x_1 + \dots + \alpha_{j-1} x_{j-1} + (-1)x_j + \alpha_{j+1} x_{j+1} + \dots + \alpha_n x_n = 0$\\
	Коефіцієнти не всі нулеві. Отже, $\{x_1, \dots, x_n\}$ - л.з.\\
	\\
	5) В обидва боки доведення\\
	$\boxed{\Rightarrow}$ Дано: $\{x_1, \dots, x_n \}$ - л.н.з.\\
	\textbf{!}Припустимо, що розклад не є єдиним. Тобто існує ще одна лінійна комбінація для елемента $y$, тобто:\\
	$y = \beta_1 x_1 + \dots + \beta_n x_n$\\
	Тоді:\\
	$0 = y - y = (\alpha_1 - \beta_1)x_1 + \dots + (\alpha_n - \beta_n)x_n$\\
	Але з умови л.н.з випливає, що $\alpha_1 = \beta_1, \dots, \alpha_n = \beta_n$. Суперечність\textbf{!} \\ 
	Отже, в лінійну комбінацію елементу $y$ розкладається єдиним чином
	\bigline
	$\boxed{\Leftarrow}$ Дано: $\exists! \alpha_1, \dots, \alpha_n:$
	$y = \alpha_1 x_1 + \dots + \alpha_n x_n$\\
	Перевіримо систему $\{x_1, \dots, x_n\}$ на л.н.з.\\
	$\gamma_1 x_1 + \dots + \gamma_n x_n = 0$\\
	$y = y + 0 = (\alpha_1 + \gamma_1)x_1 + \dots + (\alpha_n + \gamma_n)x_n$\\
	Але за умовою розклад єдиний, тому $\alpha + \gamma_1 = \alpha_1, \dots, \alpha_n + \gamma_n = \alpha_n$\\
	$\Rightarrow \gamma_1 = \dots = \gamma_n = 0$\\
	Отже, л.н.з. \qed \\
	\\
	\textbf{Елементарні перетворення л.н.з. та л.з. систем}\\
	Задано систему $\{x_1, \dots, x_n\}$. Її можна трохи видозмінити:\\
	I. $P_{j \leftrightarrow k}: \{x_1, \dots, x_j, \dots, x_k, \dots, x_n\} \rightarrow \{x_1, \dots, x_k, \dots, x_j, \dots, x_n\}$ \\ - $j$-ий та $k$-ий елементи зміняться місцями\\
	\\
	II. $P_{j \to \lambda j}: \{x_1, \dots, x_j, \dots, x_n\} \rightarrow \{x_1, \dots, \lambda x_j, \dots, x_n\}$ \\ - до $j$-го елементу множимо скаляр $\lambda \neq 0$\\
	\\
	III. $P_{j \to j+k}: \{x_1, \dots, x_j, \dots, x_k, \dots, x_n\} \rightarrow \{x_1, \dots, x_j, \dots,  x_k + x_j, \dots, x_n\}$ \\ - до $j$-го елементу додаємо $k$-ий елемент
	\bigline
	\textbf{Proposition 1.3.5.} Перетворення I, II та III зберігають властивість лінійної залежності/незалежності\\
	\proof
	Доведемо спочатку випадок л.н.з.:\\
	Задано початкову систему $\{x_1, \dots, x_n\}$ - л.н.з.\\
	I. $P_{j \leftrightarrow k}\{x_1, \dots, x_j, \dots, x_k \dots, x_n\} = \{x_1, \dots, x_k, \dots, x_j \dots, x_n\}$\\
	$\alpha_1 x_1 + \dots + \alpha_j x_k + \dots + \alpha_k x_j + \dots + \alpha_n x_n = 0 \overset{\textrm{початкова - л.н.з.}}{\Rightarrow} \\ \alpha_1 = \dots = \alpha_n = 0$\\
	\\
	II. $P_{j \to \lambda j}\{x_1, \dots, x_j, \dots, x_n\} = \{x_1, \dots, \lambda x_j, \dots, x_n\}$\\
	$\alpha_1 x_1 + \dots + \alpha_j \lambda x_j + \dots + \alpha_n x_n = 0 \overset{\textrm{початкова - л.н.з.}}{\Rightarrow} \\ \alpha_1 = \dots = \alpha_j \lambda = \dots = \alpha_n = 0$. Але оскільки $\lambda \neq 0$, то $\alpha_j = 0$\\
	\\
	III. $P_{j \to j+k}\{x_1, \dots, x_j, \dots, x_k, \dots, x_n\} = \{x_1, \dots, x_j, \dots,  x_k + x_j, \dots, x_n\}$\\
	$\alpha_1 x_1 + \dots + \alpha_j x_j + \dots + \alpha_k(x_k + x_j) + \dots + \alpha_n x_n = 0 \Rightarrow \\ \alpha_1 x_1 + \dots + (\alpha_k + \alpha_j) x_j + \dots + \alpha_k x_k + \dots + \alpha_n x_n = 0 \overset{\textrm{початкова - л.н.з.}}{\Rightarrow} \\ \alpha_1 = \alpha_j + \alpha_k = \dots = \alpha_k = \dots = \alpha_n = 0$. Тоді $\alpha_j = 0$\\
	Отже, л.н.з. система після елементарного перетворення залишається л.н.з.
	\bigline
	Лишилось довести випадок л.з.:\\
	Задано початкову систему $\{x_1, \dots, x_n\}$ - л.з.\\
	\textbf{!}Припустимо, що л.з. система після будь-якого з трьох перетворень - \\ $P_{\textrm{будь-яке}} \{x_1, \dots, x_n\}$ - стане л.н.з. Тоді якщо зробити зворотнє перетворення, тобто:\\
	I. $\{x_1,\dots,x_k, \dots, x_j, \dots,x_n\}$ - змінити ще раз $j$-ий,$k$-ий елементи місцями;\\
	II. $\{x_1, \dots, \lambda x_j, \dots, x_n\}$ - помножити на $\dfrac{1}{\lambda}$ $j$-ий елемент;\\
	III. $\{x_1, \dots, x_j, \dots,  x_k + x_j, \dots, x_n\}$ - помножити на $(-1)$ елемент $x_j$, додати $j$-ий елемент до елементу $x_k+x_j$, а потім помножити на $(-1)$ елемент $(-x_j)$.\\
	- початкова система має стати л.н.з. А ми маємо л.з. за умовою. Тому суперечність\textbf{!} \\
	Отже, л.з. система після елементарного перетворення залишається л.з. \qed \\
	
	\subsection{Лінійні оболонки}
	\defin{1.4.1.} Задано $L$ - лінійний простір і система $\{x_1, \dots, x_n\} \subset L$\\
	\textbf{Лінійною оболонкою} цієї системи називають множину всіх лінійних комбінацій:
	\begin{align*}
	span\{x_1, \dots, x_n\} \overset{\textrm{або}}{=} \textrm{\textit{л.о.}}\{x_1, \dots, x_n\} = \{\alpha_1 x_1 + \dots + \alpha_n x_n | \forall \alpha_1, \dots, \alpha_n \in \mathbb{R}\}
	\end{align*}
	Якщо взяти множину $M \subset L$ (нескінченна кількість елементів), то тут множина задається таким чином
	\begin{align*}
	span M \overset{\textrm{або}}{=} \textrm{\textit{л.о.}} M = \{\alpha_1 x_1 + \dots + \alpha_j x_j | \forall j \geq 1: \forall x_j \in M: \forall \alpha_1, \dots, \alpha_n \in \mathbb{R}\}
	\end{align*}
	\\
	\prp{1.4.2.} Лінійна оболонка є лінійним підпростором $L$\\
	\proof
	Доведення за означенням. Нехай є $span\{x_1, \dots, x_n\}$:\\
	$\forall w_1, w_2 \in span\{x_1, \dots, x_n\}$, тобто:\\
	$w_1 = \alpha_1 x_1 + \dots + \alpha_n x_n$\\
	$w_2 = \beta_1 x_1 + \dots + \beta_n x_n$\\
	Тоді отримаємо, що: \\ $w_1 + w_2 = (\alpha_1 + \beta_1)x_1 + \dots + (\alpha_n + \beta_n)x_n \Rightarrow w_1 + x_2 \in span\{x_1, \dots, x_n\}$\\
	$\lambda w_1 = \lambda \alpha_1 x_1 + \dots + \lambda \alpha_n x_n \Rightarrow \lambda w_1 \in span\{x_1, \dots, x_n\}$\\
	Отже, $span\{x_1, \dots, x_n\}$ - підпростір $L$\\
	Випадок для $span M$ є аналогічним \qed 
	\bigline
	\crl{1.4.2.} Якщо $M$ - лінійний підпростір $L$, то $span M = M$\\
	\textit{Вказівка: показати, що якийсь елемент} $w \in span M \iff w \in M$
	\bigline
	\ex{1.4.3.} Задано $L = \mathbb{R}^3$ і система з трьох векторів:\\
	$\vec{e_1} =\begin{pmatrix} 1\\ 0\\ 0 \end{pmatrix}, \vec{e_2} =\begin{pmatrix} 0\\ 1\\ 0 \end{pmatrix}, \vec{e_3} =\begin{pmatrix} 0\\ 0\\ 1 \end{pmatrix}$\\
	Довести, що $span\{\vec{e_1}, \vec{e_2}, \vec{e_3}\} = \mathbb{R}^3$\\
	$span\{\vec{e_1}, \vec{e_2}, \vec{e_3}\} \overset{\textrm{def}}{=} \{\alpha_1 \vec{e_1} + \alpha_2 \vec{e_2} + \alpha_3 \vec{e_3} | \alpha_1, \alpha_2, \alpha_3 \in \mathbb{R}\} = \\ = \{(\alpha_1, \alpha_2, \alpha_3)^T | \alpha_1, \alpha_2, \alpha_3 \in \mathbb{R}\} = \mathbb{R}^3$\\
		
	\subsection{Підпорядковані та еквівалентні системи}
	\defin{1.5.1.} Система $\{y_1, \dots, y_n \}$ називається \textbf{підпорядкованою системою} під $\{x_1, \dots, x_m\}$, якщо:
	\begin{align*}
	\forall y_j: \exists \alpha^j_1, \dots, \alpha^j_m: y_j = \alpha^j_1 x_1 + \dots + \alpha^j_m x_m
	\end{align*}
	Позначення: $\{y_1, \dots, y_n \} \prec \{x_1, \dots, x_m \}$
	\bigline
	Для випадку з множиною $Y$, яка підпорядкована $X$, маємо:
	\begin{align*}
	\forall y \in Y: \exists x_1,\dots,x_n \in X: \exists \alpha_1, \dots, \alpha_n \in \mathbb{R}: y = \alpha_1 x_1 + \dots + \alpha_n x_n
	\end{align*}
	Позначення: $Y \prec X$\bigline
	\prp{1.5.2.} $\{y_1, \dots, y_n \} \prec \{x_1, \dots, x_m \} \iff \\ \iff span \{y_1, \dots, y_n\} \subset span \{x_1, \dots, x_m \}$\\
	\proof
	$\boxed{\Rightarrow}$ Дано: $\{y_1, \dots, y_n \} \prec \{x_1, \dots, x_m \}$, тобто за означенням:\\
	$\forall y_j: \exists \alpha^j_1, \dots, \alpha^j_m: y_j = \alpha^j_1 x_1 + \dots + \alpha^j_m x_m \Rightarrow y_j \in span\{x_1, \dots, x_m\}$\\
	$\forall w \in span\{y_1, \dots, y_n\}$, тобто $w = \beta_1 y_1 + \dots + \beta_n y_n \Rightarrow w \in span\{x_1, \dots, x_m\}$\\
	$\Rightarrow span \{y_1, \dots, y_n\} \subset span \{x_1, \dots, x_m \}$\\
	\\
	$\boxed{\Leftarrow}$ Дано: $span \{y_1, \dots, y_n\} \subset span \{x_1, \dots, x_m \}$\\
	$\Rightarrow \forall y_j \in span \{y_1, \dots, y_n \}$ (тому що $y_j = 0y_1 + \dots + 1 y_j + \dots + 0 y_n$) $\Rightarrow y_j \in span\{x_1,\dots,x_m\}$:\\
	$\exists \alpha^j_1, \dots, \alpha^j_m: y_j = \alpha^j_1 x_1 + \dots + \alpha^j_m x_m$
	$\Rightarrow \{y_1, \dots, y_n \} \prec \{x_1, \dots, x_m \}$ \qed
	\bigline
	\prp{1.5.3. Властивості підпорядкованих систем}\\
	Підпорядкована система є рефлексивною, антисиметричною і транзитивною. Тобто це є відношенням порядку\\
	\textit{Випливає з минулого твердження}
	\bigline
	\ex{1.5.4.} Нехай задано такі вектори з $\mathbb{R}^3$:\\
	$\begin{matrix}
	\vec{y_1} = (0,0,1) & \vec{x_1} = (1,0,0) \\
	\vec{y_2} = (0,1,0) & \vec{x_2} = (1,1,0) \\
	\vec{y_3} = (1,0,0) & \vec{x_3} = (1,1,1)
	\end{matrix}
	$\\
	Перевірити, чи можна вважати, що:\\
	$\{\vec{y_1}, \vec{y_2}, \vec{y_3}\} \prec \{\vec{x_1}, \vec{x_2}, \vec{x_3}\}$\\
	$\{\vec{x_1}, \vec{x_2}, \vec{x_3}\} \prec \{\vec{y_1}, \vec{y_2}, \vec{y_3}\}$\\
	Розв'яжемо задачу на основі доведеного твердження:\\
	$LY =span\{\vec{y_1},\vec{y_2},\vec{y_3}\} \overset{\textrm{\textbf{Ex. 1.4.3.}}}{=} \mathbb{R}^3$\\
	$LX = span\{\vec{x_1},\vec{x_2},\vec{x_3}\} = \{\beta_1 \vec{x_1} + \beta_2 \vec{x_2} +\beta_3 \vec{x_3} | \beta_1, \beta_2, \beta_3 \in \mathbb{R} \} = \\ = \{(\beta_1+\beta_2+\beta_3, \beta_2+\beta_3, \beta_3) | \beta_1, \beta_2, \beta_3 \in \mathbb{R} \} \overset{\textrm{?}}{=} \{(a,b,c) | a,b,c \in \mathbb{R} \} = \mathbb{R}^3$\\
	Пояснення: в рівності зі знаком питання ми вирішили ствердити, що так теж можна записати. Перевіримо, чи є довільними взагалі $a,b,c$\\
	$\begin{cases}
	a = \beta_1 + \beta_2 + \beta_3\\
	b = \beta_2 + \beta_3\\
	c = \beta_3
	\end{cases} \iff
	\begin{cases}
	\beta_1 = a -b\\
	\beta_2 = b - c\\
	\beta_3 = c
	\end{cases}
	$\\
	Отже, отримали, що $LX = LY$, або інакше $\begin{cases} LX \subset LY \\ LY \subset LX \end{cases}$\\
	Отже, $\{\vec{y_1}, \vec{y_2}, \vec{y_3}\} \prec \{\vec{x_1}, \vec{x_2}, \vec{x_3}\}$ та
	$\{\vec{x_1}, \vec{x_2}, \vec{x_3}\} \prec \{\vec{y_1}, \vec{y_2}, \vec{y_3}\}$
	\bigline
	\th{1.5.5.} Якщо $\underset{\textrm{є лінійно незалежною}}{\{y_1, \dots, y_n \}} \prec \{x_1, \dots, x_m \}$, то $n \leq m$\\
	\proofMI
	База індукції: для $n = 1$ - все очевидно. Дійсно, $y_1$ не може мати лінійну комбінацію із жодних елементів. Тому або принаймні $m=1$, або $m>1 \Rightarrow n \leq m$\\
	Крок індукції: нехай для підпорядкованої системи з $n-1$ елементами твердження є виконаним\\
	Перевіримо для $n$\\
	$\underset{\textrm{є лінійно незалежною}}{\{y_1, \dots, y_n \}} \prec \{x_1, \dots, x_m \} \iff
	\begin{cases}
	y_1 = \alpha^1_1 x_1 + \dots + \alpha^1_m x_m \hspace{0.5cm} (1)\\
	y_2 = \alpha^2_1 x_1 + \dots + \alpha^2_m x_m \hspace{0.5cm} (2)\\
	\dots\\
	y_n = \alpha^n_1 x_1 + \dots + \alpha^n_m x_m \hspace{0.5cm} (n)
	\end{cases}
	$ \\
	(не втрачаючи загальності, можемо вважати, що $\alpha^n_m \neq 0$)\\
	Цю систему замінимо таким чином:\\
	$\huge (1) = (1) - \frac{\alpha^1_m}{\alpha^n_m} (n)$\\
	$\huge (2) = (2) - \frac{\alpha^2_m}{\alpha^2_m} (n)$\\
	$\dots$\\
	$\huge (n-1) = (n-1) - \frac{\alpha^{n-1}_m}{\alpha^{n-1}_m} (n)$\\
	Тоді отримаємо, що:\\
	$
	\begin{cases}
	\huge y_1 - \frac{\alpha^1_m}{\alpha^n_m}y_n = \left(\alpha^1_1 - \alpha^n_1 \frac{\alpha^1_m}{\alpha^n_m}  \right) x_1 + \dots + \left(\alpha^1_{m-1} - \alpha^n_{m-1} \frac{\alpha^1_m}{\alpha^n_m}  \right) x_{m-1} + 0x_m\\
	\dots\\
	\huge y_{n-1} - \frac{\alpha^{n-1}_m}{\alpha^n_m}y_n = \left(\alpha^{n-1}_1 - \alpha^n_1 \frac{\alpha^{n-1}_m}{\alpha^n_m}  \right) x_1 + \dots + \left(\alpha^{n-1}_{m-1} - \alpha^n_{m-1} \frac{\alpha^{n-1}_m}{\alpha^n_m}  \right) x_{m-1} + 0x_m\\
	y_n = \alpha^n_1 x_1 + \dots + \alpha^n_m x_m
	\end{cases}
	$\\
	Розглянемо таку систему: $\huge \left\{y_1 - \frac{\alpha^1_m}{\alpha^n_m}y_n, \dots, y_{n-1} - \frac{\alpha^{n-1}_m}{\alpha^n_m}y_n\right\}$ та перевіримо її на л.н.з.\\
	$\huge \beta_1 \left(y_1 - \frac{\alpha^1_m}{\alpha^n_m}y_n \right) + \dots + \beta_{n-1} \left(y_{n-1} - \frac{\alpha^{n-1}_m}{\alpha^n_m}y_n \right) = 0$\\
	Якщо розкрити дужки та звести цей вираз у формі лінійної комбінації $\{y_1,\dots,y_{n-1}, y_n\}$, то отримаємо\\
	$\beta_1 y_1 + \dots + \beta_{n-1}y_{n-1} + \Gamma y_n = 0 \overset{\textrm{за умовою л.н.з.}}{\Rightarrow} \beta_1 = \dots = \beta_{n-1} = \Gamma = 0$\\
	$\Gamma$ - це якесь число, що було сконструюване із $\alpha, \beta$ - не принципово\\
	Отже, наша задана система - л.н.з. Більш того, ця система є підпорядкованою через отриману систему рівнянь:\\
	$\huge \left\{y_1 - \frac{\alpha^1_m}{\alpha^n_m}y_n, \dots, y_{n-1} - \frac{\alpha^{n-1}_m}{\alpha^n_m}y_n\right\} \prec \{x_1, \dots, x_{m-1} \}$\\
	Тоді за припущенням індукції, $n-1 \leq m-1 \Rightarrow n \leq m$\\
	MI доведено \qed
	\bigline
	\ex{1.5.6.} $\{\vec{i}\} \not\prec \{\vec{k}, \vec{j}\}$ - приклад того, що зворотня теорема не є вірною. Тут $\vec{i}, \vec{j}, \vec{k}$ - одиничні вектори простору
	\bigline
	\defin{1.5.7.} Системи $\{y_1, \dots, y_n \}$ та $\{x_1, \dots, x_m \}$ називаються \\ \textbf{еквівалентними}, якщо:
	\begin{align*}
	\{y_1, \dots, y_n \} \prec \{x_1, \dots, x_m \} \\
	\{x_1, \dots, x_m \} \prec \{y_1, \dots, y_n \}
	\end{align*}
	Позначення: $\{y_1, \dots, y_n \} \sim \{x_1, \dots, x_m \}$
	\bigline
	\prp{1.5.8.} $\{y_1, \dots, y_n \} \sim \{x_1, \dots, x_m \} \iff \\ \iff span \{y_1, \dots, y_n\} = span \{x_1, \dots, x_m \}$\\
	\textit{Випливає з} \textbf{Prp. 1.5.2.}
	\bigline
	\prp{1.5.9. Властивості еквівалентних систем}\\
	Еквівалентна система є рефлексивною, симетричною і транзитивною. Тобто це є відношенням еквівалентності\\
	\textit{Випливає з} \textbf{Prp. 1.5.3.}
	\bigline
	\th{1.5.10.} Якщо $\underset{\textrm{є лінійно незалежною}}{\{y_1, \dots, y_n \}} \sim \underset{\textrm{є лінійно незалежною}}{\{x_1, \dots, x_m \}} $, то $n = m$\\
	\textit{Випливає з} \textbf{Th. 1.5.5.}
	\bigline
	\ex{1.5.11.} $\{\vec{i},\vec{j},\vec{k}\} \not\sim \{\vec{i}-\vec{j}, \vec{j}-\vec{k}, \vec{k} \}$ - приклад того, що зворотня теорема не є вірною. Це знову одиничні вектори простору
	
	\subsection{База та ранг. Базиси та розмірності}
	\defin{1.6.1.} Підсистема $\{x_{j_1}, \dots, x_{j_k}\}$ системи $\{x_1, \dots, x_m\}$ називається \textbf{повною}, якщо
	\begin{align*}
	\forall x_t \in \{x_1, \dots, x_m\}: \exists \alpha^1_t, \dots, \alpha^k_t: x_t = \alpha^1_t x_{j_1} + \dots + \alpha^k_t x_{j_k}
	\end{align*}
	
	\defin{1.6.2.} Підсистема $\{x_{j_1}, \dots, x_{j_k}\}$ системи $\{x_1, \dots, x_m\}$ називається \textbf{max. лінійно незалежною}, якщо
	\begin{align*}
	\forall x_t \in \{x_1, \dots, x_m\}: \{x_{j_1}, \dots, x_{j_k}, x_t\} \textrm{ - лінійно залежна}
	\end{align*}
	\\
	\prp{1.6.3.} Підсистема є повною л.н.з. $\iff$ вона є max. л.н.з.\\
	\proof
	$\boxed{\Leftarrow}$ Дано: $\{x_{j_1}, \dots, x_{j_k}\}$ - max л.н.з.\\
	Звідси $\forall x_t \in \{x_1, \dots, x_m \}$ система $\{x_{j_1}, \dots, x_{j_k}, x_t\}$ - л.з. Тоді кожний елемент виражається як лінійна комбінація інших. Зокрема:\\
	$x_t = \beta_1 x_{j_1} + \dots + \beta_k x_{j_k}$\\
	Оскільки для довільних $x_t$, то звідси $\{x_{j_1},\dots, x_{j_k}\}$ - повна л.н.з.\\
	\\
	$\boxed{\Rightarrow}$ Дано: $\{x_{j_1}, \dots, x_{j_k}\}$ - повна л.н.з.\\
	Тоді $\forall x_t \in \{x_1, \dots, x_m\}: \exists \alpha^1_t, \dots, \alpha^k_t: x_t = \alpha^1_t x_{j_1} + \dots + \alpha^k_t x_{j_k} \Rightarrow \\
	\Rightarrow \alpha^1_t x_{j_1} + \dots + \alpha^k_t x_{j_k} + (-1)x_t = 0$, коефіцієнти не всі нулі\\
	Тому $\{x_{j_1}, \dots, x_{j_k}, x_t\}$ - л.з., що й доводить max. л.н.з. \qed
	\\
	\bigline
	\defin{1.6.4.} \textbf{Базою} системи $\{x_1, \dots, x_m\}$ називається max. л.н.з. або повна л.н.з. підсистема
	\bigline
	\ex{1.6.5.} Задано система $\{\vec{i}, \vec{j}, \vec{i}+2\vec{j}, \vec{i}-3\vec{j} \}$.\\
	Тут є такі бази: $\{\vec{i},\vec{j}\}$ або $\{\vec{i}+2\vec{j},\vec{i}-3\vec{j}\}$. Не всі я перелічив\\
	\\
	\th{1.6.6.(1)} Задано система $\{x_1, \dots, x_m\}$, для якої є база $\{x_{p_1}, \dots, x_{p_s}\}$. Тоді $\{x_1, \dots, x_m\} \sim \{x_{p_1}, \dots, x_{p_s}\}$\\
	\proof
	Зрозуміло, що $\{x_{p_1}, \dots, x_{p_s} \} \prec \{x_1, \dots, x_m \}$.\\
	Дійсно, $\{x_{p_1}, \dots, x_{p_s}\}$ - max. л.н.з., тоді $\{x_1,\dots,x_{p_1},\dots,x_{p_s},\dots,x_m\}$ - л.з. Тоді $\forall x_{p_j}, j=1,\dots,s$ виражається через лінійну комбінацію інших\\
	Перевіримо, що навпаки теж працює\\
	$\forall x_t \in \{x_1 \dots, x_m\}: \exists \alpha^1_t, \dots, \alpha^s_t: x_t = \alpha^1_t x_{p_1} + \dots + \alpha^s_t x_{p_s}$. Тоді за означенням, $\{x_1, \dots, x_m \} \prec \{x_{p_1}, \dots, x_{p_s} \}$\\
	Отже, $\{x_1, \dots, x_m \} \sim \{x_{p_1}, \dots, x_{p_s} \}$ \qed
	\\
	\\
	\th{1.6.6.(2)} Задана система $\{x_1, \dots, x_m\}$, для якої є дві бази: $\{x_{p_1}, \dots, x_{p_s}\}$ та $\{x_{t_1}, \dots, x_{t_l}\}$. \\ Тоді
	$\{x_{p_1}, \dots, x_{p_s}\} \sim \{x_{t_1}, \dots, x_{t_l}\}$\\
	\textit{Випливає з} \textbf{Th. 1.6.6.(1)} \textit{та властивості транзитивності}
	\\
	\\
	\defin{1.6.7.} \textbf{Рангом} системи $\{x_1, \dots, x_m\}$ називається кількість елементів в (будь-якій) її базі\\
	Позначення: $rank\{x_1, \dots, x_m\}$
	\bigline
	\ex{1.6.8.} Задано система $\{f_1, f_2, f_3, f_4\}$, для якої треба знайти ранг, де:\\
	$\begin{matrix}
	f_1(t) = t^2-3t+2 & f_2(t) = 2t^2+3t-5 \\
	f_3(t) = -t^2-t+2 & f_4(t) = -2t^2+5t-3
	\end{matrix}
	$\\
	Загальна побудова: почергово додаємо елемент, допоки не дійдемо до л.з. А потім досліджуємо всі комбінації (раптом там виявиться л.н.з.)\\
	$\{f_1\}$ - л.н.з.? Зрозуміло, що тут л.н.з.\\
	$\{f_1, f_2 \}$ - л.н.з.? \\ $\alpha f_1 + \beta f_2 = 0 \iff \huge f_1 = -\frac{\beta}{\alpha}f_2$. \\
	Але коефіцієнти не є пропорційними, тому $\{f_1, f_2\}$ - л.н.з.\\
	$\{f_1, f_2, f_3\}$ - л.н.з.? \\
	$\alpha_1 f_1 + \alpha_2 f_2 + \alpha_3 f_3 = 0 \iff 
	\begin{cases}
	\alpha_1 + 2\alpha_2 - \alpha_3 = 0 \\
	-3\alpha_1 + 3\alpha_2 - \alpha_3 = 0 \\
	2\alpha_1 - 5\alpha_2 + 2\alpha_3 = 0
	\end{cases} \iff
	\begin{cases}
	\alpha_1 + 2\alpha_2 - \alpha_3 = 0 \\
	9\alpha_2 - 4\alpha_3 = 0
	\end{cases}
	$\\
	Отже, можна отримати ненульовий розв'язок. Отже, $\{f_1, f_2, f_3\}$ - л.з.\\
	Решта систем із 3-х елементів (треба перевіряти) також є л.з.\\
	Тому $\{f_1, f_2\}$ - max. л.н.з. - база, а остаточно $rank\{f_1, f_2, f_3, f_4 \} = 2$
	\bigline
	\defin{1.6.9.} Задано $L$ - лінійний простір\\
	\textbf{Базисом} лінійного простору називають його базу
	\bigline
	\th{1.6.10.} Задано $\{x_1, \dots, x_n\}$ - система в $L$. Наступні властивості еквівалентні:\\
	$1) \{x_1, \dots, x_n\}$ - max л.н.з.\\
	$2) \{x_1, \dots, x_n\}$ - повна л.н.з.\\
	$3) \forall y \in L: \exists! \alpha_1, \dots, \alpha_n: y = \alpha_1 x_1 + \dots + \alpha_n x_n$\\
	\proof
	$\boxed{1) \Leftrightarrow 2)}$ вже було\\
	\\
	$\boxed{2) \Rightarrow 3)}$ Дано: $\{x_1, \dots, x_n\}$ - повна л.н.з.\\
	$\forall y \in L: \exists \alpha_1, \dots, \alpha_n: y = \alpha_1 x_1 + \dots + \alpha_n x_n$\\
	Із властивості систем л.н.з. елементів, отримаємо, що розклад є єдиним\\
	\\
	$\boxed{2) \Leftarrow 3)}$ Дано: $\forall y \in L: \exists! \alpha_1, \dots, \alpha_n: y = \alpha_1 x_1 + \dots + \alpha_n x_n$\\
	Тоді $\{x_1, \dots, x_n\}$ - повна і, за властивістю, л.н.з. \qed
	\\
	\\
	\defin{1.6.11.} \textbf{Розмірністю} лінійного простору $L$ називають кількість елементів в базисі\\
	Позначення: $\textrm{dim} L$
	\bigline
	\ex{1.6.12.(1)} Задано $L = \mathbb{R}_n[x]$\\
	Розглянемо систему $\{1, x, x^2, \dots, x^n\}$ та перевіримо, що це - базис. І дійсно,\\
	$\forall f(x) \in \mathbb{R}_n[x]: \exists! a_0, a_1, \dots, a_n \in \mathbb{R}: f(x) = a_0 + a_1 x + \dots + a_n x^n$\\
	$\Rightarrow \{1, x, \dots, x^n\}$ - базис $\mathbb{R}_n[x]$ \\ $\dim{\mathbb{R}_n[x]} = n+1$
	\bigline
	\rm{1.6.12.} Надалі працюємо з лінійними просторами, в яких скінченна кількість елементів в базисі
	\bigline
	\ex{1.6.12.(2)} Задано $L = \{\vec{a} \in \mathbb{R}^4: a_1 - a_2 + a_3 - 5a_4 = 0\}$. Знайдемо базис цього простору\\
	$a_1 - a_2 + a_3 - 5a_4 = 0 \Rightarrow a_1 = a_2 - a_3 + 5a_4$\\
	$\forall \vec{a} \in L: \vec{a} = \begin{pmatrix} a_1 \\ a_2 \\ a_3 \\ a_4 \end{pmatrix} = \begin{pmatrix} a_2 - a_3 + 5a_4 \\ a_2 \\ a_3 \\ a_4 \end{pmatrix} = a_2 \begin{pmatrix} 1 \\ 1 \\ 0 \\ 0\end{pmatrix} + a_3 \begin{pmatrix} -1 \\ 0 \\ 1 \\ 0\end{pmatrix} + a_4 \begin{pmatrix} 5 \\ 0 \\ 0 \\ 1 \end{pmatrix}$\\
	Тому $\left\{\vec{x_1} = \begin{pmatrix} 1 \\ 1 \\ 0 \\ 0\end{pmatrix}, \vec{x_2} = \begin{pmatrix} -1 \\ 0 \\ 1 \\ 0\end{pmatrix}, \vec{x_3} = \begin{pmatrix} 5 \\ 0 \\ 0 \\ 1\end{pmatrix} \right\}$ - базис, $\dim{L} = 3$
	\bigline
	Можна знайти також інший базис:\\
	$a_3 = -a_1 + a_2 + 5a_4$\\
	$\forall \vec{a} \in L: \vec{a} = \begin{pmatrix} a_1 \\ a_2 \\ a_3 \\ a_4 \end{pmatrix} = \begin{pmatrix} a_1 \\ a_2 \\ -a_1 + a_2 + 5a_4 \\ a_4 \end{pmatrix} = a_1 \begin{pmatrix} 1 \\ 0 \\ -1 \\ 0 \end{pmatrix} + a_2 \begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \end{pmatrix} + a_4 \begin{pmatrix} 0 \\ 0 \\ 5 \\ 1 \end{pmatrix}$\\
	Тому $\left\{\vec{x_1} = \begin{pmatrix} 1 \\ 0 \\ -1 \\ 0\end{pmatrix}, \vec{x_2} = \begin{pmatrix} 0 \\ 1 \\ 1 \\ 0\end{pmatrix}, \vec{x_4} = \begin{pmatrix} 0 \\ 0 \\ 5 \\ 1\end{pmatrix} \right\}$ - базис, $\dim{L} = 3$
	\bigline
	
	\subsection{Сума, перетин, пряма сума лінійних просторів}
	\defin{1.7.1.} Задано $L$ - лінійний простір та $M_1, M_2$ - лінійні підпростори\\
	- \textbf{Перетином} лінійних підпросторів називається множина
	\begin{align*}
	M_1 \cap M_2 = \{x \in L | x \in M_1, x \in M_2 \}
	\end{align*}
	- \textbf{Сумою} лінійних підпросторів називається множина
	\begin{align*}
	M_1 + M_2 = \{z \in L: z = x + y | x \in M_1, y \in M_2\}
	\end{align*}
	\\
	\lm{1.7.2.} $M_1 + M_2 = span\{M_1, M_2\}$\\
	\proof
	$\{z \in L: z = x+y: x \in M_1, y \in M_2\} \subset span\{M_1, M_2\}$ - випливає з означення л.о.\\
	Перевіримо, що $span\{M_1, M_2\} \subset \{z \in L: z = x+y: x \in M_1, y \in M_2\}$\\
	Справді:\\
	$\forall w \in span\{M_1, M_2\}: w = \alpha_1 x_1 + \dots + \alpha_n x_n + \beta_1 y_1 + \dots + \beta_m y_m \\ x_1, \dots, x_m \in M_1; y_1, \dots, y_m \in M_2 \\ \alpha_1, \dots, \alpha_n, \beta_1, \dots, \beta_m \in \mathbb{R}$\\
	$w = \underset{= x \in M_1}{(\alpha_1 x_1 + \dots + \alpha_n x_n )}+ \underset{= y \in M_2}{(\beta_1 y_1 + \dots + \beta_m y_m)} \Rightarrow \\ w = x + y \in \{z \in L: z = x+y: x \in M_1, y \in M_2\}$\\
	Отже, $span\{M_1, M_2\} = \{z \in L: z = x+y: x \in M_1, y \in M_2\} = M_1 + M_2$ \qed
	\bigline
	\th{1.7.3.} $\begin{gathered} 1) M_1 \cap M_2 \\ 2) M_1 + M_2 \end{gathered}$ - лінійні підпростори $L$\\
	\proof
	1) $M_1 \cap M_2$ - лінійний підпростір?\\
	$\forall t_1, t_2 \in M_1 \cap M_2: \forall \alpha_1, \alpha_2 \in \mathbb{R}: \begin{cases} t_1, t_2 \in M_1 \\ t_1, t_2 \in M_2 \end{cases} \Rightarrow \begin{cases} \alpha_1 t_1 + \alpha_2 t_2 \in M_1 \\ \alpha_1 t_1 + \alpha_2 t_2 \in M_2 \end{cases} \Rightarrow \alpha_1 t_1 + \alpha_2 t_2 \in M_1 \cap M_2$ - лінійний підпростір
	\\
	\\
	2) $M_1 + M_2$ - лінійний підпростір?\\
	$\forall z_1, z_2 \in M_1 + M_2: \forall \alpha_1, \alpha_2 \in \mathbb{R}: \begin{cases} z_1 = x_1 + y_1 \\ z_2 = x_2 + y_2 \end{cases}x_1,x_2 \in M_1; y_1, y_2 \in M_2$\\
	$\Rightarrow \alpha_1 z_1 + \alpha_2 z_2 = \underset{\in M_1}{(\alpha_1 x_1 + \alpha_2 x_2)} + \underset{\in M_2}{(\alpha_1 y_1 + \alpha_2 y_2)} \in M_1 + M_2$ - лінійний підпростір \qed
	\bigline
	\ex{1.7.4.} $L=\mathbb{R}^2$, $M_1 = OX, M_2 = OY$\\
	$M_1 \cap M_2 = (0,0)$\\
	$\vec{z} \in M_1 + M_2: \vec{z} = \vec{x} + \vec{y} = \alpha \vec{i} + \beta \vec{j}$.\\
	$M_1 + M_2 = \mathbb{R}^2 = XOY$
	\bigline
	\rm{1.7.4.} $M_1 \cup M_2 \neq XOY$. Ця множина описує вектори, які мають принаймні одну нульову координату. Водночас $M_1 + M_2 = XOY$ - абсолютно довільний вектор площини
	\\
	\\
	Проте не завжди прозоро знаходиться перетин підпросторів. Для цього є зв'язок між розмірностями, але перед цим наведу лему\\
	\\
	\lm{1.7.5.} Задано $M$ - підпростір лінійного простору $L$\\
	Тоді $\dim M \leq \dim L$\\
	\proof
	Виділимо базис $\{f_1,\dots,f_k\} \subset L$ в $M$, тоді $\dim M = k$\\
	Звідси в $L$ система $\{f_1,\dots,f_k\}$ є л.н.з. Тоді ми можемо доповнити цю систему елементами $g_1,\dots,g_n \in L$, щоб утворити базис $\{f_1,\dots,f_k,g_1,\dots,g_n\}$. А отже, $\dim L = k+n = \dim M + n \Rightarrow \dim M \leq \dim L$ \qed
	\bigline
	\th{1.7.6.} $\dim{M_1} + \dim{M_2} = \dim(M_1 + M_2) + \dim(M_1 \cap M_2)$\\
	\proof
	Нехай базис $M_1 \cap M_2$ - $\{h_1, \dots, h_k\}$\\
	Оскільки $M_1 \cap M_2$ - підпростір $M_1$, то $\dim (M_1 \cap M_2) \leq \dim M_1$. Тоді базисом в $M_1$ буде система $\{h_1, \dots, h_k, g_1, \dots, g_m\}$\\
	Так само для $M_2$ отримаємо базис $\{h_1, \dots, h_k, f_1, \dots, f_n\}$\\
	Покажемо, що $\{h_1, \dots, h_k, f_1, \dots, f_n, g_1, \dots, g_m\}$ - базис $M_1 + M_2$\\
	\\
	I. Перевіримо на л.н.з.\\
	$\alpha_1 h_1 + \dots + \alpha_k h_k + \beta_1 f_2 + \dots + \beta_n f_n + \gamma_1 g_1 + \dots + \gamma_m g_m = 0$\\
	$\Rightarrow \underset{\in M_2}{(\alpha_1 h_1 + \dots + \alpha_k h_k + \beta_1 f_2 + \dots + \beta_n f_n)} = \underset{\in M_1}{(-\gamma_1 g_1 - \dots - \gamma_m g_m)} (*)$\\
	Вони обидва тоді належать $M_1 \cap M_2$. Тому\\
	$(-\gamma_1 g_1 - \dots - \gamma_m g_m) = \tau_1 h_1 + \dots + \tau_k h_k$ - це розклад за базисом $M_1 \cap M_2$\\
	$\Rightarrow \tau_1 h_1 + \dots + \tau_k h_k +\gamma_1 g_1 + \dots + \gamma_m g_m = 0$\\
	$\{h_1, \dots, h_k, g_1, \dots, g_m\}$ - базис, тому\\
	$\tau_1 = \dots = \tau_k = \gamma_1 = \dots = \gamma_m = 0$\\
	Отже, рівнняння $(*)$ матиме вигляд:\\
	$\alpha_1 h_1 + \dots + \alpha_k h_k + \beta_1 f_2 + \dots + \beta_n f_n = 0$\\
	$\{h_1, \dots, h_k, f_1, \dots, f_k\}$ - базис, тому\\
	$\alpha_1 = \dots = \alpha_k = \beta_1 = \dots = \beta_n = 0$\\
	Всі коефіцієнти в нас нульові, тоді $\{h_1, \dots, h_k, f_1, \dots, f_n, g_1, \dots, g_m\}$ - л.н.з.
	\bigline
	II. Перевіримо на повноту\\
	$\forall z \in M_1 + M_2: z = x + y, \\x = x_1 h_1 + \dots + x_k h_k + \tilde{x_1}g_1 + \dots + \tilde{x_m}g_m \in M_1 \\ y = y_1 h_1 + \dots + y_k h_k + \tilde{y_1}f_1 + \dots + \tilde{y_n}f_n \in M_2$\\
	$\Rightarrow z = (x_1 + y_1)h_1 + \dots + (x_k + y_k)h_k + \tilde{x_1}g_1 + \dots + \tilde{x_m}g_m + \tilde{y_1}f_1 + \dots + \tilde{y_n}f_n$\\
	Тобто система є повною\\
	\\
	Остаточно $\{h_1, \dots, h_k, f_1, \dots, f_n, g_1, \dots, g_m\}$ - базис $M_1 + M_2$\\
	Залишилось показати рівність розмірностей:\\
	$\dim{(M_1+M_2)} = k + m + n$, \hspace{1cm} $\dim{(M_1 \cap M_2)} = k$\\
	$\dim{M_1} = k + m$, \hspace{1cm}  $\dim{M_2} = k + n$\\
	$\Rightarrow \dim{M_1} + \dim{M_2} = \dim{(M_1+M_2)} + \dim{(M_1 \cap M_2)}$ \qed
	\bigline
	Перед прикладом наведу ще дві корисні леми, якими будемо часто користуватись\\
	\\
	\lm{1.7.7.(1)} Задано $L$ - лінійний простір та $M$ - такий лінійний підпростір, що $M \subset L$ та $\dim M = \dim L$\\
	Тоді $L=M$\\
	\proof
	Нехай $\{f_1,\dots,f_n\}$ - базис в $M$\\
	Тоді $\{f_1,\dots,f_n\}$ - л.н.з. в $L$, але оскільки $\dim M = \dim L$, то $\{f_1,\dots,f_n\}$ - базис в $L$\\
	А тому $\forall y \in L: y = \alpha_1 x_1 + \dots + \alpha_n x_n \Rightarrow y \in M$\\
	Тобто маємо, що $L \subset M$. За умовою $M \subset L$\\
	Отже, $L=M$ \qed
	\bigline
	\lm{1.7.7.(2)} Задано $L$ - лінійний простір, $L = span\{x_1,\dots,x_n\}$\\
	Тоді якщо $\{x_1,\dots,x_n\}$ - база, то вона є базисом $L$\\
	Ба більше, $rank\{x_1,\dots,x_n\} = \dim L$\\
	\proof
	Маємо, що $\{x_1,\dots,x_n\} \sim span\{x_1,\dots,x_n\} = L$\\
	Тому $\dim L = rank\{x_1,\dots,x_n\}$\\
	Також $\{x_1,\dots,x_n\} \subset L$, тоді $\{x_1,\dots,x_n\}$ - max. л.н.з. в $L \Rightarrow$ базис $L$ \qed
	\bigline
	\ex{1.7.8.} Нехай задані такі простори: \\ 
	$L_1 = span\left\{ \vec{x_1} = \begin{pmatrix} 3 \\ 2 \\ -1 \end{pmatrix}, \vec{x_2} = \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix}, \vec{x_3} = \begin{pmatrix} 2 \\ 1 \\ -1 \end{pmatrix}	 \right\}$\\
	$L_2 = span\left\{ \vec{y_1} = \begin{pmatrix} 1 \\ 3 \\ -2 \end{pmatrix}, \vec{y_2} = \begin{pmatrix} 2 \\ 4 \\ -2 \end{pmatrix}, \vec{y_3} = \begin{pmatrix} 3 \\ 7 \\ -4 \end{pmatrix}	 \right\}$\\
	Перед знаходженням треба замодифікувати лінійні оболонки\\
	Якщо обережно перевірити, то $\{\vec{x_1}, \vec{x_2}, \vec{x_3}\}$ - л.з., але водночас $\{\vec{x_1},\vec{x_2}\}$ - л.н.з.\\
	В чому проблема? Оскільки $\{\vec{x_1}, \vec{x_2}, \vec{x_3} \}$ - л.з., то кожний елемент є лінійною комбінацією інших. Зокрема\\
	$\vec{x_3} = \vec{x_1} - \vec{x_2}$\\
	Тоді $L_1 = span\{\vec{x_1}, \vec{x_2}, \vec{x_3}\} = \{\alpha_1 \vec{x_1} + \alpha_2 \vec{x_2} + \alpha_3 \vec{x_3} | \alpha_1, \alpha_2, \alpha_3 \in \mathbb{R} \} = \\ = \{(\alpha_1 + \alpha_3) \vec{x_1} + (\alpha_2 - \alpha_3) \vec{x_2} | \alpha_1, \alpha_2, \alpha_3 \in \mathbb{R} \} = \{\beta_1 \vec{x_1} + \beta_2 \vec{x_2} | \beta_1, \beta_2 \in \mathbb{R} \} = span\{\vec{x_1}, \vec{x_2}\}$ \\
	З цього можемо зробити висновок, що ми можемо закреслювати елементи лінійної оболонки, допоки не виникне л.н.з. система\\
	Також $\{\vec{y_1},\vec{y_2},\vec{y_3}\}$ - л.з., але $\{\vec{y_1},\vec{y_2}\}$ - л.н.з. Тому в лінійній оболонці залишається лише їх\\
	Отже: \\
	$L_1 = span\left\{ \vec{x_1}, \vec{x_2} \right\}$\\
	$L_2 = span\left\{ \vec{y_1}, \vec{y_2} \right\}$
	\bigline
	$L_1 + L_2 = span\{L_1, L_2\} = span\{\vec{x_1}, \vec{x_2}, \vec{y_1}, \vec{y_2}\}$\\
	Тут знову треба перевірити. Проте оскільки наші вектори з простору $\mathbb{R}^3$, то max. л.н.з. система містить не більше 3 елементів.\\
	Можна переконатись самостійно, що $\{\vec{x_1}, \vec{x_2}, \vec{y_1}\}$ - л.н.з.\\
	Отже, $L_1 + L_2 = span\{\vec{x_1}, \vec{x_2}, \vec{y_1} \}$\\
	Оскільки $\dim (L_1 + L_2) = 3$ та $L_1 + L_2 \subset \mathbb{R}^3$, то $L_1+L_2= \mathbb{R}^3$ за \textbf{Lm. 1.7.7.(1)}
	\bigline
	Скористаємось зв'язком між розмірностями:\\
	$\underset{=2}{\dim L_1} + \underset{=2}{\dim L_2} = \underset{=3}{\dim (L_1+L_2)} + \dim(L_1 \cap L_2)$\\
	$\Rightarrow \dim (L_1 \cap L_2) = 1$\\
	Тоді $L_1 \cap L_2 = span\{\vec{z}\}$\\
	Якщо $\vec{z} \in L_1$, то $\vec{z} = \alpha_1 \vec{x_1} + \alpha_2 \vec{x_2}$\\
	Якщо $\vec{z} \in L_2$, то $\vec{z} = \beta_1 \vec{y_1} + \beta_2 \vec{y_2}$\\
	З іншого боку, коли $\vec{z} \in L_1 \cap L_2$, то $\alpha_1 \vec{x_1} + \alpha_2 \vec{x_2} = \beta_1 \vec{y_1} + \beta_2 \vec{y_2}$\\
	$\alpha_1 \begin{pmatrix} 3 \\ 2 \\ -1 \end{pmatrix} + \alpha_2 \begin{pmatrix} 1 \\ 1 \\ 0 \end{pmatrix} = \beta_1 \begin{pmatrix} 1 \\ 3 \\ -2 \end{pmatrix} + \beta_2 \begin{pmatrix} 2 \\ 4 \\ -2 \end{pmatrix}$\\
	$\Rightarrow \begin{cases}
	3 \alpha_1 + \alpha_2 = \beta_1 + 2 \beta_2 \\
	2 \alpha_1 + \alpha_2 = 3 \beta_1 + 4 \beta_2 \\
	- \alpha_1 = -2 \beta_1 - 2 \beta_2
	\end{cases}$\\
	Розв'язуючи систему, ми отримаємо:\\
	$\alpha_1 = 2\beta_1 + 2\beta_2$\\
	$\alpha_2 = -\beta_1$\\
	$\alpha_2 = -5\beta_1 - 4\beta_2$\\
	$\Rightarrow \beta_1 = -\beta_2$\\
	Тоді $\vec{z} =\beta_1 \vec{y_1} - \beta_1 \vec{y_2} = \beta_1 \begin{pmatrix} -1 \\ -1 \\ 0 \end{pmatrix}$\\
	Остаточно $L_1 \cap L_2 = span\left\{ \begin{pmatrix} -1 \\ -1 \\ 0 \end{pmatrix} \right\}$
	\bigline
	
	
	\defin{1.7.9.} Задано $L$ - лінійний простір та $M_1, M_2$ - лінійні підпростори\\
	\textbf{Прямою сумою} називають множину
	\begin{align*}
	M_1 \dot{+} M_2 = \{z \in L | \exists! x \in M_1, \exists! y \in M_2: z = x+y\}
	\end{align*}
	\lm{1.7.10. Критерій прямої суми} \\
	Сума $M_1 + M_2$ є прямою $\iff M_1 \cap M_2 = \{0\}$\\
	\proof
	$\boxed{\Rightarrow}$ Дано: $M_1 \dot{+} M_2$, тобто пряма сума\\
	Нехай $z \in M_1 \cap M_2 \Rightarrow \begin{cases} z \in M_1 \\ z \in M_2 \end{cases} \Rightarrow \begin{cases} z = \underset{M_1}{0} + \underset{M_2}{z} \\ z = \underset{M_1}{z} + \underset{M_2}{0} \end{cases}$\\
	За умовою розклад $z$ - єдиний, тому $z=0+z=z+0 \Rightarrow z = 0$\\
	\\
	$\boxed{\Leftarrow}$ Дано: $M_1 \cap M_2 = \{0\}$\\
	\textbf{!}Припустимо, що $z$ має не один розклад, тобто $\begin{cases} z = z_1 + y_1 \\ z = z_2 + y_2 \end{cases}$,\\ $x_1,x_2 \in M_1$, $y_1,y_2 \in M_2$\\
	$\Rightarrow 0 = z-z=(x_1-x_2)+(y_1-y_2) \Rightarrow \underset{\in M_1}{x_2-x_1}=\underset{\in M_2}{y_1-y_2}$\\
	Тому $x_1-x_2 \in M_1, M_2$, та $y_1-y_2 \in M_2, M_1 \Rightarrow x_2-x_1 \in M_1 \cap M_2$, $y_2 - y_1 \in M_1 \cap M_2$\\
	Отже, $x_1 = x_2, y_1 = y_2$. Суперечність\textbf{!} \\
	Таким чином, $\forall z \in M_1 + M_2: \exists! x \in M_1, \exists! t \in M_2: z = x+y$, тобто пряма сума \qed
	\bigline
	\crl{1.7.10.} $\dim{(M_1 \dot{+} M_2)} = \dim{M_1} + \dim{M_2}$
	\bigline
	\ex{1.7.11.} Перевірити, чи буде $\mathbb{R}^4 = L_1 \dot{+} L_2$, якщо нам задані:\\
	$L_1 = \{\vec{x} \in \mathbb{R}^4: 3x_1 - x_2 + x_3 - 5x_4 = 0\}$\\
	$L_2 = \{\vec{x} \in \mathbb{R}^4: x_1 = x_2 = x_3 = x_4\}$\\
	Якщо $\vec{x} \in L_1$, то $\vec{x} = \begin{pmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{pmatrix} = \begin{pmatrix}
	x_1 \\ 3x_1+x_3-5x_4 \\ x_3 \\ x_4
	\end{pmatrix} = \\ = x_1 \begin{pmatrix}
	1 \\ 3 \\ 0 \\ 0
	\end{pmatrix} + x_3\begin{pmatrix}
	0 \\ 1 \\ 1 \\ 0
	\end{pmatrix} +  x_4\begin{pmatrix}
	0 \\ -5 \\ 0 \\ 1
	\end{pmatrix}$\\
	Отримаємо базис з трьох векторів, тобто $\dim L_1 = 3$\\
	Якщо $\vec{x} \in L_2$, то $\vec{x} = \begin{pmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{pmatrix} = \begin{pmatrix} x_1 \\ x_1 \\ x_1 \\ x_1 \end{pmatrix} = x_1 \begin{pmatrix} 1 \\ 1 \\ 1 \\ 1 \end{pmatrix}$\\
	Отримаємо базис з одного вектора, тобто $\dim L_2 = 1$\\
	Тоді $L_1 + L_2 = span\{L_1,L_2\}$ - якщо обережно перевірити, то отримані 4 вектори будуть л.н.з., отже, $\dim (L_1 + L_2) = 4$\\
	За формулою про зв'язок між розмірностями, маємо, що \\ $\dim{(L_1 \cap L_2)} = 0$\\
	Таким чином, $L_1 + L_2$ є прямою сумою\\
	І нарешті, за \textbf{Lm. 1.7.7.}, $\dim{(L_1 \dot{+} L_2)} = \dim {\mathbb{R}^4}$ та $L_1 \dot{+} L_2 \subset \mathbb{R}^4 \Rightarrow L_1 \dot{+} L_2 = \mathbb{R}^4$\\
	\newpage	
	
	
	\section{Дії з лінійними просторами}
	\subsection{Лінійні оператори}
	\defin{2.1.1.} Задані $L,M$ - лінійні простори\\
	Відображення $A: L \to M$, тобто: $\forall x \in L: Ax=y \in M$, для якого виконані наступні умови:\\
	1) $\forall x_1,x_2 \in L: A(x_1+x_2)=Ax_1+Ax_2$\\
	2) $\forall \lambda \in \mathbb{R}: A(\lambda x) = \lambda Ax$\\
	називається \textbf{лінійним оператором}\\
	\\
	\prp{2.1.2. Властивості лінійних операторів}\\
	1) Якщо $A$ - лінійний оператор, то $A(0) = 0$\\
	2) $A$ - лінійний оператор $\iff \forall x_1,x_2 \in L: \forall \alpha_1, \alpha_2 \in \mathbb{R}: \\ A(\alpha_1 x_1 + \alpha_2 x_2) = \alpha_1 Ax_1 + \alpha_2 Ax_2$\\
	3) $\forall x_1,\dots, x_n \in L: \forall \alpha_1, \dots, \alpha_n \in \mathbb{R}: \\ A(\alpha_1 x_1 + \dots + \alpha_n x_n) = \alpha_1 Ax_1 + \dots + \alpha_n Ax_n$\\
	\proof
	1) $A(0) = A(x - x) = Ax + A(-x) = Ax - Ax = 0$\\
	\\
	2) Доведення в обидві боки\\
	$\boxed{\Rightarrow}$ Дано: $A$ - лінійний оператор\\
	Тоді $\forall x_1,x_2 \in L: \forall \alpha_1, \alpha_2 \in \mathbb{R}: A(\alpha_1 x_1 + \alpha_2 x_2) = A(\alpha_1 x_1) + A(\alpha_2 x_2) = \alpha_1 Ax_1 + \alpha_2 Ax_2$
	\bigline
	$\boxed{\Leftarrow}$ Дано: $\forall x_1,x_2 \in L: \forall \alpha_1, \alpha_2 \in \mathbb{R}: A(\alpha_1 x_1 + \alpha_2 x_2) = \alpha_1 Ax_1 + \alpha_2 Ax_2$\\
	Тоді:\\
	1)) $\alpha_1 = \alpha_2 = 1 \Rightarrow A(x_1 + x_2) = Ax_1 + Ax_2$\\
	2)) $\alpha_1 = 0 \Rightarrow A(\alpha_1 x_1) = \alpha_1 Ax_1$\\
	Ці умови і показують, що $A$ - лінійний оператор\\
	\\
	3) \textit{випливає з другого, доведення за МІ за кількістю} $x$ \qed
	\\
	\\
	\ex{2.1.3.(1)} Нехай задано оператор $A: \underset{=L}{\mathbb{R}^2} \to \underset{=M}{\mathbb{R}^2}$\\
	$\huge A\vec{x} = \begin{pmatrix} x_1 - 2x_2 \\ 3x_2 + x_1 \end{pmatrix}$\\
	Перевіримо, що такий оператор є лінійним\\
	$\huge \vec{x} = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}$, $\huge \vec{y} = \begin{pmatrix} y_1 \\ y_2 \end{pmatrix}$\\
	$\Rightarrow A(\vec{x} + \vec{y}) = \begin{pmatrix} (x_1+y_1)-2(x_2+y_2) \\ 3(x_2+y_2)+(x_1+y_1) \end{pmatrix} = \dots = \begin{pmatrix} x_1 - 2x_2 \\ 3x_2 + x_1 \end{pmatrix} + \begin{pmatrix} y_1 - 2y_2 \\ 3y_2 + y_1 \end{pmatrix} = A\vec{x} + A\vec{y}$\\
	$\alpha \vec{x} = \begin{pmatrix} \alpha x_1 \\ \alpha x_2 \end{pmatrix}$\\
	$\Rightarrow A(\alpha \vec{x}) = \begin{pmatrix} (\alpha x_1) - 2(\alpha x_2) \\ 3(\alpha x_2) + (\alpha x_1) \end{pmatrix} = \dots = \alpha \begin{pmatrix} x_1 - 2x_2 \\ 3x_2 + x_1 \end{pmatrix} = \alpha A\vec{x}$\\
	Отже, $A$ - лінійний оператор\\
	\\
	\ex{2.1.3.(2)} Нехай задано оператор $A: \underset{=L}{\mathbb{R}^2} \to \underset{=M}{\mathbb{R}^2}$\\
	$\huge A\vec{x} = \begin{pmatrix} x_1 + x_2 + 3 \\ x_1 -x_2 \end{pmatrix}$\\
	$A(\vec{0}) = \begin{pmatrix} 3 \\ 0 \end{pmatrix} \neq \vec{0}$\\
	Отже, за другою властивістю, $A$ - НЕ лінійний оператор\\
	\\
	\\
	\ex{2.1.3.(3) Головний приклад}\\
	Нехай задано оператор $A: \mathbb{R}^n \to \mathbb{R}^m$\\
	Розглянемо матрицю $\huge \mathbb{A} = \begin{pmatrix}
	a_{11} & \cdots &  a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \cdots & a_{mn}
	\end{pmatrix} \in Mat(m \times n)
	$\\
	$\vec{x} = \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix} \in \mathbb{R}^n$\\
	$A\vec{x} = \mathbb{A}\vec{x} = \begin{pmatrix}
	a_{11} & \cdots &  a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \cdots & a_{mn}
	\end{pmatrix} \begin{pmatrix} x_1 \\ \vdots \\ x_n \end{pmatrix} = 
	\begin{pmatrix}
	a_{11}x_1 + \dots + a_{1n}x_n \\
	\vdots \\
	a_{m1}x_1 + \dots + a_{mn}x_n
	\end{pmatrix}
	$\\
	Цей оператор є лінійним, оскільки:\\
	$A(\alpha \vec{x} + \beta \vec{y}) = \mathbb{A}(\alpha \vec{x} + \beta \vec{y})+ \alpha \mathbb{A} \vec{x} + \beta \mathbb{A} \vec{y} = \alpha A \vec{x} + \beta A \vec{y}$\\
	\textbf{Висновок}: матриці задають лінійні оператори в \underline{арифметичному просторі}\\
	\\
	Поставимо обернену задачу: $A: \mathbb{R}^n \to \mathbb{R}^m$ - лінійний оператор. Чи буде існувати матриця, яка задає цей оператор?\\
	Нехай $\{\vec{e_1},\dots, \vec{e_n}\}$ - базис в $\mathbb{R}^n \Rightarrow \vec{x} = x_1\vec{e_1} + \dots + x_n\vec{e_n}$\\
	Подіємо цим вектором на оператор:\\
	$A\vec{x} = A(x_1\vec{e_1} + \dots + x_n\vec{e_n}) = x_1A\vec{e_1} + \dots + x_nA\vec{e_n} \boxed{=}$\\
	$A\vec{e_1} = \begin{pmatrix} a_{11} \\ \dots \\ a_{m1} \end{pmatrix}	 \in \mathbb{R}^m$\\
	...\\
	$A\vec{e_n} = \begin{pmatrix} a_{1n} \\ \dots \\ a_{mn} \end{pmatrix}	 \in \mathbb{R}^m$\\
$\boxed{=} x_1 \begin{pmatrix} a_{11} \\ \dots \\ a_{m1} \end{pmatrix} + \dots +x_n \begin{pmatrix} a_{1n} \\ \dots \\ a_{mn} \end{pmatrix} = 	
\begin{pmatrix}
	a_{11}x_1 + \dots + a_{1n}x_n \\
	\dots \\
	a_{m1}x_1 + \dots + a_{mn}x_n
	\end{pmatrix} = \mathbb{A}\vec{x}$\\
	Матриця $\mathbb{A}$ складається із стовпчиків дії $A$ на базиси елементів $A\vec{e_1}$ - 1-й стовпчик, ..., $A\vec{e_n}$ - n-й стовпчик, тобто\\
	$\mathbb{A} = \begin{pmatrix} A\vec{e_1} & \cdots & A\vec{e_n} \end{pmatrix}$\\
	\textbf{Висновок}: на заданому відображені наш лінійний оператор можна представити через матрицю\\
	\\
	А чи буде така матриця єдиною?\\
	\textbf{!}Припустимо, що $\exists \mathbb{B} \in Mat(m \times n): \mathbb{A} \vec{x} = \mathbb{B} \vec{x}$, але $\mathbb{A} \neq \mathbb{B}$ - ще одна матриця\\
	Тоді $\forall j =1,\dots,n: \mathbb{A} \vec{e_j} = \mathbb{B} \vec{e_j} \Rightarrow \begin{pmatrix} a_{1j} \\ \vdots \\ a_{mj} \end{pmatrix} = \begin{pmatrix} b_{1j} \\ \vdots \\ b_{mj} \end{pmatrix} \\ \Rightarrow \forall j=1,\dots,n: \forall i = 1,\dots,m: a_{ij} = b_{ij}$\\
	Але ж $\mathbb{A} \neq \mathbb{B}$. Суперечність\textbf{!} \\
	\textbf{Висновок}: матриця лінійного оператора задається \underline{єдиним} чином\\
	
	\subsection{Арифметичні дії з лінійними операторами}
	\defin{2.2.1.} Задані лінійні оператори $A,B: L \to M$\\
	- \textbf{сумою} лінійних операторів називають відображення $A+B: L \to M$, яке задається правилом: $(A+B)x = Ax+Bx$\\
	- \textbf{множення константи} на лінійний оператор називають відображення $\alpha A: L \to M$, яке задається правилом: $(\alpha A)(x) = \alpha (Ax)$\\
	Означення виконуються $\forall x \in L$
	\bigline
	\lm{2.2.2.} Задані лінійні оператори $A,B: L \to M$. Тоді\\
	1) $A+B$ - лінійний оператор\\
	2) $\forall \alpha \in \mathbb{R}: \alpha A$ - лінійний оператор\\
	\proof
	$\forall x_1, x_2 \in L; \forall \alpha, \beta \in \mathbb{R}:$\\
	1.1) $(A+B)(x_1+x_2) = A(x_1+x_2)+B(x_1+x_2)=Ax_1+Bx_1+Ax_2+Bx_2=(A+B)x_1 + (A+B)x_2$\\
	1.2) $(A+B)(\beta x_1) = A(\beta x_1)+B(\beta x_1)=\beta (Ax_1+Bx_1) = \beta(A+B)x_1$\\
	\\
	2.1) $(\alpha A)(x_1+x_2) = \alpha(A(x_1+x_2))=\alpha(Ax_1 + Ax_2) = \alpha Ax_1 + \alpha Ax_2 = (\alpha A)x_1 + (\alpha A)x_2$\\
	2.2) $(\alpha A) (\beta x_1) = \alpha A(\beta x) = \beta(\alpha Ax) = \beta (\alpha A)x$ \qed
	\bigline
	\rm{2.2.2.} Множину всіх лінійних операторів $L \to M$ позначають $\mathcal{L}(L,M)$ і є лінійним простором\\
	\textit{Вказівка: перевірити 8 аксіом}
	\\
	\\
	\defin{2.2.3.} Задані лінійні оператори $A: L \to M, B: M \to N$\\
	\textbf{Добутком} лінійних операторів називають відображення $B\cdot A: L \to N$, яке визначено правилом: $\forall x \in L: (BA)x = B(Ax)$
	\bigline
	\lm{2.2.4.} Задані лінійні оператори $A: L \to M, B: M \to N$. Тоді $BA$ - лінійний оператор\\
	\proof
	$\forall x_1, x_2 \in L; \forall \alpha \in \mathbb{R}:$\\
	1) $(BA)(x_1+x_2) = B(A(x_1+x_2)) = B(Ax_1+Ax_2)=B(Ax_1) + B(Ax_2)=(BA)x_1+(BA)x_2$\\
	2) $(BA)(\alpha x_1) = B(A(\alpha x_1)) = B(\alpha Ax_1) = \alpha B(Ax_1) = \alpha (BA)x_1$ \qed
	\bigline
	\rm{2.2.4.(1)} Якщо $A,B: L \to L$ та задані $BA, AB: L \to L$, то взагалі $BA \neq AB$ (прикладом є матриці лінійних операторів)
	\bigline
	\defin{2.5.1.} Оператор $I: L \to L$, такий, що $\forall x \in L: Ix = x$, називають \textbf{одиничним}
	\bigline
	\th{2.2.5. Властивості}\\
	Задані $A,B,C: L \to L$ - лінійні оператори. Тоді\\
	1) $(A \cdot B) \cdot C = A \cdot (B \cdot C)$\\
	2) $A \cdot I = I \cdot A$\\
	3) $A \cdot (B+C) = A \cdot B + A \cdot C \hspace{1cm} (A+B) \cdot C = A \cdot C + B \cdot C$\\
	\proof
	1) З одного та іншого боків маємо\\
	$((A \cdot B) \cdot C) x = (A \cdot B) \cdot (Cx) = A \cdot (B \cdot (Cx))$\\
	$(A \cdot (B \cdot C)) x = A \cdot ( (B \cdot C) x) = A \cdot (B \cdot (Cx))$\\
	Таким чином, $(A \cdot B) \cdot C = A \cdot (B \cdot C)$
	\bigline
	2) $(A \cdot I) x = A \cdot (Ix) = A x = I \cdot (A x) = (I \cdot A) x$\\
	Таким чином, $A \cdot I = I \cdot A$
	\bigline
	3.1) $[A \cdot (B + C)]x = A \cdot [(B+C)x] = A \cdot (Bx + Cx) = A (Bx) + A (Cx) = (A \cdot B)x + (A \cdot C)x = (A \cdot B + A \cdot C)x$\\
	3.2) $[(A+B) \cdot C]x = (A+B) \cdot (Cx) = A (Cx) + B (Cx) = (A \cdot C)x + (B \cdot C)x = (A \cdot C + B \cdot C)x$\\
	Таким чином, $A \cdot (B+C) = A \cdot B + A \cdot C \hspace{1cm} (A+B) \cdot C = A \cdot C + B \cdot C$ \qed
	\bigline
	\rm{2.2.4.(2)} Множина $\mathcal{L}(L,L)$ є кільцем, алгеброю
	\bigline
	\ex{2.2.5. Добуток матриці як лінійний оператор}\\
	Задані два лінійних оператори $A: \mathbb{R}^n \to \mathbb{R}^m$ та $B: \mathbb{R}^m \to \mathbb{R}^k$\\
	За \textbf{Ex. 2.1.3.(3)}, першому оператору відповідає матриця $\mathbb{A}$, а другому - матриця $\mathbb{B}$, тобто\\
	$A\vec{x}=\mathbb{A}x$, $B\vec{x}=\mathbb{B}x$\\
	Знайдемо добуток операторів:\\
	$BA: \mathbb{R}^n \to \mathbb{R}^k$, тут їй теж буде відповідати матриця (якась інша)\\
	$(BA)\vec{x} = B(A\vec{x}) = B(\mathbb{A}\vec{x}) = \mathbb{B}(\mathbb{A}\vec{x}) \boxed{=} $\\
	$
	\mathbb{A} = \begin{pmatrix}
	a_{11} \dots a_{1n}\\
	\vdots \ddots \vdots \\
	a_{m1} \dots a_{mn}
	\end{pmatrix},
	\mathbb{A}\vec{x} = \begin{pmatrix}
	a_{11}x_1 + \dots + a_{1n}x_n \\
	\dots \\
	a_{m1}x_1 + \dots + a_{mn}x_n
	\end{pmatrix} = \begin{pmatrix}
	y_1\\
	\dots \\
	y_m
	\end{pmatrix} = \vec{y}$\\
	$\mathbb{B} = \begin{pmatrix}
	b_{11} \dots b_{1m}\\
	\vdots \ddots \vdots \\
	b_{k1} \dots b_{km}
	\end{pmatrix}, \mathbb{B}\vec{y} = \begin{pmatrix}
	b_{11}y_1 + \dots + b_{1m}y_m \\
	\dots \\
	b_{k1}y_1 + \dots + b_{km}y_m
	\end{pmatrix}$\\
	$
	\boxed{=} \begin{pmatrix}
	b_{11}(a_{11}x_1 + \dots + a_{1n}x_n) + \dots + b_{1m}(a_{m1}x_1 + \dots + a_{mn}x_n) \\
	\dots \\
	b_{k1}(a_{11}x_1 + \dots + a_{1n}x_n) + \dots + b_{km}(a_{m1}x_1 + \dots + a_{mn}x_n)
	\end{pmatrix} = \\ = \begin{pmatrix}
	(b_{11}a_{11} + \dots + b_{1m}a_{m1})x_1 + \dots + (b_{11}a_{1n} + \dots + b_{1m}a_{mn})x_n \\
	\dots \\
	(b_{k1}a_{11} + \dots + b_{km}a_{m1})x_1 + \dots + (b_{k1}a_{1n} + \dots + b_{km}a_{mn})x_n \\
	\end{pmatrix} \overset{\textrm{позн}}{=} \\ \overset{\textrm{позн}}{=}
	\begin{pmatrix}
	c_{11} x_1 + \dots + c_{1n} x_n \\
	\dots \\
	c_{k1} x_1 + \dots + c_{kn} x_n \\
	\end{pmatrix} = \mathbb{C}\vec{x}
	$\\
	Розпишемо останню матрицю більш детально:\\
	$\mathbb{C} = \begin{pmatrix}
	c_{11} \dots c_{1n}\\
	\vdots \ddots \vdots \\
	c_{k1} \dots c_{kn}
	\end{pmatrix} =
	\begin{pmatrix}
	b_{11}a_{11}+\dots+b_{1m}a_{m1} \dots b_{11}a_{1n}+\dots+b_{1m}a_{mn} \\
	\vdots \ddots \vdots \\
	b_{k1}a_{11} + \dots + b_{km}a_{m1} \dots b_{k1}a_{1n} + \dots + b_{km}a_{mn} 
	\end{pmatrix} = \\ =
	\begin{pmatrix}
	b_{11} \dots b_{1m}\\
	\vdots \ddots \vdots \\
	b_{k1} \dots b_{km}
	\end{pmatrix}
	\begin{pmatrix}
	a_{11} \dots a_{1n}\\
	\vdots \ddots \vdots \\
	a_{m1} \dots a_{mn}
	\end{pmatrix} = \mathbb{B} \mathbb{A}
	$\\
	Остаточно отримали:\\
	$(BA)\vec{x} = (\mathbb{B} \mathbb{A})\vec{x}$\\
	\subsection{Ядро, образ}
	\defin{2.3.1.} Задано лінійний оператор $A: L \to M$\\
	- \textbf{ядром} лінійного оператора $A$ називають множину
	\begin{align*}
	\textrm{Ker} A = \{x \in L: Ax = 0\}
	\end{align*}
	- \textbf{образом} лінійного оператора $A$ називають множину
	\begin{align*}
	\Im A = \{y \in M: \exists x \in L: y = Ax\}
	\end{align*}
	\\
	\th{2.3.2.} $\textrm{Ker} A$ та $\Im A$ - лінійні підпростори відповідно простору $L$ та $M$\\
	\proof
	I. $\textrm{Ker} A$\\
	$\forall x_1, x_2 \in \textrm{Ker} A: \forall \lambda \in \mathbb{R}:$\\
	$A(x_1+x_2)=Ax_1+Ax_2 = 0 + 0 = 0 \Rightarrow x_1+x_2 \in \textrm{Ker} A$\\
	$A(\lambda x_1) = \lambda Ax_1 = 0 \Rightarrow \lambda x_1 \in \textrm{Ker} A$\\
	Тому це є підпростором простора $L$\\
	\\
	II. $\Im A$\\
	$\forall y_1, y_2 \in \Im A \Rightarrow \forall y_1, y_2 \in M: \exists x_1, x_2 \in L: y_1 = Ax_1, y_2 = Ax_2, \forall \lambda \in \mathbb{R}:$\\
	$y_1 + y_2 = Ax_1 + Ax_2 = A(x_1+x_2) \Rightarrow y_1+y_2 \in \Im A$\\
	$\lambda y_1 = \lambda Ax_1 = A(\lambda x_1) \Rightarrow \lambda y_1 \in \Im A$\\
	Тому це є підпростором простора $M$\\
	\qed
	\bigline
	\ex{2.3.3.(1)} Задано $A: \mathbb{R}^3 \to \mathbb{R}^3$ - такий лінійний оператор:\\
	$A \vec{x} = \begin{pmatrix}
	x_1 - x_2 + x_3 \\
	2x_1 + x_2 - 3x_3 \\
	x_1 + 2x_2 - 4x_3
	\end{pmatrix}$\\
	Знайдемо ядро та образ:\\
	I. $\vec{x} \in \ker A \iff A\vec{x} = \vec{0} \iff \begin{cases} x_1 - x_2 + x_3 = 0 \\ 2x_1 + x_2 - 3x_3 = 0 \\ x_1 + 2x_2 - 4x_3 = 0 \end{cases} \iff \begin{cases} x_1 - x_2 + x_3 = 0 \\ 3x_2 - 5x_3 = 0 \end{cases} \\ \iff \begin{cases} x_1 = \frac{2}{3}x_3 \\ x_2 = \frac{5}{3}x_3 \end{cases}$\\
	$\iff \vec{x} = \begin{pmatrix} \frac{2}{3}x_3 \\ \frac{5}{3}x_3 \\ x_3  \end{pmatrix} = \frac{1}{3}x_3 \begin{pmatrix} 2 \\ 5 \\ 3 \end{pmatrix}$\\
	Отже, $\textrm{Ker A} = span \left\{\begin{pmatrix} 2 \\ 5 \\ 3 \end{pmatrix} \right\}$\\
	Ми ще сюди повернемось: тут не так просто знаходити образ за означенням
	\bigline
	\ex{2.3.3.(2)} Задано $A: \mathbb{R}_n[x] \to \mathbb{R}_n[x]$ - такий лінійний оператор:\\
	$(Af)(x) = f'(x)$\\
	Знайдемо ядро та образ:\\
	I. $f \in \textrm{Ker A} \Rightarrow (Af)(x) = 0 \Rightarrow f'(x) \equiv 0 \Rightarrow f(x) = const$\\
	Отже, $\textrm{Ker} A = \{ f(x) = const\} \overset{\textrm{або}}{=} \mathbb{R}_0[x]$
	\\ \\
	II. $g \in \Im A$, тобто $\exists f: g(f) = (Af)(x) \Rightarrow g(x) = f'(x)$\\
	Отже, $\Im A = \mathbb{R}_{n-1}[x]$
	\bigline
	\lm{2.3.4. Структура образа}\\
	Якщо $\{e_1,\dots, e_n\}$ - базис $L$, то $\Im A = span \{Ae_1,\dots, Ae_n\}$\\
	\proof
	$y \in \Im A \Rightarrow \exists x \in L: y = Ax$\\
	$y = Ax \overset{\textrm{оскільки є базис}}{=} A(x_1e_1 + \dots + x_n e_n) = x_1 Ae_1 + \dots + x_n A e_n$\\
	Отже, $y \in \Im A \Rightarrow y \in span \{Ae_1, \dots, Ae_n \} \Rightarrow \Im A = span \{Ae_1, \dots, Ae_n \}$ \qed
	\bigline
	Повернемось до \textbf{Ex. 2.3.3.(1)}\\
	II. Оберемо базис в $\mathbb{R}^3$ множину $\{\vec{e_1}, \vec{e_2}, \vec{e_3}\}$ - одиничні вектори\\
	$A\vec{e_1} = \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}$, $A\vec{e_2} = \begin{pmatrix} -1 \\ 1 \\ 2 \end{pmatrix}$, $A\vec{e_3} = \begin{pmatrix} 1 \\ -3 \\ -4 \end{pmatrix}$\\
	Тому $\Im A = span \left\{ \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}, \begin{pmatrix} -1 \\ 1 \\ 2 \end{pmatrix}, \begin{pmatrix} 1 \\ -3 \\ -4 \end{pmatrix} \right\}$\\
	Тут трохи з лінійною оболонкою проблематично, оскільки треба переконатись, що ці 3 вектори - л.н.з. Але впадлу перевіряти. Тому знову ми згодом повернемось\\
	\bigline
	\th{2.3.5. Зв'язок розмірностей ядра та образа}\\
	$\dim{(\textrm{Ker} A)} + \dim{(\Im A)} = \dim L$\\
	\proof
	Нехай $\{f_1, \dots, f_n\}$ - базис $\textrm{Ker} A$ та $\{g_1, \dots, g_m\}$ - базис $\Im A$\\
	$\forall j = 1,\dots,m: g_j \in \Im A \Rightarrow \exists h_j \in L: Ah_j = g_j$\\
	У нас тут $\dim (\textrm{Ker} A) = n$, а $\dim(\Im A) = m$\\
	Перевіримо, що $\{f_1,\dots, f_n, h_1,\dots, h_m\}$ - базис $L$
	\bigline
	I. л.н.з.?\\
	$\alpha_1 f_1 + \dots + \alpha_n f_n + \beta_1 h_1 + \dots + \beta_m h_m = 0$ (*)\\
	Подіємо оператором на всю комбінацію:\\
	$A(\alpha_1 f_1 + \dots + \alpha_n f_n + \beta_1 h_1 + \dots + \beta_m h_m) = A(0)$\\
	$\alpha_1 Af_1 + \dots + \alpha_n Af_n + \beta_1 Ah_1 + \dots + \beta_m A h_m = 0$\\
	$0 + \dots + 0 + \beta_1 g_1 + \dots + \beta_n g_n = 0 \overset{\textrm{базис}}{\Rightarrow} \beta_1 = \dots = \beta_n = 0$\\
	Підставимо отримане в (*):\\
	$\alpha_1 f_1 + \dots + \alpha_n f_n = 0 \overset{\textrm{базис}}{\Rightarrow} \alpha_1 = \dots = \alpha_n = 0$\\
	Отже, з наших міркувань $\alpha_1 = \dots = \alpha_n = \beta_1 = \dots = \beta_n = 0$\\
	Таким чином, довели л.н.з.
	\bigline
	II. повнота?\\
	$\forall z \in L: Az \in \Im A \Rightarrow Az = \gamma_1 g_1 + \dots + \gamma_m g_m$\\
	Розглянемо елемент із $L$ таким чином, що:\\
	$w = z - (\gamma_1 h_1 + \dots + \gamma_m h_m), w \in L$\\
	Перевіримо, що $w \in \textrm{Ker} A$\\
	$Aw = A(z - (\gamma_1 h_1 + \dots + \gamma_m h_m)) = Az - \gamma_1 Ah_1 - \dots - \gamma_m Ah_m = \\ = Az - \gamma_1 g_1 - \dots - \gamma_m g_m = 0 \Rightarrow w \in \textrm{Ker} A$\\
	Тоді $\exists \tau_1, \dots, \tau_n \in \mathbb{R}: w = \tau_1 f_1 + \dots + \tau_n f_n$ (за базисом)\\
	Отримали:\\
	$\tau_1 f_1 + \dots + \tau_n f_n = z - (\gamma_1 h_1 + \dots + \gamma_m h_m)$\\
	$\Rightarrow z = \tau_1 f_1 + \dots + \tau_n f_n + \gamma_1 h_1 + \dots + \gamma_m h_m$\\
	Таким чином, маємо повну л.н.з. систему
	\bigline
	Остаточно: $\{f_1,\dots, f_n, h_1,\dots, h_m\}$ - базис $L$, а отже, $\dim L = m+n$\\
	$\dim L = \dim{(\textrm{Ker} A)} + \dim{(\Im A)}$ \qed
	\bigline
	Повернемось до \textbf{Ex. 2.3.3.(1)} вдруге\\
	Ми знайшли $\textrm{Ker A} = span \left\{\begin{pmatrix} 2 \\ 5 \\ 3 \end{pmatrix} \right\}$\\
	Також $\Im A = span \left\{ \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}, \begin{pmatrix} -1 \\ 1 \\ 2 \end{pmatrix}, \begin{pmatrix} 1 \\ -3 \\ -4 \end{pmatrix} \right\}$\\
	У нас $\dim {\mathbb{R}^3} = \dim L = 3$, а $\dim (\textrm{Ker} A) = 1$. Тому $\dim(\Im  A) = 2$\\
	Тому варто писати, що $\Im A = span \left\{ \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}, \begin{pmatrix} -1 \\ 1 \\ 2 \end{pmatrix} \right\}$\\
	
	\subsection{Лінійні функціонали}
	\defin{2.4.1.} Задано $L$ - лінійний простір\\
	\textbf{Лінійним функціоналом} на $L$ називається лінійний оператор \\ $\varphi: L \to \mathbb{R}$\\
	\\
	\ex{2.4.2.}
	$L=\mathbb{R}^4$, $\varphi: \underset{=L}{\mathbb{R}^4} \to \mathbb{R}:$\\
	$\varphi(\vec{x}) = x_1 + 3x_2 - \pi x_3 + \sqrt{17}x_4$
	\bigline
	
	\subsection{Обернений оператор, одиничний оператор}
	\defin{2.5.2.} Задано $A: L \to M$ - лінійний оператор\\
	\textbf{Оберненим оператором} називають такий оператор $B: M \to L$, що
	\begin{align*}
	\forall x \in L: BAx = x \\
	\forall y \in M: ABy = y
	\end{align*},
	якщо він існує\\
	Можна переписати умову інакше
	\begin{align*}
	BA = I_L, I_L: L \to L\\
	AB = I_M, I_M: M \to M
	\end{align*}
	\defin{2.5.3.} Оператор $A$ називають \textbf{зворотним}, якщо існує обернений оператор $B$ (та справедливі два тотожності) \\
	Позначення: $B \overset{\textrm{позн}}{=} A^{-1}$
	\bigline
	\ex{2.5.4.(1)} Задано $T: \mathbb{R}_3[x] \to Mat(2 \times 2)$ - такий лінійний оператор:\\
	$f(x) = a + bx + cx^2 + dx^3$\\
	$(Tf)(x) = \begin{pmatrix}
	a+b & a-2c \\
	d & b-d
	\end{pmatrix}$\\
	Визначимо оператор $S: Mat(2 \times 2) \to \mathbb{R}_3[x]$ таким чином, що:\\
	$\mathbb{A} = \begin{pmatrix}
	a & b \\
	c & d
	\end{pmatrix}$\\
	$S\mathbb{A} = (a-c-d) + (c+d)x + \dfrac{1}{2}(a-b-c-d)x^2 + cx^3$\\
	Перевіримо, що $S$ - обернений оператор зліва та справа. Справді:\\
	$\forall f \in \mathbb{R}_3[x]: (STf)(x) = S(Tf(x)) = S(T(a+bx+cx^2+dx^3))= \\ = S \begin{pmatrix}
	a+b & a-2c \\
	d & b-d
\end{pmatrix} = \\ = [a+b-d-(b-d)] + [d + (b-d)]x + \dfrac{1}{2}[(a+b)-(a-2c)-d-(b-d)]+dx^3 = \\ = a + bx + cx^2 + dx^3 = f(x)$\\
\\
$\forall \mathbb{A} \in Mat(2 \times 2): TS \mathbb{A} = T(S \mathbb{A}) = T \left( S\begin{pmatrix}
a & b \\
c & d
\end{pmatrix} \right) = \\ = T\left[(a-c-d)+(c+d)x+\dfrac{1}{2}(a-b-c-d)x^2+cx^3 \right] = \\ = \begin{pmatrix}
(a-c-d)+(c+d) & (a-c-d)-2 \dfrac{1}{2}(a-b-c-d) \\
c & (c+d)-c
\end{pmatrix} = \begin{pmatrix}
a & b \\
c & d
\end{pmatrix} = \mathbb{A}$\\
Отримали:
$(STf)(x) = f(x)$ та $TS \mathbb{A} = \mathbb{A}$\\
Отже, $S$ - обернений оператор, або $S = T^{-1}$
	\bigline
	\ex{2.5.4.(2)} Задано $A: \mathbb{R}^2 \to \mathbb{R}^2$ - такий лінійний оператор\\
	$A\vec{x} = \begin{pmatrix}
	x_1 + x_2 \\ 2x_1 + 2x_2
	\end{pmatrix}$
	$A\vec{x} = \vec{y} \Rightarrow \begin{cases} x_1 + x_2 = y_1 \\ 2x_1 + 2x_2 = y_2 \end{cases}$\\
	Відносно $x_1,x_2$ система не містить розв'язків. \\ Отже, не існує оберненого оператора
	\bigline
	\prp{2.5.5.} Задано $A: L \to M$ - лінійний та зворотний оператор. Тоді обернений оператор $A^{-1}$ - лінійний\\
	\proof
	$\forall y_1, y_2 \in M \Rightarrow y_1 = AA^{-1}y_1, y_2 = AA^{-1}y_2: \forall \alpha_1, \alpha_2 \in \mathbb{R}$\\
	$A^{-1}(\alpha_1 y_1 + \alpha_2 y_2) = A^{-1}(\alpha_1 AA^{-1}y_1 + \alpha_2 AA^{-1}y_2) = \\ = A^{-1}[A(\alpha_1 A^{-1}y_1 + \alpha_2 A^{-1}y_2)] = A^{-1}A(\alpha_1 A^{-1}y_1 + \alpha_2 A^{-1}y_2)) = \\ = \alpha_1 A^{-1}y_1 + \alpha_2 A^{-1}y_2$\\
	Отже, $A^{-1}$ - лінійний \qed
	\bigline
	\prp{2.5.6.} Задано $A: L \to M$ - лінійний та зворотний оператор. Тоді обернений оператор $A^{-1}_1$ є єдиним\\
	\proof
	\textbf{!}Припустимо, що існує також $A^{-1}_2$. Тоді $\forall y \in M:$\\
	$A^{-1}_1 y = A^{-1}_1 I_M y = A^{-1}_1 A A^{-1}_2 y = (A^{-1}_1 A) (A^{-1}_2 y) = I_L (\underset{\in L}{A^{-1}_2 y}) = A_2^{-1}y$\\
	$\Rightarrow A^{-1}_1 = A^{-1}_2$. Суперечність\textbf{!}
	\qed
	\bigline
	\prp{2.5.7.} Задано $A: L \to M$ - лінійний та зворотний оператор. Тоді $A^{-1}: M \to L$ теж є зворотним та $(A^{-1})^{-1} = A$\\
	\proof
	Якщо $A$ - зворотний, то $\exists A^{-1}$, для якого $AA^{-1} = I_M$, $A^{-1}A = I_L$. Ну й ба більше, цей оператор - єдиний\\
	Створимо якийсь обернений оператор $T: L \to M$, щоб $A^{-1}T = I_L$, $TA^{-1} = I_M$\\
	Тоді: $I_L = A^{-1}A = A^{-1}T$ та $I_M = AA^{-1} = TA^{-1}$\\
	Звідси $T = A$. Отже, $A^{-1}$ зворотний до $A = (A^{-1})^{-1}$ \qed
	\bigline
	\lm{2.5.8.} Задано $A: L \to M$ - лінійний оператор\\
	$A$ - зворотний $\iff$ $A$ має бієктивне відображення\\
	\proof
	$\boxed{\Rightarrow}$ Дано: $A$ - зворотний, тобто $\exists A^{-1}$\\
	Доведемо ін'єктивність\\
	$\forall y \in M: \exists x \overset{\textrm{встановимо}}{=} A^{-1}y: Ax = AA^{1}y = y$\\
	Отже, оператор є ін'єктивним\\
	Доведемо сюр'єктивність\\
	\textbf{!}Припустимо, що $\forall x_1,x_2 \in L: x_1 \neq x_2 \Rightarrow Ax_1 = Ax_2$\\
	Тоді звідси $Ax_1 - Ax_2 = A(x_1-x_2)=0=AA^{-1}0 \Rightarrow x_1 - x_2 = 0$. Суперечність\textbf{!} \\
	Отже, $\forall x_1,x_2 \in L: x_1 \neq x_2 \Rightarrow Ax_1 \neq Ax_2$\\
	Тобто є сюр'єктивним\\
	Остаточно ін'єктивний + сюр'єктивний = бієктивний
	\bigline
	$\boxed{\Leftarrow}$ Дано: $A$ - бієктивний, тобто $\forall y \in M: \exists! x \in L: y=  Ax$\\
	Побудуємо оператор $B: M \to L$, такий, що $\forall y \in M: x = By \in L$\\
	Тоді:\\
	$\forall y \in M: ABy = Ax = y$\\
	$\forall x \in L: BAx = By = x$\\
	Тому $B = A^{-1}$, а наш оператор $A$ - зворотний \qed
	\bigline
	\th{2.5.9.} Задано $A: L \to M$ - лінійний оператор\\
	$A$ - зворотний $\iff$ $\begin{cases} \textrm{Ker} A = \{0\} \\ \Im A = M \end{cases}$\\
	\proof
	$\boxed{\Rightarrow}$ Дано: $A$ - зворотний\\
	1) $x \in \textrm{Ker} A \Rightarrow x \in L$. Тоді $x = A^{-1}Ax = A(0) = 0$\\
	Тому $\textrm{Ker} A = \{0\}$\\
	2) $\forall y \in M: y = A(\underset{\in L}{A^{-1}y}) \in \Im A$\\
	Тому $M \subset \Im A$\\
	За означенням образу, $\Im A \subset M$\\
	Отже, $\Im A = M$
	\bigline
	$\boxed{\Leftarrow}$ Дано: $\begin{cases} \textrm{Ker} A = \{0\} \\ \Im A = M \end{cases}$\\
	Треба знайти обернену матрицю $A^{-1}$\\
	$\Im A = M \Rightarrow \forall y \in M: \exists x \in L: y = Ax$\\
	\textbf{!}Припустимо, що $\exists \tilde{x} \in L: y = A\tilde{x}$\\
	Тоді $0 = y - y = Ax - A\tilde{x} = A(x-\tilde{x}) \Rightarrow x-\tilde{x} \in \textrm{Ker} A$\\
	Отже, $x-\tilde{x}=0$, тобто $x = \tilde{x}$. Суперечність\textbf{!}\\
	Таким чином, ми маємо: $\exists! x \in L: y = Ax$\\
	Тоді маємо бієкцію $\Rightarrow A$ - зворотний \qed
	\bigline
	\crl{2.5.9.} $A:L \to L$ - зворотний $\iff$ $\left[ \begin{gathered} \textrm{Ker} A = \{0\} \\ \Im A = L \end{gathered} \right.$\\
	\textit{Випливає з} \textbf{Th. 2.5.9.}\\
	
	\subsection{Ізоморфні лінійні простори, ізоморфізм}
	\defin{2.6.1.} Лінійні простори $L,M$ називаються \textbf{ізоморфними}, якщо $\exists A: L \to M$ - зворотний\\
	А оператор $A$ називають \textbf{ізоморфізмом}\\
	Позначення: $L \cong M$
	\bigline
	\th{2.6.2.} Задано $A: L \to M$ - лінійний оператор\\
	$A$ - ізоморфізм $\iff$ якщо $\{f_1,\dots,f_n\}$ - базис в $L$, то $\{\overset{=g_1}{Af_1},\dots, \overset{=g_n}{Af_n}\}$ - базис в $M$\\
	\proof
	$\boxed{\Rightarrow}$ Дано: $L \cong M$, або $A: L \to M$ - ізоморфізм\\
	Також в нас відомий базис $\{f_1,\dots,f_n\}$ в $L$. Перевіримо, що $\{g_1,\dots,g_n\}$ - базис\\
	І дійсно, $\forall y \in M: y = Ax = A(\alpha_1 f_1 + \dots + \alpha_n f_n) = \alpha_1 Af_1 + \dots + \alpha_n Af_n = \alpha_1 g_1 + \dots + \alpha_n g_n$\\
	Отримали розклад єдиним чином. Отже, $\{g_1,\dots,g_n\}$ - базис в $M$
	\bigline
	$\boxed{\Leftarrow}$ Дано: $\{f_1,\dots,f_n\}, \{Af_1,\dots,Af_n\}$ - відповідно базиси в $L$,$M$\\
	Тобто маємо, що $Ax = A(\alpha_1 f_1 + \dots + \alpha_n f_n) = \alpha_1 Af_1 + \dots + \alpha_n Af_n = y$\\
	Покажемо, що цей оператор є зворотним\\
	Із щойно 'маємо' отримали, що $\forall y \in M: y \in \Im A \Rightarrow M \subset \Im A$\\
	За означенням образа, $\Im A \subset M$\\
	Тоді $\Im A = M \Rightarrow \dim(\textrm{Ker} A) = 0 \Rightarrow \textrm{Ker} A = \{0\}$\\
	Отже, $A$ - зворотний, а тому - ізоморфізм \qed
	\bigline
	\th{2.6.3.} $L \cong M$ $\iff$ $\dim L = \dim M$\\
	\textit{Випливає під час доведення минулої теореми}
	\bigline
	\crl{2.6.3.} Будь-який простір розмірності $n$ є ізоморфним \\ арифметичному простору. Або коротко: $L \cong \mathbb{R}^n$ \bigline
	\ex{2.6.4.} $\mathbb{R}_2[x] \cong \mathbb{R}^3$, оскільки $\dim(\mathbb{R}_2[x]) = \dim (\mathbb{R}^3) = 3$\\
	$\forall f \in \mathbb{R}_2[x]: f(x) = ax^2 + bx +c \leftrightarrow \begin{pmatrix}
	a \\ b \\ c
	\end{pmatrix} = \vec{x} \in \mathbb{R}^3$
	
	\subsection{Матриця лінійного оператора, що побудована за лінійним оператором}
	Задані $L,M$ - лінійні простори, $A: L \to M$ - лінійний оператор\\
	За щойно отриманим наслідком, буде у нас наступна картина:\\
	$L \cong \mathbb{R}^n$\\
	$\{f_1,\dots,f_n\}$ - базис в $L$ переводить в $\{\vec{e_1},\dots,\vec{e_n}\}$ - базис в $\mathbb{R}^n$\\
	А оператор $J_f: L \to \mathbb{R}^n$:\\
	$J_f(f_j) = \vec{e_j}$ - ізоморфізм\\
	$M \cong \mathbb{R}^m$\\
	$\{g_1,\dots,g_n\}$ - базис в $M$ переводить в $\{\vec{e_1},\dots,\vec{e_m}\}$ - базис в $\mathbb{R}^m$\\
	А оператор $J_g: M \to \mathbb{R}^m$:\\
	$J_g(g_k) = \vec{e_k}$ - ізоморфізм\\
	Але ми знаємо, що відображення $\mathbb{R}^n \to \mathbb{R}^m$ задає матрицю $\mathbb{A}$. Якраз її треба знайти
	\\
	Коротше, у нас виникне така картина:\\
	\begin{tikzcd}
L \arrow{r}{A} \arrow{d}{J_f} & M \arrow{d}{J_g} \\
\mathbb{R}^n \arrow{r}{\mathbb{A}} & \mathbb{R}^m
\end{tikzcd}\\
	Матрицю отримаємо наступним чином:\\
	$\mathbb{A}\vec{x} = J_g(A(J^{-1}_f\vec{x}))$\\
	\textit{спочатку із $\mathbb{R}^n$ переводимось в $L$, далі в $M$ і згодом в $\mathbb{R}^m$}\\
	Тобто ми побудували оператор:\\
	$\mathbb{A} = J_g A J_f^{-1}$\\
	А тепер дізнаємось, яким чином будується матриця:\\
	$\forall \vec{x} \in \mathbb{R}^n: \vec{x} = x_1 \vec{e_1}+ \dots + x_n \vec{e_n}$\\
	$J_f^{-1} \vec{e_j} = f_j \\ \Rightarrow J_f^{-1} \vec{x} = x_1f_1+\dots+x_nf_n$\\
	$\Rightarrow A(J_f^{-1}\vec{x}) = x_1Af_1 + \dots + x_nAf_n$\\
	$\forall j = 1,\dots,n: Af_j \in M$ - розкладається за базисом $\{g_1,\dots,g_m\}$ в $M$\\
	$Af_1 = a_{11}g_1 + \dots + a_{m1}g_m$\\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + a_{mn}g_m$\\
	$\Rightarrow J_g(A(J_f^{-1}\vec{x})) = J_g(x_1Af_1 + \dots + x_nAf_n) = \\ = \huge J_g\left(x_1 \sum_{k=1}^m a_{k1}g_k + \dots + x_n \sum_{k=1}^m a_{kn}g_k\right) = J_g\left(\sum_{k=1}^m (a_{k1}x_1 + \dots + a_{kn}x_n)g_k \right) = \\ = \begin{pmatrix}
	a_{11}x_1 + \dots + a_{1n}x_n \\
	\dots \\
	a_{m1}x_1 + \dots + a_{mn}x_n \\
	\end{pmatrix} = \begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \dots & a_{mn}
	\end{pmatrix} \begin{pmatrix}
	x_1 \\ \vdots \\ x_n
	\end{pmatrix} = \mathbb{A}\vec{x}$\\
	Та сама шукана матриця. Тепер можемо записати словесний алгоритм
	\bigline
	\textbf{Алгоритм побудови матриці оператора}:\\
	Оператором $A$ діємо на:\\
	- 1-й базисний вектор з $L$, результат розкладаємо за базисом $M$. Коефіцієнти розкладу утворюють 1-й стовпчик матриці $\mathbb{A}$\\
	- 2-й базисний вектор з $L$, результат розкладаємо за базисом $M$. Коефіцієнти розкладу утворюють 2-й стовпчик матриці $\mathbb{A}$\\
	... \\ тощо
	\bigline
	\ex{2.7.1.} Задано $A: \mathbb{R}_2[x] \to \mathbb{R}_2[x]$ - такий лінійний оператор\\
	$(Af)(x) = f(x+1)$\\
	Розглянемо для обох просторів базис $\{1,x,x^2\}$\\
	Знайдемо матрицю оператора:\\
	\begin{tikzcd}
\mathbb{R}_2[x] \arrow{r}{A} \arrow{d}{J} & \mathbb{R}_2[x] \arrow{d}{J} \\
\mathbb{R}^3 \arrow{r}{\mathbb{A}} & \mathbb{R}^3
\end{tikzcd}\\
	$f_0(x) = 1$ \hspace{0.5cm} $f_1(x) = x$ \hspace{0.5cm} $f_2(x) = x^2$\\
	$(Af_0)(x) = f_0(x+1) = 1 = 1 + 0x + 0x^2$\\
	$(Af_1)(x) = f_1(x+1) = x+1 = 1 + x + 0x^2$\\
	$(Af_2)(x) = f_2(x+1) = (x+1)^2 = 1 + 2x + x^2$\\
	Отже, $\mathbb{A} = \begin{pmatrix}
	1 & 1 & 1 \\
	0 & 1 & 2 \\
	0 & 0 & 1 
	\end{pmatrix}$
	\bigline
	\textbf{Remark 2.7.1.} Порядок базису тепер є важливим. Якщо змінити елементи місцями, то відповідно може змінитись матриця
	\bigline
	\textbf{*Зміна матриці лінійного оператора при деяких змін базисів}\\
	Задано $A: L \to M$ - лінійний оператор \\ Також є базиси $\{f_1,\dots,f_n\}$ в $L$ та $\{g_1,\dots,g_m\}$ в $M$\\
	Нехай нам вже відома матриця $\mathbb{A} = \begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \dots & a_{mn}
	\end{pmatrix}$\\
	Для деяких змін в базисах нас цікавитиме подальший вигляд матриці.\\
	Зробимо наступні зміни:
	\bigline
	1. $f_j \longleftrightarrow f_k$
\multicolsep=0pt
	\begin{multicols}{2}
	Було \\
$Af_1 = a_{11}g_1 + \dots + a_{m1}g_m$ \\
$\dots$ \\
$Af_j = a_{1j}g_1 + \dots + a_{mj}g_m$ \\
$\dots$ \\
$Af_k = a_{1k}g_1 + \dots + a_{mk}g_m$ \\
$\dots$ \\
$Af_n = a_{1n}g_1 + \dots + a_{mn}g_m$
	\columnbreak
	\\
	Стало \\
$Af_1 = a_{11}g_1 + \dots + a_{m1}g_m$ \\
$\dots$ \\
$Af_k = a_{1k}g_1 + \dots + a_{mk}g_m$\\
$\dots$ \\
$Af_j = a_{1j}g_1 + \dots + a_{mj}g_m$\\
$\dots$ \\
$Af_n = a_{1n}g_1 + \dots + a_{mn}g_m$
	\end{multicols}
	Висновок: $j$-ий та $k$-ий стовпчики матриці $\mathbb{A}$ зміняться місцями
	\bigline
	2. $f_j \rightarrow \lambda f_j$
\multicolsep=0pt
	\begin{multicols}{2}
	Було \\
$Af_j = a_{1j}g_1 + \dots + a_{mj}g_m$
	\columnbreak
	\\
	Стало \\
$A(\lambda f_j) = \lambda Af_j = \lambda a_{1j}g_1 + \dots + \lambda a_{mj}g_m$
	\end{multicols}
	Висновок: $j$-ий стовпчик матриці $\mathbb{A}$ помножиться на $\lambda$
	\bigline
	3. $f_j \rightarrow f_j+f_k$
\multicolsep=0pt
	\begin{multicols}{2}
	Було \\
$Af_j = a_{1j}g_1 + \dots + a_{mj}g_m$
	\columnbreak
	\\
	Стало \\
$A(f_j+f_k) = Af_j + Af_k =$\\
$= (a_{1j}+a_{1k})g_1 + \dots + (a_{mj}+a_{mk})g_m$
	\end{multicols}
	Висновок: до $j$-го стовпчику матриці $\mathbb{A}$ буде додано $k$-ий стовпчик
	\bigline
	
	4. $g_j \leftrightarrow g_k$
	%\hspace*{-2.4cm}%
	\multicolsep=0pt
	\begin{multicols}{2}
	Було \\
	$Af_1 = a_{11}g_1 + \dots + a_{j1}g_j + \\
	+ \dots + a_{k1}g_k + \dots + a_{m1}g_m$ \\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + a_{jn}g_j + \\
	+ \dots + a_{kn}g_k + \dots + a_{mn}g_m$
	\columnbreak
	\\
	Стало \\
	$Af_1 = a_{11}g_1 + \dots + a_{k1}g_k + \\
	+ \dots + a_{j1}g_j + \dots + a_{m1}g_m$ \\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + a_{kn}g_k + \\
	+ \dots + a_{jn}g_j + \dots + a_{mn}g_m$
	\end{multicols}
	Висновок: $j$-ий та $k$-ий рядки матриці $\mathbb{A}$ зміняться місцями
	\bigline
	5. $g_j \rightarrow \lambda g_j$
	\multicolsep=0pt
	\begin{multicols}{2}
	Було \\
	$Af_1 = a_{11}g_1 + \dots + a_{j1}g_j + \dots + a_{m1}g_m$\\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + a_{jn}g_j + \dots + a_{mn}g_m$
	\columnbreak
	\\
	Стало \\
	$Af_1 = a_{11}g_1 + \dots + \dfrac{a_{j1}}{\lambda} (\lambda g_j) + \dots + a_{m1}g_m$\\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + \dfrac{a_{jn}}{\lambda} (\lambda g_j) + \dots + a_{mn}g_m$
	\end{multicols}
	Висновок: $j$-ий рядок матриці $\mathbb{A}$ помножиться на $\dfrac{1}{\lambda}$
	\bigline
	6. $g_j \rightarrow g_j + g_k$
	\multicolsep=0pt
	\begin{multicols}{2}
	Було \\
	$Af_1 = a_{11}g_1 + \dots + a_{j1}g_j + \\ \dots + a_{k1}g_k + \dots + a_{m1}g_m$\\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + a_{jn}g_j + \\ \dots + a_{kn}g_k + \dots + a_{mn}g_m$\\
	\columnbreak
	\\
	Стало \\
	$Af_1 = a_{11}g_1 + \dots + a_{j1}(g_j+g_k) + \\ + \dots + (a_{k1}-a_{j1})g_k + \dots + a_{m1}g_m$\\
	$\dots$\\
	$Af_n = a_{1n}g_1 + \dots + a_{jn}(g_j+g_k) + \\ + \dots + (a_{kn}-a_{jn})g_k + \dots + a_{mn}g_m$
	\end{multicols}
	Висновок: до $k$-го рядку матриці $\mathbb{A}$ буде віднято $j$-ий рядок
	\subsection{Матриця добутку операторів}
	Задані $A: L \to M$, $B: M \to K$ - лінійні оператори\\
	Також є базиси $\{f_1,\dots, f_n\}$, $\{g_1,\dots, g_m\}$, $\{h_1,\dots, h_k\}$ відповідно для $L,M,K$\\
	$BA: L \to M$ - добуток\\
	$\mathbb{A}$ - матриця $A$ в базисі $\{f_1,\dots,f_n\}$\\
	$\mathbb{B}$ - матриця $B$ в базисі $\{g_1,\dots,g_m\}$\\
	Хочемо знайти $\mathbb{B} \mathbb{A}$\\
	\begin{tikzcd}
L \arrow{r}{A} \arrow{d}{J_f} & M \arrow{r}{B} \arrow{d}{J_g} & K \arrow{d}{J_h} \\
\mathbb{R}^n \arrow{r}{\mathbb{A}} & \mathbb{R}^m \arrow{r}{\mathbb{B}} & \mathbb{R}^k
\end{tikzcd}
	\\
	$Mat(BA)\vec{x} = J_h(BA(J_f^{-1} \vec{x})) = J_h(B \textcolor{red}{J_g^{-1} J_g} A(J_f^{-1} \vec{x})) = (J_h B J_g^{-1})(J_g A J_f^{-1}) \vec{x} \\ = \mathbb{B} \mathbb{A} \vec{x}$
	\subsection{Матриця лінійного функціоналу}
	Задано $\varphi: L \to \mathbb{R}$ - лінійний функціонал\\
	Також є базиси $\{f_1,\dots,f_n\}$, $\{1\}$ відповідно для $L,\mathbb{R}$\\
	Хочемо знайти матрицю $\Phi$\\
	\begin{tikzcd}
L \arrow{r}{\varphi} \arrow{d}{J} & \mathbb{R} \arrow{d}{I} \\
\mathbb{R}^n \arrow{r}{\Phi} & \mathbb{R}
\end{tikzcd}\\
Отримати матрицю можна вже за готовим алгоритмом (п. 2.7)\\
	$\varphi(f_1) = a_1 = a_1 \cdot 1$\\
	$\varphi(f_2) = a_2 = a_2 \cdot 1$\\
	$\dots$\\
	$\varphi(f_n) = a_n = a_n \cdot 1$\\
	$\Rightarrow \Phi = \begin{pmatrix} a_1 & a_2 & \dots & a_n \end{pmatrix}$ - її ще називають \textbf{ковектором}
	\bigline
	\subsection{Пряма сума операторів}
	\defin{2.10.1}. Задано наступне:\\
	$L$ - лінійний простір, $L = L_1 \dot{+} L_2$\\
	$M$ - лінійний простір, $M = M_1 \dot{+} M_2$\\
	$A_1: L_1 \to M_1$, $A_2: L_2 \to M_2$\\
	\textbf{Прямою сумою операторів} $A_1$ та $A_2$ називають оператор $A_1 \dot{+} A_2: L_1 \dot{+} L_2 \to M_1 \dot{+} M_2$ - таке відобржання, яке визначено за правилом:
	\begin{align*}
	\forall x_1 \in L_1, x_2 \in L_2, x_1+x_2 \in L_1 \dot{+} L_2: (A_1 \dot{+} A_2)(x_1+x_2)=A_1x_1 + A_2x_2 \in M_1 \dot{+} M_2
	\end{align*}
	\prp{2.10.2.} $A_1 \dot{+} A_2$ - лінійний оператор\\
	\proof
	$\forall x \in L_1+L_2: \exists! x_1 \in L_1, \exists! x_2 \in L_2$\\
	$\forall y \in L_1+L_2: \exists! y_1 \in L_1, \exists! y_2 \in L_2$\\
	$\forall \alpha, \beta \in \mathbb{R}$\\
	$(A_1 \dot{+} A_2)(\alpha x + \beta y) = (A_1\dot{+}A_2)((\alpha x_1 + \beta y_1) + (\alpha x_2 + \beta y_2)) = \\ = A_1(\alpha x_1 + \beta y_1) + A_2(\alpha x_2 + \beta y_2) = \alpha A_1 x_1 + \beta A_1 y_1 + \alpha A_2 x_2 \beta A_2 y_2 = \\ = \alpha(A_1 x_1 + A_2 x_2) + \beta(A_1 y_1 + A_2 y_2) = \\ = \alpha(A_1 \dot{+}A_2)(x_1+x_2) + \beta(A_1 \dot{+} A_2)(y_1+y_2) = \alpha(A_1 \dot{+}A_2)x + \beta(A_1 \dot{+}A_2)y$ \qed
	\\
	\textit{Навіщо це все, дізнаємось скоро. А зараз буде невеличкий відступ, до операторів ми ще повернемось} \newpage
	\section{Теорія матриць}
	\subsection{Основні властивості}
	Повертаємось до \textbf{Ex. 2.1.3.(3)}\\
	Задано $A: \mathbb{R}^n \to \mathbb{R}^m$ - лінійний оператор\\
	Нехай $\{ \vec{e}_1, \dots, \vec{e}_n \}$ - базис $\mathbb{R}^n$\\
	\defin{3.1.1. Матрицею лінійного оператора} називають таблицю, що містить розклад кожного елементу $A \vec{e}_1, \dots, A \vec{e}_n$
	\begin{align*}
	\mathbb{A} = \begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \dots & a_{mn} \\
	\end{pmatrix}
	\end{align*}
	Надалі ми будемо називати просто матрицею як прямокутний набір чисел
	\bigline
	А тепер розглянемо одиничний оператор $I: \mathbb{R}^n \to \mathbb{R}^n$ та зафіксуємо $\{\vec{e}_1, \dots, \vec{e}_n\}$ - базис\\
	$I \vec{x} = I \begin{pmatrix}
	x_1 \\ \vdots \\ x_n
	\end{pmatrix} = \begin{pmatrix}
	1 \cdot x_1 + \dots + 0 \cdot x_n \\ \vdots \\ 0 \cdot x_1 + \dots + 1 \cdot x_n
	\end{pmatrix} = \begin{pmatrix}
	1 & \dots & 0 \\
	\vdots & \ddots & \vdots \\
	0 & \dots & 1
	\end{pmatrix} \vec{x} = \mathbb{I} \vec{x}$
	\bigline
	Отримали квадратну \textbf{одиничну матрицю}
	\begin{align*}
	\mathbb{I} = \begin{pmatrix}
	1 & \dots & 0 \\
	\vdots & \ddots & \vdots \\
	0 & \dots & 1
	\end{pmatrix}
	\end{align*}
	\bigline
	І нарешті, розглянемо нульовий оператор $O: \mathbb{R}^n \to \mathbb{R}^n$ та зафіксуємо $\{\vec{e}_1, \dots, \vec{e}_n\}$ - базис\\
	$O \vec{x} = \vec{0}$\\
	Маємо в цьому випадку \textbf{нульову матрицю}
	\begin{align*}
	\mathbb{O} = \begin{pmatrix}
	0 & \dots & 0 \\
	\vdots & \ddots & \vdots \\
	0 & \dots & 0
	\end{pmatrix}
	\end{align*}
	Ми вже задали основні арифметичні дії з лінійними операторами: це додавання та множення на скаляр. Через них ми зможемо отримати арифметичні дії з матрицями\\
	Задані $A,B: \mathbb{R}^n \to \mathbb{R}^m$ - лінійні оператори та їхні матриці $\mathbb{A}, \mathbb{B}$\\
	Створимо $A+B: \mathbb{R}^n \to \mathbb{R}^m$, тоді\\
	$(A+B)\vec{x} = A \vec{x} + B \vec{x} = \mathbb{A} \vec{x} + \mathbb{B} \vec{x} = \begin{pmatrix}
	a_{11}x_1 + \dots + a_{1n} x_n \\
	\vdots \\
	a_{m1}x_1 + \dots + a_{mn} x_n \\
	\end{pmatrix} + \begin{pmatrix}
	b_{11}x_1 + \dots + b_{1n} x_n \\
	\vdots \\
	b_{m1}x_1 + \dots + b_{mn} x_n \\
	\end{pmatrix} = \\
	= \begin{pmatrix}
	(a_{11}+b_{11})x_1 + \dots + (a_{1n}+b_{1n}) x_n \\
	\vdots \\
	(a_{m1} + b_{m1})x_1 + \dots + (a_{mn}+b_{mn}) x_n \\
	\end{pmatrix} = \begin{pmatrix}
	a_{11} + b_{11} & \dots & a_{1n} + b_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} + b_{m1} & \dots & a_{mn} + b_{mn}
	\end{pmatrix} \vec{x}$
	\bigline
	Створимо $\lambda A: \mathbb{R}^n \to \mathbb{R}^m$, тоді\\
	$(\lambda A)\vec{x} = \lambda A \vec{x} = \lambda \mathbb{A} \vec{x} = \lambda \begin{pmatrix}
	a_{11}x_1 + \dots + a_{1n} x_n \\
	\vdots \\
	a_{m1}x_1 + \dots + a_{mn} x_n \\
	\end{pmatrix}
	= \begin{pmatrix}
	\lambda a_{11}x_1 + \dots + \lambda a_{1n} x_n \\
	\vdots \\
	\lambda a_{m1} x_1 + \dots + \lambda a_{mn} x_n \\
	\end{pmatrix} = \begin{pmatrix}
	\lambda a_{11} & \dots & \lambda a_{1n}\\
	\vdots & \ddots & \vdots \\
	\lambda a_{m1} & \dots & \lambda a_{mn}
	\end{pmatrix} \vec{x}$
	\bigline
	Таким чином, ми нарешті змогли створити лінійний простір $Mat(m \times n)$, в якому задано:\\
	1. Операція додавання\\
	$\forall \mathbb{A}, \mathbb{B} \in Mat(m \times n): \mathbb{A} + \mathbb{B} \in Mat(m \times n)$\\
	$\mathbb{A} + \mathbb{B} = \begin{pmatrix}
	a_{11} + b_{11} & \dots & a_{1n} + b_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} + b_{m1} & \dots & a_{mn} + b_{mn}
	\end{pmatrix}$\\
	2. Операція множення на скаляр\\
	$\forall \mathbb{A} \in Mat(n \times m): \forall \lambda \in \mathbb{R}: \lambda \mathbb{A} \in Mat(m \times n)$\\
	$\lambda \mathbb{A} = \begin{pmatrix}
	\lambda a_{11} & \dots & \lambda a_{1n}\\
	\vdots & \ddots & \vdots \\
	\lambda a_{m1} & \dots & \lambda a_{mn}
	\end{pmatrix}$\\
	І виконуються всі 8 аксіом
	\bigline
	Ба більше, в \textbf{Ex. 2.2.5.} ми змогли визначити множення двох матриць таким чином\\
	$\forall \mathbb{B} \in Mat(k \times m), \forall \mathbb{A} \in Mat(m \times n): \mathbb{B} \cdot \mathbb{A} \in Mat(k \times n)$\\
	$\mathbb{B} \cdot \mathbb{A} = \begin{pmatrix}
	b_{11}a_{11}+\dots+b_{1m}a_{m1} & \dots & b_{11}a_{1n}+\dots+b_{1m}a_{mn} \\
	\vdots & \ddots & \vdots \\
	b_{k1}a_{11} + \dots + b_{km}a_{m1} & \dots & b_{k1}a_{1n} + \dots + b_{km}a_{mn} 
	\end{pmatrix}$\\
	Для множення матриці виконуються властивості як в лінійному операторі
	\bigline

	
	\subsection{Кососиметричні функціонали}
	\defin{3.1.1.} Задано $L$ - лінійний простір\\
	\textbf{$n$-лінійним функціоналом} на $L$ називають відображення:\\
	$F: L \times L \times \dots \times L \to \mathbb{R}$\\
	$\forall x_1 \dots, x_n \in L: F(x_1, \dots, x_n) \in \mathbb{R}$\\
	,для якого виконані властивості:
	\begin{align*}
	\forall j = \overline{1,n}: \forall x_1,\dots,x_{j-1}, x_{j+1}, \dots, x_n \in L: \forall x_j^1, x_j^2 \in L: \forall \alpha, \beta \in \mathbb{R}:\\
	F(x_1,\dots,x_{j-1}, \textcolor{red}{\alpha x_j^1 + \beta x_j^2}, x_{j+1}, \dots, x_n) = \\ = \textcolor{red}{\alpha} F(x_1, \dots, x_{j-1}, \textcolor{red}{x_j^1}, x_{j+1}, \dots x_n) + \textcolor{red}{\beta} F(x_1, \dots, x_{j-1}, \textcolor{red}{x_j^2}, x_{j+1}, \dots x_n)
	\end{align*}
	Тобто за кожним аргументом виконується лінійність
	\bigline
	\ex{3.1.2.(1).} $L = \mathbb{R}^3$, $F(\vec{x},\vec{y},\vec{z}) = (\vec{x}, \vec{y}, \vec{z})$\\
	\ex{3.1.2.(2).} $L = \mathbb{R}_n[x]$, $F(f_0,f_1,\dots,f_n) = \displaystyle \int_{\sqrt{e}}^{\pi^{17}} f_0(0)f_1(1)\dots f_n(n) \,dx$
	\bigline
	\defin{3.1.3.} $n$-лінійний функціонал називається \textbf{кососиметричним}, якщо виконується властивість:
	\begin{align*}
	\forall x_1 \dots, x_n \in L: \forall j,k = \overline{1,n}\\
	F(x_1, \dots, \textcolor{red}{x_j}, \dots, \textcolor{red}{x_k}, \dots, x_n) = -F(x_1, \dots, \textcolor{red}{x_k}, \dots, \textcolor{red}{x_j}, \dots, x_n)
	\end{align*}
	Тобто якщо переставити 2 аргументи, то це значення буде однаковим зі знаком мінус
	\bigline
	\ex{3.1.4.} $F(\vec{x},\vec{y},\vec{z}) = (\vec{x}, \vec{y}, \vec{z})$ - кососиметричний
	\bigline
	\th{3.1.5.} $F$ - кососиметричний $\iff$ $\forall x_1 \dots, x_{j-1}, x_{j+1}, \dots, x_{k-1}, x_{k+1}, \dots, x_{n} \\ \in L: \forall y \in L: F(x_1,\dots, x_{j-1}, y, x_{j+1}, \dots, x_{k-1}, y, x_{k+1}, \dots, x_n) = 0$\\
	\proof
	$\boxed{\Rightarrow}$ \textit{чисто за означенням}\bigline
	$\boxed{\Leftarrow}$ Дано: права умова\\
	Нехай $y = x_j + x_k$. Тоді за лінійністю:\\
	$0 = F(x_1,\dots, x_{j-1}, x_j+x_k ,x_{j+1}, \dots, x_{k-1}, x_j+x_k, x_{k+1}, \dots, x_n) \overset{\textrm{по першому } x_j+x_k}{=} \\ = F(x_1,\dots, x_{j-1}, x_j ,x_{j+1}, \dots, x_{k-1}, x_j+x_k, x_{k+1}, \dots, x_n) + \\ + F(x_1,\dots, x_{j-1}, x_k ,x_{j+1}, \dots, x_{k-1}, x_j+x_k, x_{k+1}, \dots, x_n) \overset{\textrm{обидва по другому } x_j+x_k}{=} \\ =
	\underbrace{F(x_1,\dots, x_{j-1}, x_j ,x_{j+1}, \dots, x_{k-1}, x_j, x_{k+1}, \dots, x_n)}_{=0} + \\ + F(x_1,\dots, x_{j-1}, x_j ,x_{j+1}, \dots, x_{k-1}, x_k, x_{k+1}, \dots, x_n) + \\ + F(x_1,\dots, x_{j-1}, x_k ,x_{j+1}, \dots, x_{k-1}, x_j, x_{k+1}, \dots, x_n) + \\ + \underbrace{F(x_1,\dots, x_{j-1}, x_k ,x_{j+1}, \dots, x_{k-1}, x_k, x_{k+1}, \dots, x_n)}_{=0}$\\
	$\Rightarrow F(x_1,\dots, x_j, \dots, x_k, \dots, x_n) = -F(x_1,\dots, x_k, \dots, x_j, \dots, x_n)$\\
	Отже, кососиметричний \qed
	\bigline
	\subsection{Перестановки}
	\defin{3.2.1.} Розглядаємо перші $n$ натуральних чисел $\{1,2,\dots,n\}$\\
	\textbf{Перестановками} назвемо наступні таблиці:
	\begin{align*}
	\tau = \begin{pmatrix}
	1 & 2 & \dots & n \\
	j_1 & j_2 & \dots & j_n
	\end{pmatrix}
	\end{align*}
	Де $j_1, j_2, \dots, j_n = \overline{1,n}$ - всі вони різні\\
	\\
	\rm{3.2.1.} Стовпчики переставляти ми можемо, без жодної різниці
	\bigline
	\textbf{Тотожня перестановка}: $\begin{pmatrix}
	1 & 2 & \dots & n \\
	1 & 2 & \dots & n
	\end{pmatrix} = id$
	\bigline
	\textbf{Обернена перестановка}: $\begin{pmatrix}
	j_1 & j_2 & \dots & j_n \\
	1 & 2 & \dots & n
	\end{pmatrix} = \tau^{-1}$
	\bigline
	\textbf{Композиція (множення)}\\
	$ \tau_1	 = \begin{pmatrix}
	1 & 2 & \dots & n \\
	j_1 & j_2 & \dots & j_n
	\end{pmatrix},$ $ \tau_2 = \begin{pmatrix}
	1 & 2 & \dots & n \\
	k_1 & k_2 & \dots & k_n
	\end{pmatrix}$\\
	Переставимо стовпчики в $\tau_2$ таким чином, щоб $ \tau_2 = \begin{pmatrix}
	j_1 & j_2 & \dots & j_n \\
	k_{j_1} & k_{j_2} & \dots & k_{j_n}
	\end{pmatrix}$\\
	
	$\tau_1 \tau_2 = \begin{pmatrix}
	1 & 2 & \dots & n \\
	j_1 & j_2 & \dots & j_n
	\end{pmatrix} \begin{pmatrix}
	j_1 & j_2 & \dots & j_n \\
	k_{j_1} & k_{j_2} & \dots & k_{j_n}
	\end{pmatrix} = \begin{pmatrix}
	1 & 2 & \dots & n \\
	k_{j_1} & k_{j_2} & \dots & k_{j_n}
	\end{pmatrix}$\\
	\\
	З властивостей композиції відображень маємо: $(\tau_1 \tau_2) \tau_3 = \tau_1 (\tau_2 \tau_3)$\\
	$\tau \cdot id = id \cdot \tau = \tau$\\
	$\tau \tau^{-1} = id$\\
	\\
	Таким чином, множина перестановок утворює групу $S_n$
	\bigline
	\defin{3.2.2. Транспозицією} називають перестановку двох елементів
	\begin{align*}
	\sigma_{j,k} \begin{pmatrix}
	1 & \dots & j & \dots & k & \dots & n \\
	1 & \dots & k & \dots & j & \dots & n
	\end{pmatrix}
	\end{align*}
	Властивість: $\sigma_{j,k}^2 = id$\\
	\\
	Факт: кожна перестановка $\tau$ може бути розкладена в добуток транспозиції (транспозицій сусідів). Цей розклад не є однозначним, але в усіх розкладах зберігається парність/непарність кількості множників\\
	\\
	\ex{3.2.3.} $\tau = \begin{pmatrix}
	1 & 2 & 3 & 4 \\
	3 & 1 & 4 & 2
	\end{pmatrix} = \begin{pmatrix}
	1 & 2 & 3 & 4 \\
	4 & 1 & 3 & 2
	\end{pmatrix} \begin{pmatrix}
	1 & 2 & 3 & 4 \\
	1 & 2 & 4 & 3
	\end{pmatrix} = \begin{pmatrix}
	1 & 2 & 3 & 4 \\
	4 & 1 & 3 & 2
	\end{pmatrix} \sigma_{3,4} \\ = \begin{pmatrix}
	1 & 2 & 3 & 4 \\
	1 & 4 & 3 & 2
	\end{pmatrix} \begin{pmatrix}
	1 & 2 & 3 & 4 \\
	4 & 2 & 3 & 1
	\end{pmatrix} \sigma_{3,4} = \sigma_{2,4}\sigma_{1,4}\sigma_{3,4}$
	\bigline
	\defin{3.2.4.} Перестановка називається \textbf{парною (непарною)}, якщо в її розкладі в добуток транспозиції кількість множників парна (непарна)
	\bigline
	\textbf{Функція парності} на перестановках: $l: S_n \to \{0,1\}$\\
	$l(\tau) = \begin{cases} 0, \tau \textrm{- парна} \\ 1, \tau \textrm{- непарна} \end{cases}$\\
	\bigline
	\defin{3.2.5.} Задано $L$ - лінійний простір, $\dim L = n$ та $F$ - $n$-лінійне кососиметричне відображення. Також задано $\tau = \begin{pmatrix} 1 & 2 & \dots & n \\
	j_1 & j_2 & \dots & j_n
\end{pmatrix}	 \in S_n$ - перестановка\\
\textbf{Дією перестановки на кососиметричну функцію} називається
\begin{align*}
\tau F(x_1,\dots,x_n) = F(x_{j_1},\dots,x_{j_n})
\end{align*}
\\
\lm{3.2.6.} Задано $L$ - лінійний простір, $\dim L = n$ та $F$ - $n$-лінійне кососиметричне відображення. Також задано $\tau = \begin{pmatrix} 1 & 2 & \dots & n \\
	j_1 & j_2 & \dots & j_n
\end{pmatrix}	 \in S_n$ - перестановка\\
Тоді $\tau F(x_1,\dots, x_n) = (-1)^{l(\tau)}F(x_1,\dots,x_n)$\\
\proof
$\tau = \sigma_1 \dots \sigma_k$ - розклад в добуток транспозицій\\
$\sigma_{j,k}F(x_1,\dots,x_{j-1},\textcolor{red}{x_j},x_{j+1},\dots,x_{k-1},\textcolor{red}{x_k},x_{k+1},\dots,x_n) = \\ = F(x_1,\dots,x_{j-1},\textcolor{red}{x_k},x_{j+1},\dots,x_{k-1},\textcolor{red}{x_j},x_{k+1},\dots,x_n) = \\ = -F(x_1,\dots,x_{j-1},x_j,x_{j+1},\dots,x_{k-1},x_k,x_{k+1},\dots,x_n)$\\
Тоді\\
$\tau F(x_1,\dots,x_n) = \sigma_1 \dots \sigma_k F(x_1,\dots,x_n) \boxed{=}$\\
Якщо діяти по черзі, то отримаємо бажану формулу\\
$\boxed{=} (-1)^{l(\tau)}F(x_1,\dots,x_n)$ \qed
\bigline
\\
\\
\textbf{Повертаємось до п. 3.1.}\\
\th{3.1.6. Єдиність $n$-лінійного кососиметричного функціоналу}\\
Задано $L$-лінійний простір, $\dim L = n$ та $F,\Phi$ - $n$-лінійні кососиметричні функціонали $F \not\equiv 0$\\
Тоді $\exists c \in \mathbb{R}: \forall x_1, \dots, x_n \in L: F(x_1,\dots,x_n) = c\Phi(x_1,\dots,x_n)$\\
\\
\rm{3.1.6.(1)} Константа $c$ не залежить від $x_1,\dots,x_n$\\
\rm{3.1.6.(2)} $\dim L = n = $ кількість аргументів\\
\proof
Нехай $n=2$ і задано базис $\{e_1,e_2\}$. Тоді $L=span\{e_1,e_2\}$\\
$\forall x_1 \in L: x_1 = x_{11}e_1 + x_{12}e_2$\\
$\forall x_2 \in L: x_2 = x_{21}e_1 + x_{22}e_2$\\
$\Rightarrow F(x_1,x_2)=F(x_{11}e_1 + x_{12}e_2, x_{21}e_1 + x_{22}e_2) \boxed{=}$\\
Скористаємось лінійністю за кожним аргументом\\
$\boxed{=} x_{11}x_{21}\underset{=0}{F(e_1,e_1)} + x_{11}x_{22}F(e_1,e_2)+x_{12}x_{21}F(e_2,e_1)+x_{12}x_{22}\underset{=0}{F(e_2,e_2)} = \\
= x_{11}x_{22}F(e_1,e_2) - x_{12}x_{21}F(e_1,e_2) = F(e_1,e_2) \underbrace{(x_{11}x_{22}-x_{12}x_{21})}_{\textrm{схожий на визначник 2 порядку}}$\\
Так само $\Phi(x_1,x_2) = \dots = \Phi(e_1,e_2)(x_{11}x_{22}-x_{12}x_{21})$\\
\\
\textbf{Remark.} $F \not\equiv 0 \iff F(e_1,e_2) \neq 0$. Так само і для $\Phi$\\
\\
Оберемо $C = \huge \frac{F(e_1,e_2)}{\Phi(e_1,e_2)}$\\
Тоді $\huge \frac{F(x_1,x_2)}{\Phi(x_1,x_2)} = \frac{F(e_1,e_2)(x_{11}x_{22}-x_{12}x_{21})}{\Phi(e_1,e_2)(x_{11}x_{22}-x_{12}x_{21})} = C$\\
\\
Для інших $n$ це аналогічно, тобто ми довели, але зробимо ту саму справу для $n=3$\\
\\
Нехай $n=3$ і задано базис $\{e_1,e_2,e_3\}$. Тоді $L=span\{e_1,e_2,e_3\}$\\
$\forall x_1 \in L: x_1 = \huge \sum_{j_1=1}^3 x_{1j_1}e_{j_1}$\\
$\forall x_2 \in L: x_2 = \huge \sum_{j_2=1}^3 x_{2j_2}e_{j_2}$\\
$\forall x_3 \in L: x_3 = \huge \sum_{j_1=1}^3 x_{3j_3}e_{j_3}$\\
$\Rightarrow F(x_1,x_2,x_3) = \huge F\left(\sum_{j_1=1}^3 x_{1j_1}e_{j_1}, \sum_{j_2=1}^3 x_{2j_2}e_{j_2}, \sum_{j_1=1}^3 x_{3j_3}e_{j_3}\right) = \\ = \sum_{j_1 = 1}^3 \sum_{j_2 = 1}^3 \sum_{j_3 = 1}^3 x_{1j_1}x_{2j_2}x_{3j_3} F(e_{j_1},e_{j_2},e_{j_3}) \boxed{=}$\\
Залишуться лише 6 доданків, де в $F$ стоять різні елементи за базисом\\
$\boxed{=} x_{11}x_{22}x_{33}F(e_1,e_2,e_3) + x_{11}x_{23}x_{32}F(e_1,e_3,e_2)+x_{12}x_{21}x_{33}F(e_2,e_1,e_3) + x_{12}x_{23}x_{31}F(e_2,e_3,e_1) + x_{13}x_{21}x_{32}F(e_3,e_1,e_2) + x_{13}x_{22}x_{31}F(e_3,e_2,e_1) \boxed{=}$\\
Змінимо в усіх функціоналах порядок елементів базису на $e_1,e_2,e_3$ та винесемо за дужки\\
$\boxed{=} F(e_1,e_2,e_3)\cdot \\ \underbrace{(x_{11}x_{22}x_{33} - x_{11}x_{23}x_{32} - x_{12}x_{21}x_{33} + x_{12}x_{23}x_{31} + x_{13}x_{21}x_{32} - x_{13}x_{22}x_{31})}_{\textrm{схожий на визначник 3 порядку}}$\\
Ну а далі абсолютно аналогічні міркування, тут нам треба було акцентувати увагу на останній вираз\\
\\
І нарешті, загальний випадок, $\dim L = n$, $L = span\{e_1,\dots,e_n\}$\\
$\forall k = 1,\dots,n: \forall x_k \in L: x_k = \huge \sum_{j_k=1}^{n} x_{kj_k}e_{j_k}$\\
$\Rightarrow F(x_1,\dots,x_n) = \huge F\left(\sum_{j_1=1}^{n} x_{1j_1}e_{j_1}, \dots, \sum_{j_n=1}^{n} x_{kn_k}e_{j_n}\right) = \\ = \sum_{j_1 = 1}^n \dots \sum_{j_n = 1}^n \left(x_{1j_1}\dots x_{nj_n} F(e_{j_1},\dots,e_{j_n}) \right) =$\\
Знову ж таки, зникають доданки, де принаймні 2 елементи однакові. Якщо математично:\\
$\exists j_k = j_l \Rightarrow F(e_1,\dots, e_{j_k}, \dots, e_{j_l}, \dots, e_n) = 0$\\
Тоді залишаються доданки, де $j_k \neq j_l$ - різні. Тому буде перестановка\\
$\huge \sum_{\tau} x_{1j_1}x_{2j_2}\dots x_{n j_n} F(e_{j_1},e_{j_2}\dots, e_{j_n}) =$\\
І переставимо елементи базису в природному порядку, завдяки \textbf{Lm. 3.2.6.} \\
$\huge \sum_{\tau \in S_n} x_{1j_1}x_{2j_2}\dots x_{n j_n} \tau F(e_1,e_2\dots, e_n) = \\
= \huge \sum_{\tau \in S_n} x_{1j_1}x_{2j_2}\dots x_{n j_n} (-1)^{l(\tau)} F(e_1,e_2\dots, e_n) = \\
= \huge F(e_1,\dots,e_n) \sum_{\tau \in S_n} (-1)^{l(\tau)} x_{1j_1}x_{2j_2}\dots x_{n j_n}$\\
\\
Позначимо $A(x_1,\dots,x_n) = \huge \sum_{\tau \in S_n} (-1)^{l(\tau)} x_{1j_1}x_{2j_2}\dots x_{n j_n}$\\
$\Rightarrow F(x_1,\dots,x_n) = F(e_1,\dots,e_n)A(x_1,\dots,x_n)$\\
І далі все абсолютно аналогічно \qed
\bigline
\rm{3.1.6.(3).} Якщо $\dim L = n$, але тепер $F$ - $(n+1)$-лінійний кососиметричний функціонал, то $F \equiv 0$
\bigline
\subsection{Визначники n-го порядку}
\defin{3.3.1.} \textbf{Визначником} $n$-го порядку називають відображення $\det : Mat(n \times n) \to \mathbb{R}$, який визначений наступним чином:\\
$F: \mathbb{R}^n \times \dots \times \mathbb{R}^n \to \mathbb{R}$ - $n$-лінійний кососиметричний функціонал\\
$\forall \mathbb{A} \in Mat(n \times n): \mathbb{A} = (\vec{a_1},\dots, \vec{a_n}) \Rightarrow \det \mathbb{A} = F(\vec{a_1},\dots,\vec{a_n})$\\
Додаткова умова на $F$: ми розглядаємо базис одиничних векторів $\{\vec{e_1},\dots, \vec{e_n}\}$, тоді $F(\vec{e_1},\dots,\vec{e_n}) = 1$, або $\det \mathbb{I} = 1$\\
\textit{Це робиться для того, щоб детермінант можна було б знайти однозначним чином}
\bigline
\rm{3.3.1.} З доведення попередньої теореми випливає, що\\
$\det \mathbb{A} = \huge \sum_{\tau \in S_n} (-1)^{l(\tau)} a_{j_1 1}\dots a_{j_n n}$\\
При $\mathbb{A} = \begin{pmatrix}
 a_{11} & \dots & a_{1n} \\
 \vdots & \ddots &\vdots \\
 a_{n1} & \dots & a_{nn}М
\end{pmatrix} = (\vec{a_1}, \dots, \vec{a_n})$
\bigline
\th{3.3.2. Властивості}\\
0) $\det \mathbb{I} = 1$\\
Нехай далі $\mathbb{A} = (\vec{a_1},\dots, \vec{b}+\vec{c}, \dots, \vec{a_n})$
\bigline
1) Нехай $\mathbb{A}_b = (\vec{a}_1, \dots, \vec{b}, \dots, \vec{a_n})$, $\mathbb{A}_c = (\vec{a}_1, \dots, \vec{c}, \dots, \vec{a_n})$\\
та $\mathbb{A}_{b+c} = (\vec{a}_1, \dots, \vec{b}+\vec{c}, \dots, \vec{a_n})$. Тоді\\
$\det \mathbb{A}_{b+c} = \det \mathbb{A}_b + \det \mathbb{A}_{c}$
\bigline
2) Нехай $\mathbb{A}_{\lambda} = (\vec{a}_1, \dots, \lambda \vec{a}_j, \dots, \vec{a}_n)$. Тоді\\
$\det \mathbb{A}_{\lambda} = \lambda \det \mathbb{A}$
\bigline
3) Нехай $\mathbb{A}_{jk} = (\vec{a}_1, \dots, \vec{a}_j, \dots, \vec{a}_k, \dots, \vec{a}_n)$. Тоді \\
$\det \mathbb{A}_{jk} = - \det \mathbb{A}_{kj}$\\
\textit{Всі щойно перелічені властивості випливають з означення детермінанта - $n$-лінійний кососиметричний функціонал}
\bigline
4) Нехай $\mathbb{A}_{j + \lambda k} = (\vec{a_1},\dots, \vec{a_j} + \lambda \vec{a_k}, \dots, \vec{a_n})$. Тоді\\
$\det (\mathbb{A}_{j + \lambda k}) = \det \mathbb{A}$\\
\textit{Випливає з вл. 1,2 та кососиметричності}
\bigline
5) $\det \mathbb{A}^T = \det \mathbb{A}$\\
\proof
$\det \mathbb{A} = \huge \sum_{\tau = \begin{pmatrix} 1 & \dots & n \\ j_1 & \dots & j_n \end{pmatrix}} (-1)^{l(\tau)}a_{j_1 1}\dots a_{j_n n}$\\
$\det \mathbb{A}^T = \huge \sum_{\theta = \begin{pmatrix} 1 & \dots & n \\ k_1 & \dots & k_n \end{pmatrix}} (-1)^{l(\theta)}a_{1 k_1 }\dots a_{n k_n} =$\\
Переставимо множники таким чином, щоб другий індекс був впорядкованим\\
$= \huge \sum_{\theta = \begin{pmatrix} m_1 & \dots & m_n \\ 1 & \dots & n \end{pmatrix}} (-1)^{l(\theta)}a_{m_1 1}\dots a_{m_n n} = \sum_{\theta^{-1} = \begin{pmatrix} 1 & \dots & n\\ m_1 & \dots & m_n \end{pmatrix}} (-1)^{l(\theta^{-1})}a_{m_1 1}\dots a_{m_n n} = \\
= \sum_{\tau = \begin{pmatrix} 1 & \dots & n \\ m_1 & \dots & m_n \end{pmatrix}} (-1)^{l(\tau)}a_{m_1 1}\dots a_{m_n n} = \det \mathbb{A}$ \qed
\subsubsection*{Обчислення - розкриття за рядком}
\defin{3.3.2.} Задана матриця $\mathbb{A} \in Mat(n \times n)$\\
\textbf{Мінором} матриці $\mathbb{A}$ називається визначник $M_{jk}$, який був отриманий в результаті викреслення рядка $j$ та стовпчика $k$\\
\\
6) Розкриття за рядком \\
$\det \mathbb{A} = \huge \sum_{k=1}^n (-1)^{k+j} a_{jk}M_{jk}$\\
\proof
Доведемо розкриття за 1-м рядком. Для решти аналогічно\\
Скористаємось теоремою про єдиність $n$-лінійного кососиметричного функціоналу\\
Розглянемо два функціонала:\\
1) $F(\vec{a_1},\dots, \vec{a_n}) = \det \mathbb{A}$\\
2) $\Phi(\vec{a_1},\dots, \vec{a_n}) = \huge \sum_{k=1}^n (-1)^{k+1} a_{1k}M_{1k} =$\\
\hspace*{-2cm}
$= a_{11} \det \begin{pmatrix} a_{22} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \dots & a_{nn} \end{pmatrix} - a_{12} \det \begin{pmatrix} a_{21} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n1} & \dots & a_{nn} \end{pmatrix} + \dots + (-1)^{n+1} a_{1n} \det \begin{pmatrix} a_{21} & a_{22} & \dots \\ \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \dots \end{pmatrix}$\\
Перевіримо на лінійність за 1-м аргументом: $\vec{a_1} = \vec{b} + \alpha \vec{c}$. Тоді\\
$\Phi(\vec{b}+\alpha \vec{c},\dots,\vec{a_n}) =$ \\
$= (b_1 + \alpha c_1) \det \begin{pmatrix} a_{22} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \dots & a_{nn} \end{pmatrix} - a_{12} \det \begin{pmatrix} b_2 + \alpha c_2 & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ b_n + \alpha c_n & \dots & a_{nn} \end{pmatrix} + \dots + \\ + (-1)^{n+1} a_{1n} \det \begin{pmatrix} b_2 + \alpha c_2 & a_{22} & \dots \\ \vdots & \ddots & \vdots \\ b_n + \alpha c_n & a_{n2} & \dots \end{pmatrix} = $\\
Починаючи з другого доданку, ми використаємо властивості детермінанту\\
$= b_1 \det \begin{pmatrix} a_{22} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \dots & a_{nn} \end{pmatrix} + \alpha c_1 \det \begin{pmatrix} a_{22} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \dots & a_{nn} \end{pmatrix} - \\
- a_{12} \det \begin{pmatrix} b_2 & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ b_n & \dots & a_{nn} \end{pmatrix} - \alpha a_{12} \det \begin{pmatrix} c_2 & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ c_n & \dots & a_{nn} \end{pmatrix} + \dots + \\
+ (-1)^{n+1} a_{1n} \det \begin{pmatrix} b_2 & a_{22} & \dots \\ \vdots & \ddots & \vdots \\ b_n & a_{n2} & \dots \end{pmatrix} + (-1)^{n+1} \alpha a_{1n} \det \begin{pmatrix} c_2 & a_{22} & \dots \\ \vdots & \ddots & \vdots \\ c_n & a_{n2} & \dots \end{pmatrix} =$\\
Перший стовпчик доданків відповідає першому функціоналу, а другий - другому\\
$= \Phi(\vec{b}, \dots, \vec{a_n}) + \alpha \Phi(\vec{c},\dots, \vec{a_n})$\\
Отже, лінійний за 1-м аргументом. Для інших аргументів все аналогічно\\
\\
Перевіримо на кососиметричність для 1-го та 2-го аргументу:\\
$\Phi(\vec{a_2},\vec{a_1},\dots,\vec{a_n}) = $\\
\hspace*{-2cm}
$= a_{12} \det \begin{pmatrix} a_{21} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n1} & \dots & a_{nn} \end{pmatrix} - a_{11} \det \begin{pmatrix} a_{22} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \dots & a_{nn} \end{pmatrix} + \dots + (-1)^{n+1} a_{1n} \det \begin{pmatrix} a_{22} & a_{21} & \dots \\ \vdots & \ddots & \vdots \\ a_{n2} & a_{n1} & \dots \end{pmatrix} = $\\
Перші два доданки ми змінимо місцями. А для решти за властивістю детермінанта, ми змінимо перший та другий стовпчики, зі знаком мінус\\
\hspace*{-2cm}
$= - a_{11} \det \begin{pmatrix} a_{22} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \dots & a_{nn} \end{pmatrix} + a_{12} \det \begin{pmatrix} a_{21} & \dots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n1} & \dots & a_{nn} \end{pmatrix} - \dots - (-1)^{n+1} a_{1n} \det \begin{pmatrix} a_{21} & a_{22} & \dots \\ \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \dots \end{pmatrix} = \\ = -\Phi(\vec{a_1},\vec{a_2},\dots,\vec{a_n})$\\
Отже, кососиметричний за 1-м та 2-м аргументом. Для інших все аналогічно\\
\\
Таким чином, за теоремою про єдиність, обидві функціонали відрізняються на константу\\
Знайдемо $\Phi(\mathbb{I})$ та $F(\mathbb{I})$\\
За визначенням, $F(\mathbb{I}) = 1$\\
$\Phi(\mathbb{I}) =$\\
Залишиться лише єдиний доданок, оскільки решта мають множення на нуль\\
$= 1 \det \begin{pmatrix} 1 & \dots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \dots & 1 \end{pmatrix} = 1$\\
Оскільки $F(\mathbb{I}) = C\cdot \Phi(\mathbb{I})$, то $C = 1$\\
Остаточно, $F(\mathbb{A}) = \Phi(\mathbb{A})$ \qed
\bigline
6) \textbf{Corollary 1}. $\huge\sum_{k=1}^n (-1)^{k+j} b_k M_{jk} = \det \begin{pmatrix}
a_{11} & a_{12} & \dots & a_{1n} \\
\vdots & \vdots & \ddots & \vdots \\
b_1 & b_2 & \dots & b_n \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn} \\
\end{pmatrix}$\\
Елементи $b_1,b_2,\dots,b_n$ знаходяться в $j$-му рядку
\bigline
6) \textbf{Corollary 2}. $\huge \sum_{k=1}^n (-1)^{k+j} a_{mk}M_{jk} = \left[\begin{gathered} 0, m \neq j \\ \det \mathbb{A}, m = j \end{gathered} \right.$\\
\proof
Випадок $m = j$\\
$\huge \sum_{k=1}^n (-1)^{k+j} a_{jk} M_{jk} \overset{\textrm{6)}}{=} \det \mathbb{A}$\\
Випадок $m \neq j$\\
$\huge \sum_{k=1}^n (-1)^{k+j} a_{mk} M_{jk} \overset{\textrm{6) \textbf{Crl 1}}}{=} \det \begin{pmatrix}
a_{11} & a_{12} & \dots & a_{1n} \\
\vdots & \vdots & \ddots & \vdots \\
\underset{=a_{m1}}{a_{j1}} & \underset{=a_{m2}}{a_{j2}} & \dots & \underset{=a_{mn}}{a_{jn}} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \dots & a_{mn} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn}
\end{pmatrix} = 0$\\
За властивістю 5), ми можемо транспонувати матрицю. А за критерієм кососиметричного фукнціоналу, це має бути рівним нулю через два однакових стовпчика\\
Це називається фальшивим розкладом детермінанта за рядком (тобто коли ми беремо не той рядок) \qed
\bigline
5), 6) \textbf{Corollary 1.} Розкладати детермінант можна за елементами за стовпчиком\\
5), 6) \textbf{Corollary 2.} $\huge \sum_{j=1}^n (-1)^{j+k} a_{jm}M_{jk} = \left[\begin{gathered} 0, m \neq k \\ \det \mathbb{A}, m = k \end{gathered} \right.$
\subsubsection*{Використання методу Гауса для обчислення детермінанту}
$\det \mathbb{A} = \det \begin{pmatrix} 
a_{11} & a_{12} & a_{13} & \dots & a_{1n} \\
a_{21} & a_{22} & a_{23} & \dots & a_{2n} \\
a_{31} & a_{32} & a_{33} & \dots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & a_{n3} & \dots & a_{nn} \\
\end{pmatrix} = $\\
Варто змінити рядки місцями, щоб діагональні елементи були ненульовими. А далі мета - зробити перетворення, щоб під діагональними елементами всі вони були нулевими\\
$= (-1)^? \det \begin{pmatrix} 
\tilde{a_{11}} & \tilde{a_{12}} & \tilde{a_{13}} & \dots & \tilde{a_{1n}} \\
0 & \tilde{a_{22}} & \tilde{a_{23}} & \dots & \tilde{a_{2n}} \\
0 & 0 & \tilde{a_{33}} & \dots & \tilde{a_{3n}} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \dots & \tilde{a_{nn}} \\
\end{pmatrix} = $\\
Якщо розкрити за першим стовпчиком, то ми отримаємо добуток діагональних елементів\\
$ = (-1)^? \tilde{a_{11}}\tilde{a_{22}}\tilde{a_{33}}\dots \tilde{a_{nn}}$
\bigline
7) $\det (\mathbb{A} \mathbb{B}) = \det \mathbb{A} \det \mathbb{B}$\\
\proof
Зафіксуємо матрицю $\mathbb{A}$, розглядатимемо 2 функціонала від стовпчика $\mathbb{B}$\\
1) $F(\vec{b_1},\dots, \vec{b_n}) = \det \mathbb{A} \det \mathbb{B}$ - лінійний кососиметричний за означенням\\
$\mathbb{A}\mathbb{B} = \mathbb{A}(\vec{b_1},\dots, \vec{b_n}) = (\mathbb{A}\vec{b_1},\dots, \mathbb{A}\vec{b_n})$\\
2) $\Phi(\vec{b_1},\dots, \vec{b_n}) = \det(\mathbb{A}\mathbb{B})$ - лінійний та кососиметриний теж\\
Таким чином, спрацьовує теорема про єдиність функціоналу: $F(\mathbb{B}) = C \Phi(\mathbb{B})$\\
Але при $\mathbb{B} = \mathbb{I}$ отримаємо, що $C=1$\\
Отже, $F(\mathbb{B}) = \Phi(\mathbb{B})$ \qed
\bigline
8) $\det \begin{pmatrix}
 \mathbb{A} & \vline & \mathbb{C} \\
 \hline
 \mathbb{O} & \vline & \mathbb{B}
\end{pmatrix} = \det \mathbb{A} \det \mathbb{B}$, де \\$\mathbb{A} \in Mat(n \times n)$, $\mathbb{B} \in Mat(k \times k)$, $\mathbb{C} \in Mat(n \times k)$\\
\proof
Розглянемо матриці $\mathbb{B}, \mathbb{C}$\\
І розглянемо два функціонала від стовпчиків матриці $\mathbb{A}$\\
$F(\mathbb{A}) = \det \mathbb{A} \det \mathbb{B}$ - $n$-лінійний кососиметричний функціонал\\
Позначу $\begin{pmatrix}
 \mathbb{A} & \vline & \mathbb{C} \\
 \hline
 \mathbb{O} & \vline & \mathbb{B}
\end{pmatrix} = \mathbb{D}$\\
$\Phi(\mathbb{A}) = \det \mathbb{D}$\\
Якщо змінити стовпчики матриці $\mathbb{A}$ місцями, то зміниться загалом стовпчик блочно трикутної матриці\\
Також нескалдно показати, що виконується властивість лінійності\\
Тому $\Phi(\mathbb{A})$ - $n$-лінійний кососиметричний функціонал\\
Отже, $F(\mathbb{A}) = c \cdot \Phi(\mathbb{A})$\\
Якщо взяти матрицю $\mathbb{I}$, то $\Phi(\mathbb{I}) = \det \mathbb{B}$, якщо розкрити за першим стовпчиком\\
Ну і $F(\mathbb{I}) = \det \mathbb{B}$\\
Отже, отримаємо, що $c = 1$ \qed
\bigline

\subsection{Обернена матриця}
\defin{3.5.1.} Матриця $\mathbb{A}^{-1}$ називається \textbf{оберненою}, якщо
	\begin{align*}
	\mathbb{A}^{-1} \mathbb{A} = \mathbb{A} \mathbb{A}^{-1} = \mathbb{I}
	\end{align*}
,якщо вона існує\\
Водночас матрицю $\mathbb{A}$ називають \textbf{оборотною}
\bigline
\th{3.5.2.} Матриця $\mathbb{A}$ - оборотна $\iff \det \mathbb{A} \neq 0$\\
\proof
$\boxed{\Rightarrow}$ Дано: $\mathbb{A}$ - оборотна\\
Тоді $\exists \mathbb{A}^{-1}: \mathbb{A} \mathbb{A}^{-1} = \mathbb{I}$\\
$\Rightarrow \det (\mathbb{A} \mathbb{A}^{-1}) = \det \mathbb{A} \det \mathbb{A}^{-1} = \det \mathbb{I} = 1$\\
Тому $\det \mathbb{A} \neq 0$\\
Додатково зауважу, що
$\det \mathbb{A}^{-1} = \dfrac{1}{\det \mathbb{A}}$
\bigline
$\boxed{\Leftarrow}$ Дано: $\det \mathbb{A} \neq 0$\\
Спробуємо сконструювати обернену матрицю $\mathbb{A}^{-1}$\\
Для цього розглянемо матрицю $\tilde{\mathbb{A}} = \begin{pmatrix}
A_{11} & A_{12} & \dots & A_{1n} \\
A_{21} & A_{22} & \dots & A_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
A_{n1} & A_{n2} & \dots & A_{nn} \\
\end{pmatrix}$ - \textbf{приєднана матриця}\\
Тут $A_{jk} = (-1)^{j+k}M_{jk}$ - \textbf{алгебраїчне доповнення}\\
Головною мотивацією цієї побудови слугує $6) \textbf{Crl. 2.}$, використання цієї формули\\
Щоб це зробити, нам необхідно розглянути добуток таких матриць\\
$\mathbb{A} \cdot \tilde{\mathbb{A}}^T = \begin{pmatrix}
a_{11} & a_{12} & \dots & a_{1n} \\
a_{21} & a_{22} & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn} \\
\end{pmatrix} \cdot \begin{pmatrix}
A_{11} & A_{21} & \dots & A_{n1} \\
A_{12} & A_{22} & \dots & A_{n2} \\
\vdots & \vdots & \ddots & \vdots \\
A_{1n} & A_{2n} & \dots & A_{nn} \\
\end{pmatrix} = \begin{pmatrix}
\det \mathbb{A} & 0 & \dots & 0 \\
0 & \det \mathbb{A} & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & \det \mathbb{A} \\
\end{pmatrix} \\ = \det \mathbb{A} \mathbb{I}$\\
Отже, $\mathbb{A} \cdot \tilde{\mathbb{A}}^T = \mathbb{A} \mathbb{I}$\\
Але оскільки $\det \mathbb{A} \neq 0$ за умовою, то маємо, що\\
$\mathbb{A} \cdot \dfrac{\tilde{\mathbb{A}}^T}{\det \mathbb{A}} = \mathbb{I}$\\
Якщо встановити $\mathbb{A}^{-1} = \dfrac{1}{\det \mathbb{A}} \tilde{\mathbb{A}}^T$, то отримаємо\\
$\mathbb{A} \mathbb{A}^{-1} = \mathbb{I}$ \qed
\bigline
(додати властивості обернених матриць)

\subsubsection*{Побудова оберненої матриці методом Гауса}
Побудуємо так називаєму \textbf{розширену матрицю}\\
(згодом додам)

\subsection{Матричні алгебраїчні рівняння}
Розглядаються такі рівняння\\
1) $\mathbb{A} X = \mathbb{D}_1$\\
2) $X \mathbb{B} = \mathbb{D}_2$\\
3) $\mathbb{A} X \mathbb{B} = \mathbb{D}_3$\\
Причому $\mathbb{A} \in Mat(n \times n)$ та $\mathbb{B} \in Mat(m \times m)$ - обидва оборотні\\
Також $\mathbb{D}_1 \in Mat(n \times k), \mathbb{D}_2 \in Mat(k \times m), \mathbb{D}_3 \in Mat(n \times m)$\\
Розв'язки\\
1) $\mathbb{A}^{-1} \mathbb{A} X = \mathbb{A}^{-1} \mathbb{D}_1 \Rightarrow X = \mathbb{A}^{-1} \mathbb{D}_1$\\
2) $X \mathbb{B} \mathbb{B}^{-1} = \mathbb{D}_2 \mathbb{B}^{-1} \Rightarrow X = \mathbb{D}_2 \mathbb{B}^{-1}$\\
3) Комбінація 1) та 2) $\Rightarrow X = \mathbb{A}^{-1} \mathbb{D}_3 \mathbb{B}^{-1}$
\bigline
Особливий випадок:\\
$\mathbb{A} \vec{x} = \vec{b}$\\
Причому $\mathbb{A} \in Mat(n \times n)$ - оборотна\\
Тоді $\vec{x} = \mathbb{A}^{-1} \vec{b}$\\
Розпишемо це покоординатно\\
$\begin{pmatrix}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{pmatrix} = \dfrac{1}{\det \mathbb{A}} \begin{pmatrix}
A_{11} & A_{21} & \dots & A_{n1} \\
A_{12} & A_{22} & \dots & A_{n2} \\
\vdots & \vdots & \ddots & \vdots \\
A_{1n} & A_{2n} & \dots & A_{nn} \\
\end{pmatrix} \begin{pmatrix}
b_1 \\ b_2 \\ \vdots \\ b_n
\end{pmatrix}$\\
Зауважимо, що\\
$A_{11}b_1 + A_{21}b_2 + \dots + A_{n1}b_n \overset{\textrm{6) \textbf{Crl 1}}}{=} \det \begin{pmatrix}
b_1  & a_{12} & \dots & a_{1n} \\
b_2 & a_{22} & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
b_n & a_{n2} & \dots & a_{nn}
\end{pmatrix} = \Delta_1$\\
$A_{12}b_1 + A_{22}b_2 + \dots + A_{n2}b_n \overset{\textrm{6) \textbf{Crl 1}}}{=} \det \begin{pmatrix}
a_{11}  & b_1 & \dots & a_{1n} \\
a_{21} & b_2 & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & b_n & \dots & a_{nn}
\end{pmatrix} = \Delta_2$\\
$\vdots$\\
$A_{1n}b_1 + A_{2n}b_2 + \dots + A_{nn}b_n \overset{\textrm{6) \textbf{Crl 1}}}{=} \det \begin{pmatrix}
a_{11}  & a_{12} & \dots & b_1 \\
a_{21} & a_{22} & \dots & b_2 \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & b_n
\end{pmatrix} = \Delta_n$\\
Отримали ось що\\
\th{3.6.1. Метод Крамера}\\
Розв'язком рівняння $\mathbb{A} \vec{x} = \vec{b}$ є\\
$x_1 = \dfrac{\Delta_1}{\det \mathbb{A}}, \dots, x_n = \dfrac{\Delta_n}{\det \mathbb{A}}$

\subsection{Інші теореми}
\th{3.7.1.} Задана матриця $\mathbb{A} = (\vec{a}_1,\dots,\vec{a}_n)$\\
Система $\{\vec{a}_1, \dots, \vec{a}_n\}$ є л.н.з. $\iff \det \mathbb{A} \neq 0$\\
\proof
$\{\vec{a}_1,\dots,\vec{a}_n\}$ - л.н.з. $\iff$ $\{\vec{a}_1,\dots,\vec{a}_n\}$ - базис в $\mathbb{R}^n \iff \mathbb{A} = (\vec{a}_1,\dots,\vec{a}_n)$ задає ізоморфізм $A: \mathbb{R}^n \to \mathbb{R}^n \iff$ має обернений $A^{-1} \iff \det \mathbb{A} \neq 0$ \qed
\bigline
Час повернутись до формули $\det (\mathbb{A} \mathbb{B}) = \det \mathbb{A} \det \mathbb{B}$\\
Розглянемо випадок, коли $\det \mathbb{B} = 0$\\
Тоді звідси $\{\vec{b}_1, \dots, \vec{b}_n\}$ - л.з., зокрема $\{\mathbb{A}\vec{b}_1, \dots, \mathbb{A} \vec{b}_n\}$ - л.з. $\Rightarrow \det \mathbb{A} \mathbb{B} = 0$\\
Тепер ця властивість є коректною
\bigline
Повернімось теперь до $\det \begin{pmatrix}
 \mathbb{A} & \vline & \mathbb{C} \\
 \hline
 \mathbb{O} & \vline & \mathbb{B}
\end{pmatrix} = \det \mathbb{A} \det \mathbb{B}$\\
Знову нехай $\det \mathbb{B} = 0 \Rightarrow \det \mathbb{A} \mathbb{B} = 0$\\
Тоді звідси $\{ \vec{b}_1,\dots,\vec{b}_n \}$ - л.з. А оскільки $\det \mathbb{B} = \det \mathbb{B}^T$, то звідси $\{ \overleftarrow{b}_1,\dots,\overleftarrow{b}_n \}$ - система рядків матриці $\mathbb{B}$ - л.з.\\
А тому рядки блочно трикутної матриці - л.з. $\Rightarrow \det \begin{pmatrix}
 \mathbb{A} & \vline & \mathbb{C} \\
 \hline
 \mathbb{O} & \vline & \mathbb{B}
\end{pmatrix} = 0$

\subsection{Ранг}
\defin{3.8.1.} Задано $A: L \to M$ - лінійний оператор\\
\textbf{Рангом} оператора $A$ називають $\rank A = \dim \Im A$\\
\textbf{Дефектом} оператора $A$ називають $\textrm{def } A = \dim{\ker A}$
\bigline
\subsubsection*{Випадок матриці}
Маємо $A: \mathbb{R}^n \to \mathbb{R}^m$\\
$\Im A = span\{A\vec{e}_1,\dots, A\vec{e}_n\} = span\{\vec{a}_1,\dots,\vec{a}_n\}$\\
Маємо такі означення
\bigline
\defin{3.8.2.(1) Стовпчиковим рангом} матриці $\mathbb{A}$ називають ранг системи стовпчиків
\begin{align*}
\rank_{\textrm{col}} \mathbb{A} = span\{\vec{a}_1,\dots,\vec{a}_n\}
\end{align*}
\defin{3.8.2.(2) Рядковим рангом} матриці $\mathbb{A}$ називають ранг системи рядків
\begin{align*}
\rank_{\textrm{row}} \mathbb{A}
\end{align*}
\defin{3.8.3.} Задана матриця $\mathbb{A} \in Mat(n \times m)$\\
\textbf{Мінором} матриці $\mathbb{A}$ називається її визначник, яка складається з елементів, які стоять на перехресті $i_1,\dots,i_m$ рядків та $j_1,\dots,j_k$ стовпчиків\\
(інше означення мінору)\\
Позначення: $M_{j_1,\dots,j_k}^{i_1,\dots,i_m}$
\bigline
\defin{3.8.4. Мінорним рангом} матриці $\mathbb{A}$ називається розмірність максимального за розмірністю ненульового мінора\\
Позначення: $\rank_{\textrm{minor}} \mathbb{A}$
\bigline
\lm{3.8.5. Про базисний мінор}\\
Задана матриця $\mathbb{A} \in Mat(n \times m)$\\
Відомо, що $M_{j_1,\dots,j_k}^{i_1,\dots,i_k} \neq 0$, але $\forall t = \overline{1,n}, \forall s = \overline{1,m}: M_{j_1,\dots,j_k,t}^{i_1,\dots,i_k,s} = 0$\\
Тоді $\{\vec{a}_{j_1},\dots,\vec{a}_{j_k}\}$ - база системи стовпчиків матриці $\mathbb{A}$\\
Тому $\rank_{\textrm{col}} \mathbb{A} = \rank_{\textrm{minor}} \mathbb{A} = k$\\
\proof
\textit{Згодом додам}
\bigline
\crl{3.8.5.} $\rank_{\textrm{col}} \mathbb{A} = \rank_{\textrm{minor}} \mathbb{A} = \rank_{\textrm{row}} \mathbb{A} = \rank \mathbb{A}$
\bigline
\subsubsection*{Метод обвідних мінорів}
Задана матриця $\mathbb{A} \in Mat(n \times m)$\\
Знайдемо ненульовий мінор порядку $1$ (порядку 2)\\
Нехай це мінор $M_{1,j_1}^{1,i_1}$\\
Шукаємо для нього ненульовий обвідний мінор $M_{1,j_1,j_2}^{1,i_1,i_2}$, тобто той мінор, що містить минулий ненульовий мінор:\\
- якщо для всіх цих таких мінорів буде 0, то тоді $\rank \mathbb{A} = 2$\\
- якщо знайдеться такий мінор, що не буде 0, то розглядаємо $M_{1,j_1,j_2,j_3}^{1,i_1,i_2,i_3}$. І робимо все знову за двома пунктами

\subsection{Системи лінійних рівнянь}
\subsubsection*{Однорідні рівняння}
Розглянемо таке рівняння\\
$\begin{cases}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = 0\\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = 0\\
\dots \\
a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n = 0
\end{cases}
$\\
Це можна записати в матричному вигляді\\
$\mathbb{A} \vec{x} = \vec{0}$\\
\prp{3.9.1.} Множину розв'язків $\mathbb{A} \vec{x} = \vec{0}$ утворює лінійний простір $\ker { \mathbb{A}}$
\bigline
\defin{3.9.2. Фундаментальною системою розв'язків} називають базис лінійного простору розв'язків $\{\vec{f}_1,\dots,\vec{f}_k\}$\\
Загальний розв'язок: $\vec{x}_{g.h.} = c_1 \vec{f}_1 + \dots + c_k \vec{f}_k$ 
\\
\textbf{Повертаємось до п. 2}
\newpage
\addtocontents{toc}{\protect\vspace*{0.5cm}}
\setcounter{section}{2}
\setcounter{subsection}{10}
\subsection{Різні базиси в лінійному просторі, матриця оператора переходу від одного базису до іншого}
Задано $L$ - лінійний простір, в якому два різних базиси: \\ $\{f_1,\dots,f_n\}$, $\{g_1,
\dots,g_n\}$\\
Елемент $x \in L$ можна розкласти двома шляхами:\\
$x = a_1 f_1 + \dots + a_n f_n$\\
$x = b_1 g_1 + \dots + b_n g_n$\\
Вже відомо, що $L \cong \mathbb{R}^n_g$, а з іншого боку, $L \cong \mathbb{R}^n_f$\\
Звідси візьмемо базиси $\{\vec{e_1},\dots, \vec{e_n}\}_g$ та $\{\vec{e_1},\dots, \vec{e_n}\}_f$
\\
\begin{tikzcd}
& L \arrow{ld}[swap]{J_g} \arrow{rd}{J_f} & \\
\mathbb{R}^n_g \arrow{rr}{\mathbb{U}_{g \to f}} & & \mathbb{R}^n_f
\end{tikzcd}\\
Тут лінійні оператори працюють наступним чином:\\
$J_f x = a_1 J_f f_1 + \dots + a_n J_f f_n = a_1 \vec{e_1} + \dots + a_n \vec{e_n} = \begin{pmatrix}
a_1 \\ \dots \\ a_n
\end{pmatrix} = \vec{x}_f$\\
$J_g x = b_1 J_g g_1 + \dots + a_n J_g g_n = b_1 \vec{e_1} + \dots + b_n \vec{e_n} = \begin{pmatrix}
b_1 \\ \dots \\ b_n
\end{pmatrix} = \vec{x}_g $\\
Спробуємо знайти зв'язок\\
Побудуємо матрицю оператора $\mathbb{U}$: (тут $U$ - це якийсь оператор)\\
$U \vec{x}_g = U(b_1 \vec{e_1} + \dots + b_n \vec{e_n}) = b_1 U\vec{e_1} + \dots + b_n U\vec{e_n} =\\ = b_1 J_f J_g^{-1} \vec{e_1} + \dots + b_1 J_f J_g^{-1} \vec{e_n} = b_1 J_f g_1 + \dots + b_n J_f g_n \boxed{=} $\\
Розкладемо $g_1,\dots,g_n$ за базисом $\{f_1,\dots, f_n\}$\\
$g_1 = u_{11}f_1 + \dots + u_{n1}f_n$\\
$\dots$\\
$g_n = u_{1n}f_1 + \dots + u_{nn}f_n$\\
$\boxed{=} \huge \sum_{k=1}^n b_k J_f g_k = \sum_{k=1}^n b_k J_f \left(\sum_{j=1}^n u_{jk} f_j\right) = \sum_{k=1}^n \sum_{j=1}^n b_k u_{jk} \vec{e_j} = \sum_{j=1}^n \left(\sum_{k=1}^n u_{jk} b_k \right) \vec{e_j} = \\ = \begin{pmatrix}
 \huge \sum_{k=1}^n u_{1k} b_k \\ \dots \\ \huge \sum_{k=1}^n u_{nk} b_k
\end{pmatrix} = \mathbb{U} \vec{x_g}$\\
де $\mathbb{U} = \begin{pmatrix}
u_{11} & \dots & u_{1n} \\
\vdots & \ddots & \vdots \\
u_{n1} & \dots & u_{nn}
\end{pmatrix}$
\bigline
\textbf{Алгоритм побудови матриці оператора переходу з одного базису в інший:}\\
- розкладаємо $g_1,\dots,g_n$ за базисом $\{f_1,\dots,f_n\}$\\
- коефіцієнти записуємо в матрицю $\mathbb{U}_{g \to f}$ в стовпчик
\bigline
\textbf{Example 2.11.1.} $L = \mathbb{R}^3$\\
Знайдемо матрицю переходу з базису $\{\vec{f_1},\vec{f_2},\vec{f_3}\}$ в базис $\{\vec{e_1},\vec{e_2}, \vec{e_3}\}$\\
$\vec{f_1} = \begin{pmatrix}
3 \\ -1 \\ 1
\end{pmatrix}, \vec{f_2} = \begin{pmatrix}
1 \\ 2 \\ 3
\end{pmatrix}, \vec{f_3} = \begin{pmatrix}
2 \\ -2 \\ -2
\end{pmatrix}$\\
$\vec{f_1} = 3\vec{e_1} -\vec{e_2} + \vec{e_3}$\\
$\vec{f_2} = \vec{e_1} +2\vec{e_2} + 3\vec{e_3}$\\
$\vec{f_3} = 2\vec{e_1} -2\vec{e_2} -2\vec{e_3}$\\
$\Rightarrow \mathbb{U}_{f \to e} = \begin{pmatrix}
3 & 1 & 2 \\
-1 & 2 & -2 \\
1 & 3 & -2
\end{pmatrix}$
\bigline
А тепер знайдемо вектор $\vec{x}_f$ в старому базисі, якщо в новому базисі $\vec{x}_e = \begin{pmatrix}
 5 \\ 1 \\ 7
\end{pmatrix}$\\
$\vec{x}_e = \mathbb{U}_{f \to e}\vec{x}_f$\\
Звідси випливає, що:\\
$\vec{x}_f = \mathbb{U}^{-1}_{f \to e} \vec{x}_e = \mathbb{U}_{e \to f} \vec{x}_e$\\
Декілька магій обчислень для одержання оберненої матриці:\\
$\mathbb{U}_{e \to f} = \huge \frac{1}{8} \begin{pmatrix}
-2 & -8 & 6 \\
4 & 8 & -4 \\
5 & 8 & -7
\end{pmatrix}$
Тоді, додавши ще магії, отримаємо:\\
$\vec{x}_f = \begin{pmatrix}
3 \\ 0 \\ -2
\end{pmatrix}$
\bigline
\rm{2.11.1.} Знаходження матриці дужа схожа з випадком із пункту 2.7. Тут встановити оператор $A: L_f \to L_g$, в якому для першого старий базис, а в другому відповідно новий, то отримаємо наш поточний випадок
\bigline
\subsection{Матриця лінійного оператору в різних базисах}
Задано $A: L \to M$ - лінійний оператор\\
В $L$ задані два базиси: $\{f_1,\dots, f_n\}$, $\{g_1, \dots, g_n\}$\\
В $M$ задані два базиси: $\{h_1,\dots, h_k\}$, $\{p_1, \dots, p_k\}$\\
Маємо більш складну картину:\\
\begin{tikzcd}
\mathbb{R}^n \arrow{rrr}{\mathbb{A}_{f,h}} \arrow{dd}[swap]{\mathbb{U}_{f \to g}} & & & \mathbb{R}^k \arrow{dd}{\mathbb{U}_{h \to p}} \\
& \arrow{lu}[swap]{J_f} L \arrow{r}{A} \arrow{ld}{J_g} & M \arrow{ru}{J_h} \arrow{rd}[swap]{J_p} \\
\mathbb{R}^n \arrow{rrr}{\mathbb{A}_{g,p}} & & & \mathbb{R}^k
\end{tikzcd}
\\
$\mathbb{A}_{g,p} \vec{x}_g = J_p(A(J_g^{-1} \vec{x}_g)) = J_p(J_h^{-1} \mathbb{A}_{f,h} J_f)(J_g^{-1} \vec{x}_g) = (J_p J_h^{-1}) \mathbb{A}_{f,h} (J_f J_g^{-1})\vec{x}_g = \\
= \mathbb{U}_{h \to p} \mathbb{A}_{f,h} \mathbb{U}_{g \to f} \vec{x}_g$\\
Таким чином, маємо зв'язок:\\
$\mathbb{A}_{g,p} = \mathbb{U}_{h \to p} \mathbb{A}_{f,h} \mathbb{U}_{g \to f}$
\bigline
\textbf{Example 2.12.1.} Нехай задано оператор $A: \mathbb{R}_2[x] \to \mathbb{R}_2[x]$\\
$(Af)(x) = x(f(x+1)-f(x))$\\
Мали базис $\{\underset{=1}{f_0},\underset{=x}{f_1},\underset{=x^2}{f_2}\}$, а стане базис $\{\underset{=x^2+x-1}{g_0},\underset{=x^2-3x+2}{g_1},\underset{=x^2-2x+1}{g_2}\}$\\
Наш випадок\\
\begin{tikzcd}
\mathbb{R}^3_g \arrow{rrr}{\mathbb{A}_{g}} \arrow{dd}[swap]{\mathbb{U}_{g \to f}} & & & \mathbb{R}^3_g \arrow{dd}{\mathbb{U}_{g \to f}} \\
& \arrow{lu}[swap]{J_g} \mathbb{R}_2[x] \arrow{r}{A} \arrow{ld}{J_f} & \mathbb{R}_2[x] \arrow{ru}{J_g} \arrow{rd}[swap]{J_f} \\
\mathbb{R}^3_f \arrow{rrr}{\mathbb{A}_{f}} & & & \mathbb{R}^3_f
\end{tikzcd}
\\
Знайдемо матрицю $\mathbb{A}_g$\\
$Af_0 = 0 = 0f_0 + 0f_1 + 0f_2$\\
$Af_1 = x = 0f_0 + 1f_1 + 0f_2$\\
$Af_2 = 2x^2+x = 0f_0+1f_1+2f_2$\\
$\Rightarrow \mathbb{A}_f = \begin{pmatrix}
0 & 0 & 0 \\
0 & 1 & 1 \\
0 & 0 & 2
\end{pmatrix}$
\\
$g_0 = x^2+x-1 = -1f_0+1f_1+1f_2$\\
$g_1 = x^2-3x+2 = 2f_0-3f_1+1f_2$\\
$g_2 = x^2-2x+1 = 1f_0-2f_1+1f_2$\\
$\Rightarrow \mathbb{U}_{g \to f} = \begin{pmatrix}
-1 & 2 & 1 \\
1 & -3 & -2 \\
1 & 1 & 1
\end{pmatrix}$\\
$\Rightarrow \mathbb{A}_g = \mathbb{U}_{g \to f}^{-1} \mathbb{A}_f \mathbb{U}_{g \to f} = \dots = \begin{pmatrix}
4 & 0 & 1 \\
6 & -2 & 0 \\
-8 & 4 & 1
\end{pmatrix}$\\
Чому не знайти цю матрицю як в п. 2.7.? Тому що базис є взагалі неприємним для розкладання. Враховуючи вигляд оператора, ми отримуємо подвійний біль. В канонічному базису з часом матриці отримуються миттєво, тому цей пункт і існує
\bigline
\iffalse
\ex{} $A: \mathbb{R}^3 \to \mathbb{R}^3$\\
$A \vec{x} = \begin{pmatrix}
x_1 - 3x_2 \\ x_1 + x_2 + 3x_3 \\ 3x_2 + 5x_4
\end{pmatrix}$\\
Із $\mathbb{R}^3$ маємо 2 базиси: $\{\vec{e_1}, \vec{e_2}, \vec{e_3}\}$ та $\{\vec{f_1}, \vec{f_2}, \vec{f_3}\}$\\
$\vec{f_1} = \begin{pmatrix}
3 \\ 2 \\1
\end{pmatrix}, \vec{f_2} = \begin{pmatrix}
2 \\ 1 \\ 1
\end{pmatrix}, \vec{f_3} = \begin{pmatrix}
-1 \\ 2 \\ -2
\end{pmatrix}
$\\
Побудувати матрицю $\mathbb{A}_f$\\
Маємо таку картину\\
\begin{tikzcd}
\mathbb{R}^3_e \arrow{r}{\mathbb{A}_e} & \mathbb{R}^3_e\\
\mathbb{R}^3_f \arrow{u}{\mathbb{U}_{f \to e}} \arrow{r}[swap]{\mathbb{A}_f} & \mathbb{R}^3_f \arrow{u}[swap]{\mathbb{U}_{f \to e}}
\end{tikzcd}\\
$A\vec{e_1} = \begin{pmatrix}
1 \\ 1 \\ 0
\end{pmatrix} = \vec{e_1} + \vec{e_2}$\\
$A\vec{e_1} = \begin{pmatrix}
-3 \\ 1 \\ 3
\end{pmatrix} = -3\vec{e_1} + \vec{e_2} + 3 \vec{e_3}$\\
$A\vec{e_1} = \begin{pmatrix}
0 \\ 3 \\ 5
\end{pmatrix} = 3\vec{e_2} + 5 \vec{e_3}$\\
$\Rightarrow \mathbb{A}_e = \begin{pmatrix}
1 & -3 & 0 \\
1 & 1 & 3 \\
0 & 3 & 5
\end{pmatrix}$
\bigline
$\mathbb{U}_{f \to e} = \begin{pmatrix}
3 & 2 & -1 \\
2 & 1 & 2 \\
1 & 1 & -2
\end{pmatrix}$
\bigline
$\mathbb{A}_f \vec{x}_f = \mathbb{U}^{-1} \mathbb{A}_e \mathbb{U}\vec{x}_f \Rightarrow \mathbb{A}_f = \mathbb{U}^{-1} \mathbb{A}_e \mathbb{U}$\\
А далі вже самостійно
\bigline
\fi

\subsection{Інваріантні підпростори}
\defin{2.13.1.} Задано $A: L \to L$ - лінійний оператор\\
Підпростір $L_1$ називається \textbf{інваріантним} для оператора $A$, якщо
\begin{align*}
\forall x \in L_1: Ax \in L_1
\end{align*}
або пишуть так
\begin{align*}
AL_1 \subset L_1
\end{align*}
\ex{2.13.2.(1)} $L_1 = \textrm{Ker} A$, тому що $\forall x \in \textrm{Ker} A: Ax = 0 \in \textrm{Ker} A$\\
\ex{2.13.2.(2)} $L_1 = \Im A$, тому що $\forall y \in \Im A: Ay \in \Im A$
\bigline
\defin{2.13.3.} Задано $A: L \to L$ - лінійний оператор та $L_1$ - інваріантний підпростір\\
\textbf{Звуженням} оператора $A$ на підпросторі $L_1$ називається лінійний оператор: $A |_{L_1}: L_1 \to L_1$
\begin{align*}
\forall x \in L_1: Ax \in L_1: A |_{L_1}x = Ax
\end{align*}
\rm{2.13.3.} От паралель. Припустимо, що є дві функції:\\
$f(x) = \sin x, x \in \mathbb{R}$\\
$g(x) = \sin x, x \in [0,2\pi]$\\
Функції є \underline{різними} в силу області визначення, хоча закон однаковий. Але навіть не в цьому суть: можна привести 'криву паралель', що $f(x)$ - це $A$, в той час $g(x)$ - це $A |_{L_1}$
\bigline
\ex{2.13.2.(3)} Розглянемо лінійний оператор $A: \mathbb{R}^3 \to \mathbb{R}^3$\\
$A \vec{x} = \begin{pmatrix}
x_1 - x_2 \\ -x_2 + 4x_3 \\ x_3
\end{pmatrix}$\\
Розглянемо $L_1 = XOY$ - цей підпростір буде дійсно інваріантним для $A$, оскільки\\
$\forall \vec{x} \in XOY \Rightarrow \vec{x} = \begin{pmatrix}
x_1 \\ x_2 \\ x_3
\end{pmatrix}: A \vec{x} = \begin{pmatrix}
x_1 - x_2 \\ -x_2 \\ 0
\end{pmatrix} \in XOY$\\
А тому маємо права звузити оператор $A|_{XOY}: XOY \to XOY$\\
$A \vec{x} = \begin{pmatrix}
x_1 - x_2 \\ -x_2
\end{pmatrix}$
\bigline
\rm{2.13.2.} Для кожного оператора може бути безліч інваріантних підпросторів. Власне в \textbf{Ex. 2.13.2.(3)} інваріантними є $\mathbb{R}^2, \{\vec{0}\}, \mathbb{R}^3$
\bigline
\lm{2.13.4.} Задано $A: L \to L$ - лінійний оператор та $L_1, L_2$ - інваріантні підпростори\\
Тоді $L_1 \cap L_2$ та $L_1 + L_2$ - обидва інваріантні підпростори\\
\proof
1) $\forall x \in L_1 \cap L_2 \Rightarrow \begin{cases} x \in L_1 \\ x \in L_2 \end{cases} \Rightarrow \begin{cases} Ax \in L_1 \\ Ax \in L_2 \end{cases} \Rightarrow Ax \in L_1 \cap L_2$\\
\\
2) $\forall x \in L_1 + L_2 \Rightarrow x = \overset{\in L_1}{x_1} + \overset{\in L_2}{x_2} \Rightarrow Ax = \overset{\in L_1}{A x_1} + \overset{\in L_2}{A x_2} \Rightarrow Ax \in L_1+L_2$ \qed
\bigline
\prp{2.13.5.} Задано $A: L \to L$ - лінійний оператор та $L = L_1 \dot{+} L_2$, де $L_1,L_2$ - інваріантні підпростори\\
Тоді $A = A|_{L_1} + A|_{L_2}$\\
\proof
$\forall x \in L: \exists! x_1 \in L_1, \exists! x_2 \in L_2: x = x_1 + x_2$\\
$Ax = Ax_1 + Ax_2 = A|_{L_1}x_1 + A|_{L_2}x_2 = (A|_{L_1}+A|_{L_2})(x_1 + x_2) = (A|_{L_1}+A|_{L_2})x$ \qed
\bigline
\subsection{Матриця оператора в базисі, розширенному з базису в інваріантному просторі}
Задано $A: L \to L$ - лінійний оператор та $L_1$ - інваріантний підпростір, в якому є базис $\{f_1,\dots, f_k\}$\\
Продовжимо його до базису $L$, $\{f_1,\dots,f_k,f_{k+1},\dots,f_n\}$\\
І треба знайти матрицю для розширеного базису\\
$Af_1 \in L_1 \Rightarrow Af_1 = a_{11}f_1 + a_{21}f_2 + \dots + a_{k1}f_k$\\
$\dots$\\
$Af_k \in L_1 \Rightarrow Af_k = a_{1k}f_1 + a_{2k}f_2 + \dots + a_{kk}f_k$\\
$Af_{k+1} \in L $, але $Af_{k+1} \not\in L_1$ $\Rightarrow \\ Af_{k+1} = a_{1,k+1}f_1 + a_{2,k+1}f_2 + \dots + a_{k,k+1}f_k + a_{k+1,k+1}f_{k+1} + \dots + a_{n,k+1}f_n$\\
$\dots$\\
$Af_n \in L $, але $Af_n \not\in L_1$ $\Rightarrow \\ Af_n = a_{1,n}f_1 + a_{2,n}f_2 + \dots + a_{k,n}f_k + a_{k+1,n}f_{k+1} + \dots + a_{n,n}f_n$\\
Тоді матимемо наступний вигляд:\\
$\mathbb{A}_f = \begin{pmatrix}
a_{11} & \dots & a_{1,k} & \vline & a_{1,k+1} & \dots & a_{1, n} \\
a_{21} & \dots & a_{2,k} & \vline & a_{2,k+1} & \dots & a_{2, n} \\
\vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
a_{k,1} & \dots & a_{k,k} & \vline & a_{k,k+1} & \dots & a_{k, n} \\
\hline
0 & \dots & 0 & \vline & a_{k+1,k+1} & \dots & a_{k+1, n} \\
0 & \dots & 0 & \vline & a_{k+2,k+1} &  \dots & a_{k+2, n} \\
\vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
0 & \dots & 0 & \vline & a_{n,k+1} & \dots & a_{n, n} \\
\end{pmatrix}$\\
\\
Тепер розглянемо звужений оператор $A|_{L_1}$ в базисі $\{f_1,\dots,f_k\}$\\
Тоді $A|_{L_1} f_1 = Af_1 , \dots, A|_{L_1}f_k = Af_k$\\
Матриця матиме вигляд:\\
$\mathbb{A}_{|_{L_1}f} = \begin{pmatrix}
a_{11} & \dots & a_{1,k}\\
a_{21} & \dots & a_{2,k}\\
\vdots & \ddots & \vdots\\
a_{k,1} & \dots & a_{k,k}\\
\end{pmatrix}$\\
\\
Можна тоді сказати, що\\
$\mathbb{A}_f = \begin{pmatrix}
 \mathbb{A}_{|_{L_1}f}  & \vline & * \\
 \hline
 \mathbb{O} & \vline & *
\end{pmatrix}$ - остаточна матриця
\bigline
Залишається питання, що буде, якщо є 2 інваріантних підпростори:
\bigline
\\
Задано $A: L \to L$ - лінійний оператор та $L = L_1 \dot{+} L_2$, де $L_1,L_2$ - інваріантні підпростори\\
$\{f_1,\dots,f_k\}$ - базис $L_1$\\
$\{f_{k+1},\dots,f_{n}\}$ - базис $L_2$\\
Тоді $\{f_1,\dots,f_k,f_{k+1},\dots,f_n\}$ - базис $L$\\
Дійсно, якщо $z \in L$, то $\exists! x \in L_1, \exists! y \in L_2: z = x + y$\\
$\Rightarrow z = \alpha_1 f_1 + \dots + \alpha_k f_k + \beta_1 f_{k+1} + \dots + \beta_{n-k}f_n$\\

Побудуємо в цьому базисі матрицю:\\
$A|_{L_1}f_1 = Af_1 = a_{11}f_1 + \dots + a_{k1}f_k$\\
$\dots$\\
$A|_{L_1}f_k = Af_k = a_{1k}f_1 + \dots + a_{kk}f_k$\\
$A|_{L_2}f_{k+1} = Af_{k+1} = a_{k+1,k+1}f_{k+1} + \dots + a_{n,k+1}f_n$\\
$\dots$\\
$A|_{L_2}f_n = Af_n = a_{k+1,n}f_{k+1} + \dots + a_{n,n}f_n$\\
Тоді\\
$\mathbb{A}_f = \begin{pmatrix}
a_{11} & \dots & a_{1,k} & \vline & 0 & \dots & 0 \\
\vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
a_{k,1} & \dots & a_{k,k} & \vline & 0 & \dots & 0 \\
\hline
0 & \dots & 0 & \vline & a_{k+1,k+1} & \dots & a_{k+1, n} \\
\vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
0 & \dots & 0 & \vline & a_{n,k+1} & \dots & a_{n, n} \\
\end{pmatrix} = \begin{pmatrix}
\mathbb{A}_{|_{L_1}}  & \vline & \mathbb{O} \\
 \hline
 \mathbb{O} & \vline & \mathbb{A}_{|_{L_2}}
\end{pmatrix}$
\bigline
Якщо виникне випадок $L = L_1 \dot{+} L_2 \dot{+} L_3$, то\\
$\mathbb{A}_f \begin{pmatrix} 
\mathbb{A}_{|_{L_1}}  & \vline & \mathbb{O} & \vline & \mathbb{O} \\
 \hline
\mathbb{O}  & \vline & \mathbb{A}_{|_{L_2}} & \vline & \mathbb{O} \\
 \hline
\mathbb{O}  & \vline & \mathbb{O} & \vline & \mathbb{A}_{|_{L_3}} \\
\end{pmatrix}$
\bigline
За МІ (або за аналогічними міркуваннями) можна довести і для прямої суми із $n$ підпросторів
\bigline
А тепер розглянемо $L = L_1+L_2$ - вже не пряма сума. Позначу \\ $L_1 \cap L_2 = L_{12}$ (теж інваріантний за \textbf{Lm. 2.13.4.})\\
$\{h_1,\dots, h_n \}$ - базис $L_{12}$\\
Продовжимо його до базисів $L_1$ та $L_2$:\\
$L_1: \{f_1,\dots,f_s, h_1,\dots,h_n \}$\\
$L_2: \{g_1,\dots,g_t, h_1,\dots,h_n \}$\\
Тоді матриця матиме такаий вигляд:\\
$ \mathbb{A} =
  \tikz[baseline=(M.west)]{%
    \node[matrix of math nodes,matrix anchor=west,left delimiter=(,right delimiter=),ampersand replacement=\&] (M) {%
      * \& \mathbb{O} \& \mathbb{O} \\
      * \& \mathbb{A}_{|_{L_{12}}} \& * \\
      \mathbb{O} \& \mathbb{O} \& * \\
    };
    \node[draw,fit=(M-1-1)(M-2-2),inner sep=-1pt] {};
    \node[draw,fit=(M-2-2)(M-3-3),inner sep=-1pt] {};
  }
$\\
Перший квадрат відповідає матриці $\mathbb{A}_{|_{L_{1}}}$, а другий квадрат - $\mathbb{A}_{|_{L_{2}}}$ \bigline
\subsection{Оператор проєктування}
\defin{2.15.1.} Задано $L = L_1 \dot{+} L_2$ - лінійний простір\\
\textbf{Оператором проєктування} на $L_1$ вздовж $L_2$ називають такий оператор $P: L \to L$, що
\begin{align*}
\forall z \in L: z = \underset{\in L_1}{x}+\underset{\in L_2}{y}: P(x+y) = x
\end{align*}

\ex{2.15.2.} $P: \mathbb{R}^2 \to \mathbb{R}^2$ - проєкція вектора на вісь OX - є оператором проєктування
\begin{figure}[H]
\centering
	\begin{tikzpicture}
	\draw[thick, ->] (0,0)--(3,0) node[right] {$x$};
	\draw[thick, ->] (0,0)--(0,2) node[right] {$y$};
	\draw[thick, ->] (0,0)--(2,1) node[anchor = south east] {$\vec{a}$};
	\draw[dashed] (2,1)--(2,0);
	\end{tikzpicture}
\end{figure}

\prp{2.15.2. Властивості}\\
1) $\ker P = L_2$ \hspace{1cm} $\Im P = L_1$\\
2) $P^2 = P$\\
3) $L = \Im P \dot{+} \ker P$\\
\proof
1) $\forall z \in \ker P \iff Pz = x = 0 \iff z = y \in L_2$
$\forall w \in \Im P \iff w = Pz = x \in L_1$
\bigline
2) $P^2z = P(Pz) = Px = P(x+0)=x=Pz$
\bigline
3) \textit{випливає з означення} \qed
\bigline
\prp{2.15.3.} Задано $P: L \to L$ - такий оператор, що $P^2 = P$\\
Тоді $P$ - оператор проєктування\\
\proof
1) Покажемо, що $\Im P \cap \ker P = \{0\}$\\
Дійсно, $\forall z \in (\Im P \cap \ker P) \Rightarrow \begin{cases} z \in \Im P \\ z \in \ker P \end{cases} \Rightarrow \begin{cases} z = Pw \\ Pz = 0 \end{cases}$\\
$\Rightarrow 0 = Pz = P^2z = P(Pz) = Pw = z$
\bigline
2) Доведемо, що $L = \Im P \dot{+} \ker P$\\
Зафіксуємо елемент $w = z - Pz$, $z \in L$\\
Тоді $Pw = Pz - P(Pz) = Pz - P^2z = Pz - Pz = 0 \Rightarrow w \in \ker P$\\
$\Rightarrow z = \underset{\in \Im P}{Pz} + \underset{\in \ker P}{w}$\\
Отже, $\forall z \in L: \exists! x \in \Im P = L_1, \exists! y \in \ker P = L_2: z = x+y$\\
Оскільки $x \in \Im P$, то $x = Pw$\\
$\Rightarrow Pz = P(Pw+y) = P^2 w = Pw = x$\\
Остаточно, $P$ - оператор проєктування \qed
\bigline
\rm{2.15.3.} Задано $P: L \to L$ - оператор проєктування, $L = \underset{=L_1}{\ker P} \dot{+} \underset{=L_2}{\Im P}$\\
$L_1,L_2$ - інваріантні підпростори (це вже було). Тоді $P = P|_{L_1} \dot{+} P|_{L_2}$\\
Дізнаємось, хто ці $P|_{L_1}, P|_{L_2}$\\
$z \in L_1 \Rightarrow z = x = x+0 \Rightarrow P|_{L_1}z = Pz = x = z$\\
Тобто $P|_{L_1} = I$ - тотожній оператор\\
$z \in L_2 \Rightarrow z = y \in \ker P \Rightarrow P|_{L_2} = Pz = Py = 0$\\
Тобто $P|_{L_2} = O$ - нульовий оператор\\
Тобто $P = I \dot{+} O$
\bigline
Тепер покажемо, що є матрицею для оператора $P$\\
Нехай $\{e_1,\dots,e_k\}$ - базис $\Im P$ та $\{e_{k+1},\dots,e_n\}$ - базис $\ker P$\\
$Pe_1 = e_1 \dots Pe_k = e_k$\\
$Pe_{k+1} = 0 \dots Pe_n = 0$\\
Отже, маємо таку матрицю:\\
$\mathbb{P} = \begin{pmatrix}
1 & \dots & 0 & \vline & 0 & \dots & 0 \\
\vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
0 & \dots & 1 & \vline & 0 & \dots & 0 \\
\hline
0 & \dots & 0 & \vline & 0 & \dots & 0 \\
\vdots & \ddots & \vdots & \vline & \vdots & \ddots & \vdots \\
0 & \dots & 0 & \vline & 0 & \dots & 0 \\
\end{pmatrix} = \begin{pmatrix}
\mathbb{I}  & \vline & \mathbb{O} \\
 \hline
\mathbb{O} & \vline & \mathbb{O}
\end{pmatrix}$

\newpage
\setcounter{section}{3}
\setcounter{subsection}{0}
\section{Нова ера з матрицями}
\subsection{Власні числа та власні вектори}
\defin{4.1.1.} Задано $A: L \to L$ - лінійний оператор\\
\textbf{Власним вектором} оператора $A$ називається такий елемент $f \neq 0 \in L$, що:
\begin{align*}
\exists \lambda \in \mathbb{R}: Af = \lambda f
\end{align*}
Водночас число $\lambda$ називається \textbf{власним числом} оператора $A$ \bigline
\rm{4.1.1.} Із означення випливає, що власному вектору відповідає \underline{єдине} власне число. А власному числу може відповідати безліч власних векторів (див. нижче властивість 1)
\bigline
\prp{4.1.2. Властивості власних чисел та векторів}\\
1. Нехай $L_{\lambda}$ - множина всіх власних векторів з цим власним числом $\lambda$, який також містить елемент $0$. Тоді $L_{\lambda}$ - лінійний підпростір\\
2. Нехай $f_1,\dots,f_k$ - власні вектори з попарно різними власними числами. Тоді $\{f_1,\dots,f_k\}$ - л.н.з.\\
3. $f$ - власний вектор оператора $A$ з власним числом $\lambda \iff$ $f$ - власний вектор оператора $(A - \mu I)$ з власним числом $(\lambda - \mu)$\\
4. $f$ - власний вектор з числом $\lambda \iff f \in \textrm{Ker}(A-\lambda I)$\\
Наслідок 4. $L_{\lambda} = \textrm{Ker}(A-\lambda I)$\\
5. Нехай $\{g_1,\dots,g_n\}$ - базис $L$, також $\mathbb{A}_g$ - матриця $A$ для нашого базису.\\
$\lambda$ - власне число $A$ $\iff$ $\lambda$ - власне число $\mathbb{A}_g$\\
$f$ - власний вектор $A$ з власним числом $\lambda$ $\iff$ $J_g f$ - власний вектор $\mathbb{A}_g$\\
6. Нехай $\mathbb{A} \in Mat(n \times n)$\\
$\lambda$ - власне число оператора $\mathbb{A} \iff \det (\mathbb{A} - \lambda \mathbb{I}) = 0$\\

\proof
1. $\forall f_1,f_2 \in L_{\lambda} \Rightarrow Af_1 = \lambda f_1; Af_2 = \lambda f_2; \forall \alpha_1, \alpha_2 \in \mathbb{R}:$\\
$A(\alpha_1 f_1 + \alpha_2 f_2) = \alpha_1 Af_1 + \alpha_2 Af_2 = \alpha_1 \lambda f_1 + \alpha_2 \lambda f_2 = \lambda (\alpha_1 f_1 + \alpha_2 f_2)$\\
Тобто $\alpha_1 f_1 + \alpha_2 f_2 \in L_{\lambda}$. Отже, це є лінійний підпростір
\bigline
2. Доведення за МІ\\
При $k=1$ маємо $\{f_1\}$ - л.н.з. автоматично\\
Припустимо, що $\{f_1,\dots,f_k\}$ - л.н.з.\\
Перевіримо л.н.з. системи $\{f_1,\dots,f_k, f_{k+1}\}$\\
$\alpha_1 f_1 + \dots + \alpha_k f_k + \alpha_{k+1} f_{k+1} = 0$ $(1)$\\
Подіємо оператором на обидві частини. Матимемо:\\
$A(\alpha_1 f_1 + \dots + \alpha_k f_k + \alpha_{k+1} f_{k+1}) = \alpha_1 Af_1 + \dots + \alpha_k Af_k + \alpha_{k+1} Af_{k+1} = \\ = \alpha_1 \lambda_1 f_1 + \dots + \alpha_k \lambda_k f_k + \alpha_{k+1} \lambda_{k+1} f_{k+1}$ - ліва частина. Тоді:\\
$\alpha_1 \lambda_1 f_1 + \dots + \alpha_k \lambda_k f_k + \alpha_{k+1} \lambda_{k+1} f_{k+1} = 0$ $(2)$\\
З першого рівняння маємо: $\alpha_{k+1}f_{k+1} = -\alpha_1 f_1 - \dots - \alpha_k f_k$\\
Його підставимо в друге, тоді отримаємо:\\
$\alpha_1 (\lambda_1 - \lambda_{k+1})f_1 + \dots + \alpha_k (\lambda_k - \lambda_{k+1})f_k = 0 \overset{\textrm{л.н.з.}}{\Rightarrow} \\ \alpha_1(\lambda_1 - \lambda_{k+1})=0, \dots, \alpha_k(\lambda_k - \lambda_{k+1}) = 0$\\
Оскільки власні числа попарно не є рівними, то $\alpha_1 = \dots = \alpha_k = 0$\\
Підставимо отримані значення в рівняння (1). Автоматично отримаємо $\alpha_{k+1} = 0$\\
Остаточно, $\{f_1,\dots,f_k, f_{k+1}\}$ - л.н.з.\\
МІ доведено
\bigline
3. $f$ - власний вектор $A$ з власним числом $\lambda \iff Af = \lambda f \iff \\ \iff Af - \mu f = \lambda f - \mu f \iff Af - \mu If = (\lambda - \mu)f \iff \\ \iff (A-\mu I)f = (\lambda - \mu)f \iff$ $f$ - власний вектор $(A- \mu I)$ з власним число $(\lambda - \mu)$
\bigline
4. $Af = \lambda f \iff Af - \lambda f = 0 \iff Af - \lambda If = 0 \iff \\ \iff (A-\lambda I)f = 0 \iff f \in \textrm{Ker}(A - \lambda I)$\bigline
5. Маємо наступну картину\\
\begin{tikzcd}
L \arrow{r}{A} \arrow{d}[swap]{J_g} & L \arrow{d}{J_g} \\
\mathbb{R}^n \arrow{r}{\mathbb{A}_g} & \mathbb{R}^n
\end{tikzcd}\\
Тоді\\
$Af = J_g^{-1} \mathbb{A}_g J_g f = \lambda f$. Обидві частини множимо на $J_g$\\
$\Rightarrow \mathbb{A}_g (J_g f) = \lambda (J_g f)$
\bigline
6. $\lambda$ - власне число для $\mathbb{A}$ $\iff$ $\exists \vec{f} \neq 0: A \vec{f} = \lambda \vec{f} \iff \\ \iff \vec{f} \in \textrm{Ker} (A-\lambda I) \iff \textrm{Ker} (A-\lambda I) \neq \{0\} \iff \not\exists (\mathbb{A} - \lambda \mathbb{I})^{-1} \iff \det (\mathbb{A} - \lambda \mathbb{I}) = 0$ \qed \bigline
\rm{4.1.2.} З рівняння $\det (\mathbb{A} - \lambda \mathbb{I}) = 0$ знаходимо власні числа. А власні вектори - як розв'язок рівняння $(\mathbb{A} - \lambda \mathbb{I})\vec{f} = \vec{0}$ \bigline
\ex{4.1.3.(1).} Задана матриця $\mathbb{A} = \begin{pmatrix}
4 & -1 & -2 \\
2 & 1 & -2 \\
1 & -1 & 1
\end{pmatrix}$. Знайдемо всі власні числа та власні вектори\\
$\det (\mathbb{A} - \lambda \mathbb{I}) = \det \begin{pmatrix}
4-\lambda & -1 & -2 \\
2 & 1-\lambda & -2 \\
1 & -1 & 1-\lambda
\end{pmatrix} = \dots = -\lambda^3 + 6 \lambda^2 - 11 \lambda + 6 = 0$\\
$\Rightarrow (\lambda - 1)(\lambda -2)(\lambda - 3) = 0$\\
Розглянемо кожне власне число окремо для знаходження власних векторів:\\
$\lambda_1 = 1$\\
$(\mathbb{A} - \lambda_1 \mathbb{I})\vec{f} =\begin{pmatrix}
3 & -1 & -2 \\
2 & 0 & -2 \\
1 & -1 & 0
\end{pmatrix} \vec{f} = \vec{0} \Rightarrow \begin{cases} 2f_1 - 2f_3 = 0 \\ f_1 - f_2 = 0 \end{cases} \Rightarrow f_1 = f_2 = f_3$\\
$\vec{f} = f_1 \begin{pmatrix}
1 \\ 1 \\ 1
\end{pmatrix}$\\
Можемо обрати $\vec{f_1} = \begin{pmatrix}
1 \\ 1 \\ 1
\end{pmatrix}$
\bigline
$\lambda_2 = 2$\\
$(\mathbb{A} - \lambda_2 \mathbb{I})\vec{f} =\begin{pmatrix}
2 & -1 & -2 \\
2 & -1 & -2 \\
1 & -1 & -1
\end{pmatrix} \vec{f} = \vec{0} \Rightarrow \begin{cases} 2f_1 - f_2 - 2f_3 = 0 \\ f_1 - f_2 - f_3 = 0 \end{cases} \Rightarrow \begin{cases} f_1 = f_3 \\ f_2 = 0 \end{cases}$\\
$\vec{f} = f_1 \begin{pmatrix}
1 \\ 0 \\ 1
\end{pmatrix}$\\
Можемо обрати $\vec{f_2} = \begin{pmatrix}
1 \\ 0 \\ 1
\end{pmatrix}$
\bigline
$\lambda_3 = 3$\\
$(\mathbb{A} - \lambda_3 \mathbb{I})\vec{f} =\begin{pmatrix}
1 & -1 & -2 \\
2 & -2 & -2 \\
1 & -1 & -2
\end{pmatrix} \vec{f} = \vec{0} \Rightarrow \begin{cases} 2f_1 - 2f_2 - 2f_3 = 0 \\ f_1 - f_2 - 2f_3 = 0 \end{cases} \Rightarrow \begin{cases} f_1 = f_2 \\ f_3 = 0 \end{cases}$\\
$\vec{f} = f_1 \begin{pmatrix}
1 \\ 1 \\ 0
\end{pmatrix}$\\
Можемо обрати $\vec{f_3} = \begin{pmatrix}
1 \\ 0 \\ 1
\end{pmatrix}$
\bigline
\ex{4.1.3.(2).} Знайдемо власні значення та власні вектори для оператора $A: \mathbb{R}^3 \to \mathbb{R}^3$\\
$A\vec{x} = [\vec{x}, \vec{a}]$\\
Тут $\vec{a}$ - якийсь фіксований вектор\\
За означенням маємо:\\
$A\vec{f} = \lambda \vec{f} \Rightarrow [\vec{f},\vec{a}] = \lambda \vec{f}$\\
Ліворуч маємо вектор, що перпендикулярний до $\vec{f}$, але водночас він дорівнює цьому ж вектору $\vec{f}$, який є домноженим на скаляр.\\
Тоді звідси маємо єдиний випадок рівності, якщо $\lambda = 0$\\
Знайдемо власні вектори:\\
$A\vec{f} = [\vec{f}, \vec{a}] = \vec{0} \Rightarrow \vec{f} || \vec{a}$\\
Таким чином, власні вектори - це вектори $\vec{f}$, що колінеарні $\vec{a}$, з власним числом $\lambda = 0$
\bigline
\defin{4.1.4.} Вираз $\det(\mathbb{A} - \lambda \mathbb{I})$ називається \textbf{характеристичним многочленом}, а саме рівняння називається \textbf{характеристичним рівнянням}
\bigline
\prp{4.1.5.(1)} Задано $A: L \to L$ - лінійний оператор та матриці $\mathbb{A}_f, \mathbb{A}_g$ в різних базисах. Тоді $\det(\mathbb{A}_f - \lambda \mathbb{I}) = \det(\mathbb{A}_g - \lambda \mathbb{I})$\\
\proof
Матриці $\mathbb{A}_f, \mathbb{A}_g$ пов'язані тотожністю:\\
$\mathbb{A}_f = U \mathbb{A}_g U^{-1}$\\
$\Rightarrow \det(\mathbb{A}_f - \lambda I) = \det(U \mathbb{A}_g U^{-1} - \lambda I) = \det(U \mathbb{A}_g U^{-1} - \lambda U U^{-1}) = \\ = \det(U(\mathbb{A}_g-\lambda I)U^{-1}) = \det U \det U^{-1} \det (\mathbb{A}_g - \lambda I) = \det (\mathbb{A}_g - \lambda I)$ \qed
\bigline

\prp{4.1.5.(2)} Характеристичний многочлен має таку формулу: \\ $\det(\mathbb{A} - \lambda \mathbb{I}) = \huge (-1)^n \lambda^n + \sum_{k=1}^{n-1} \left( \sum_{1 \leq j_1 < j_2 < \dots < j_k \leq n} (-1)^{n-k} M_{j_1 \dots j_n}^{j_1 \dots j_n} \right) \lambda^{n-k} + \det \mathbb{A}$\\
\proof
Розглянемо випадок матриці $\mathbb{A}$ розмірності $2 \times 2$\\
$\det (\mathbb{A} - \lambda \mathbb{I}) = \det \begin{pmatrix}
a_{11}-\lambda & a_{12} \\
a_{21} & a_{22} - \lambda
\end{pmatrix} = \lambda^2 - (a_{11}+a_{22})\lambda + \det \mathbb{A}$\\
\\
Далі - матриця $\mathbb{A}$ розмірності $3 \times 3$\\
$\det (\mathbb{A} - \lambda \mathbb{I}) = \det \begin{pmatrix}
a_{11}-\lambda & a_{12} & a_{13} \\
a_{21} & a_{22}-\lambda & a_{23} \\
a_{31} & a_{32} & a_{33}-\lambda \\
\end{pmatrix} = -\lambda^3 + (a_{11}+a_{22}+a_{33})\lambda^2 - \left(\underset{=M_{12}^{12}}{\det \begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix}} - \underset{=M_{13}^{13}}{\det \begin{pmatrix}
a_{11} & a_{13} \\
a_{31} & a_{33}
\end{pmatrix}} + \underset{=M_{23}^{23}}{\det \begin{pmatrix}
a_{22} & a_{23} \\
a_{32} & a_{33}
\end{pmatrix}} \right)\lambda + \det \mathbb{A}$\\
Зауважимо, що коефіцієнт при $\lambda$ є сумою головних мінорів (тобто тих мінорів, де номера рядка та стовпчиків співпадають)
\bigline
І нарешті, матриця $\mathbb{A}$ $n \times n$\\
$\det (\mathbb{A} - \lambda \mathbb{I}) = \det \begin{pmatrix}
a_{11}-\lambda & a_{12} & \dots & a_{1n} \\
a_{21} & a_{22} - \lambda & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn}-\lambda
\end{pmatrix} = $\\
Аналізуємо цю матрицю:\\
- доданок при $\lambda^n$ отримується при множенні тільки елементів головної діагоналі, тобто маємо коефіцієнт $(-1)^n$:\\
$\begin{pmatrix}
a_{11}-\textcolor{red}{\lambda} & a_{12} & \dots & a_{1n} \\
a_{21} & a_{22}-\textcolor{red}{\lambda} & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn}-\textcolor{red}{\lambda}
\end{pmatrix}$\\
- доданок при $\lambda^{n-1}$ отримується при множенні всіх елементів головної діагоналі, крім, можливо, одного, по черзі, тобто маємо коефіцієнт \\ $(-1)^{n-1}(a_{11}+a_{22}+\dots+a_{nn})$\\
$\begin{pmatrix}
\textcolor{red}{a_{11}}-\lambda & a_{12} & \dots & a_{1n} \\
a_{21} & a_{22}-\textcolor{red}{\lambda} & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn}-\textcolor{red}{\lambda}
\end{pmatrix} + \begin{pmatrix}
a_{11}-\textcolor{red}{\lambda} & a_{12} & \dots & a_{1n} \\
a_{21} & \textcolor{red}{a_{22}}-\lambda & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn}-\textcolor{red}{\lambda}
\end{pmatrix} + \dots + \begin{pmatrix}
a_{11}-\textcolor{red}{\lambda} & a_{12} & \dots & a_{1n} \\
a_{21} & a_{22}-\textcolor{red}{\lambda} & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & \textcolor{red}{a_{nn}}-\lambda
\end{pmatrix}$\\
- доданок при $\lambda^{n-2}$ отримується при множенні всіх елементів головної діагоналі, крім, можливо, двох, по черзі\\
Наприклад, розглянемо один із доданків, в якому множимо елементи головної діагоналі з номерами $3,4,\dots,n$, при множенні цих елементів обираємо $\lambda^{n-2}$, залишається цей вираз помножити на \\ 
$\det \begin{pmatrix}
a_{11}-\lambda & a_{12} \\
a_{21} & a_{22}-\lambda
\end{pmatrix} = \lambda^2 - (a_{11}+a_{22})\lambda + \det \begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix}$ \\
Оскільки нам потрібна степінь $n-2$, то ми обираємо останній доданок, що є $M_{12}^{12}$\\
Для інших випадків все аналогічно\\
Загалом маємо коефіцієнт при $\lambda^{n-2}:$\\
$(-1)^{n-2} (M_{12}^{12} + M_{13}^{13} + \dots + M_{1n}^{1n} + M_{23}^{23} + \dots + M_{2n}^{2n} + \dots + M_{n-1,n}^{n-1,n} + M_{nn}^{nn}) = \\ = (-1)^{n-2} \huge \sum_{1 \leq j < m \leq n} M_{jm}^{jm}$ - сума всіх головних мінорів 2-го порядку\\
$\begin{pmatrix}
\textcolor{red}{a_{11}}-\lambda & \textcolor{red}{a_{12}} & a_{13} & \dots & a_{1n} \\
\textcolor{red}{a_{21}} & \textcolor{red}{a_{22}}-\lambda & a_{23} & \dots & a_{2n} \\
a_{31} & a_{32} & a_{33}-\textcolor{red}{\lambda} & \dots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & a_{n3} & \dots & a_{nn}-\textcolor{red}{\lambda}
\end{pmatrix} + 
\begin{pmatrix}
\textcolor{red}{a_{11}}-\lambda & a_{12} & \textcolor{red}{a_{13}} & \dots & a_{1n} \\
a_{21} & a_{22} - \textcolor{red}{\lambda} & a_{23} & \dots & a_{2n} \\
\textcolor{red}{a_{31}} & a_{32} & \textcolor{red}{a_{33}}-\lambda & \dots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & a_{n3} & \dots & a_{nn}-\textcolor{red}{\lambda}
\end{pmatrix} + 
\dots 
+ \begin{pmatrix}
\textcolor{red}{a_{11}}-\lambda & a_{12} & a_{13} & \dots & \textcolor{red}{a_{1n}} \\
a_{21} & a_{22} - \textcolor{red}{\lambda} & a_{23} & \dots & a_{2n} \\
a_{31} & a_{32} & a_{33}-\textcolor{red}{\lambda} & \dots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\textcolor{red}{a_{n1}} & a_{n2} & a_{n3} & \dots & \textcolor{red}{a_{nn}}-\lambda
\end{pmatrix} \\
+ \begin{pmatrix}
a_{11} - \textcolor{red}{\lambda} & a_{12} & a_{13} & \dots & a_{1n} \\
a_{21} & \textcolor{red}{a_{22}} - \lambda & \textcolor{red}{a_{23}} & \dots & a_{2n} \\
a_{31} & \textcolor{red}{a_{32}} & \textcolor{red}{a_{33}}-\lambda & \dots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & a_{n3} & \dots & a_{nn}-\textcolor{red}{\lambda}
\end{pmatrix} +
\dots \\
+ \begin{pmatrix}
a_{11} - \textcolor{red}{\lambda} & a_{12} & a_{13} & \dots & a_{1n} \\
a_{21} & \textcolor{red}{a_{22}} - \lambda & a_{23} & \dots & \textcolor{red}{a_{2n}} \\
a_{31} & a_{32} & a_{33} - \textcolor{red}{\lambda} & \dots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & \textcolor{red}{a_{n2}} & a_{n3} & \dots & \textcolor{red}{a_{nn}}-\lambda
\end{pmatrix} + \dots
$\\
- все аналогічно для $\lambda^{n-3}$, коефіцієнт:\\
$(-1)^{n-3} \huge \sum_{1 \leq j < m < p \leq n} M_{jmp}^{jmp}$ - сума всіх головних мінорів 3-го порядку\\
\dots
- вільний коефіцієнт: $\det \mathbb{A}$\\
$\begin{pmatrix}
\textcolor{red}{a_{11}}-\lambda & \textcolor{red}{a_{12}} & \textcolor{red}{\dots} & \textcolor{red}{a_{1n}} \\
\textcolor{red}{a_{21}} & \textcolor{red}{a_{22}} - \lambda & \textcolor{red}{\dots} & \textcolor{red}{a_{2n}} \\
\textcolor{red}{\vdots} & \textcolor{red}{\vdots} & \textcolor{red}{\ddots} & \textcolor{red}{\vdots} \\
\textcolor{red}{a_{n1}} & \textcolor{red}{a_{n2}} & \textcolor{red}{\dots} & \textcolor{red}{a_{nn}}-\lambda
\end{pmatrix} \rightarrow \det \mathbb{A}$\\
В результаті маємо:\\
$\det (\mathbb{A} - \lambda \mathbb{I}) = \huge (-1)^n \lambda^n + (-1)^{n-1} (a_{11} + a_{22} + \dots + a_{nn}) \lambda^{n-1} + (-1)^{n-2} \sum_{1 \leq j < m \leq n} M_{jm}^{jm} \lambda^{n-2} \\ + (-1)^{n-3} \sum_{1 \leq j < m < p \leq n} M_{jmp}^{jmp} \lambda^{n-3} + \dots + \det \mathbb{A} = \\
= (-1)^n \lambda^n + (-1)^{n+1} \lambda^{n-1} \textrm{tr} A + \sum_{k=2}^{n-1} (-1)^{n-k} \left( \sum_{1 \leq j_1 < j_2 < \dots < j_k} M_{j_1j_2\dots j_k}^{j_1j_2\dots j_k} \lambda^{n-k} \right) + \det \mathbb{A}$
\qed
\\
\bigline
Розглянемо випадок, коли у оператора $A: L \to L$ є $n$ л.н.з. власних векторів $\{f_1,\dots,f_n\}$, $\dim L = n$\\
Тоді $\{f_1,\dots,f_n\}$ - базис\\
$Af_1 = \lambda_1 f_1 = \lambda_1 f_1 + 0 f_2 + \dots + 0 f_n$\\
$Af_2 = \lambda_2 f_2 = 0 f_1 + \lambda_2 f_2 + \dots + 0 f_n$\\
$Af_n = \lambda_n f_n = 0 f_1 + 0 f_2 + \dots + \lambda_n f_n$\\
Тоді матриця оператора $A$ в базисі власних векторів має вигляд:\\
$\mathbb{A}_f = \begin{pmatrix}
\lambda_1 & 0 & \dots & 0 \\
0 & \lambda_2 & \dots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & \lambda_n
\end{pmatrix}$
\bigline
\rm{4.1.6.} Якщо оператор $A$ має $n$ штук різних власних чисел (тобто всі мають кратність 1), то $A$ має $n$ л.н.з. власних векторів
\bigline
В \textbf{Ex. 4.1.3.(1)} мали 3 власних числа: $\lambda_1 = 1, \lambda_2 = 2,\lambda_3 = 3$\\
І також ми мали власні вектори: $\vec{f_1} = \begin{pmatrix}
1 \\ 1 \\ 1
\end{pmatrix}, \vec{f_2} = \begin{pmatrix}
1 \\ 0 \\ 1
\end{pmatrix}, \vec{f_3} = \begin{pmatrix}
1 \\ 1 \\ 0
\end{pmatrix}$\\
Тому $\mathbb{A}_f = \begin{pmatrix}
1 & 0 & 0 \\
0 & 2 & 0 \\
0 & 0 & 3
\end{pmatrix}$\\
Ба більше, ми можемо розкрити деякі цікаві факти\\
\begin{tikzcd}
\mathbb{R}^3_f \arrow{r}{\mathbb{A}_f} \arrow{d}[swap]{U} & \mathbb{R}^3_f \arrow{d}{U} \\
\mathbb{R}^3_e \arrow{r}{A} & \mathbb{R}^3_e
\end{tikzcd}\\
Тут $U = \begin{pmatrix}
1 & 1 & 1 \\
1 & 0 & 1 \\
1 & 1 & 0 \\
\end{pmatrix}$\\
З картинки можна знайти:\\
$A = U \mathbb{A}_f U^{-1}$\\
$A^2 = A\cdot A = U \mathbb{A}_f U^{-1} U \mathbb{A}_f U^{-1} = U \mathbb{A}_f^2 U^{-1}$\\
$A^3 = A^2 \cdot A = U \mathbb{A}^2_f U^{-1} U \mathbb{A}_f U^{-1} = U \mathbb{A}_f^3 U^{-1}$\\
Ну і т.д.
\bigline
\subsection{Приєднаний власний вектор}
\rm{4.2.0.} Надалі ми будемо враховувати комплексні корені з \\ характеристичного полінома, щоб ми мали змогу завжди знайти власні числа
\bigline
Розглянемо особливий випадок, коли $A: L \to L$ має єдиний (взагалі єдиний) л.н.з. власний вектор $f$. Тому й єдине власне число $\lambda$. При цьому $\dim L = n$\\
За вимогою, $\dim (\textrm{Ker}(A - \lambda I)) = \dim L_{\lambda} = 1$\\
Отже, $\dim (\Im (A - \lambda I)) = n-1$\\
Нехай $M=\textrm{Ker}(A-\lambda I) \cap \Im(A-\lambda I)$\\
Оскільки $M \subset \textrm{Ker} (A-\lambda I)$, то $\dim M \leq \dim(\textrm{Ker} (A-\lambda I)) = 1$ \\
Маємо або $\dim M = 0$, або $\dim M = 1$\\
\\
Перед цим доведемо, що $\textrm{Ker}(A - \lambda I), \Im(A-\lambda I)$ - інваріантні підпростори для оператора $A$\\
За вимогою, $\textrm{Ker}(A-\lambda I) = L_{\lambda} = span\{f\}$\\
Тоді $\forall g \in span\{f\}: g = \alpha f \Rightarrow Ag = A(\alpha f) = \alpha Af = (\alpha \lambda) f \\ \Rightarrow Ag \in span\{f\}$\\
Або теж саме, що $\forall g \in (\textrm{Ker}(A - \lambda I)) \Rightarrow Ag \in  \textrm{Ker}(A - \lambda I))$
\bigline
Тоді $\forall y \in \Im(A-\lambda I): \exists x \in L: y = (A-\lambda I)x$\\
$\Rightarrow Ay = A(A-\lambda I)x = (A^2-\lambda A)x = (A-\lambda I)(Ax) \in \Im(A-\lambda I)$\\
Отже, $\textrm{Ker}(A-\lambda I)$ та $\Im(A-\lambda I)$ - два інваріантних підпростори\\
\\
Розглянемо випадок $\dim M = 0$\\
$\Rightarrow M = \textrm{Ker}(A-\lambda I) \cap \Im(A-\lambda I) = \{0\}$\\
Розглянемо $A |_{\textrm{Ker}(A-\lambda I)}: \textrm{Ker}(A-\lambda I) \to \textrm{Ker}(A-\lambda I)$ - звужений оператор\\
У нього є власний вектор $f$\\
Також розглянемо $A |_{\Im(A-\lambda I)}: \Im(A-\lambda I) \to \Im(A-\lambda I)$ - звужений оператор\\
У цього оператора є власне число $\mu$ та власний вектор $g$ (згідно з \textbf{Rm. 4.2.0.}) \\
$Ag = A |_{\Im(A-\lambda I)} g = \mu g$\\
Таким чином, $f \in \textrm{Ker}(A-\lambda I)$ та $g \in \Im(A-\lambda I)$. Оскільки $\ker \{ A-\lambda I \} \cap \Im \{ A - \lambda I \} = \{ 0 \}$, то вони утворюють пряму суму, а водночас $\{f,g\}$ - л.н.з. і є власними векторами для $A$ - суперечність. Отже, $\dim M \neq 0$
\bigline
Залишається єдиний випадок - це $\dim M = 1$\\
$\begin{cases}
M \subset \textrm{Ker}(A-\lambda I)\\
\dim{(\textrm{Ker}(A-\lambda I))} = 1
\end{cases}
\Rightarrow M = \textrm{Ker}(A-\lambda I)$
\bigline
Тоді як можна побачити, $\textrm{Ker}(A-\lambda I) = \textrm{Ker}(A-\lambda I) \cap \Im (A - \lambda I)$, тобто $\textrm{Ker}(A-\lambda I) \subset \Im(A-\lambda I)$\\
$f \in \textrm{Ker}{A- \lambda I} \Rightarrow f \in \Im(A - \lambda I)$\\
Тоді $\exists h \in L: f = (A-\lambda I)h$ \qed \\
Ми прийшли до нового означення
\bigline
\defin{4.2.1.} Задано $A: L \to L$ - лінійний оператор, в якому $f$ - власний вектор з власним числом $\lambda$\\
Елемент $h \in L$ називається \textbf{приєднаним вектором} до власного вектора $f$ (висоти 1), якщо
\begin{align*}
(A-\lambda I)h = f
\end{align*}
\\
\lm{4.2.2.} Задано $A: L \to L$ - лінійний оператор\\
$\exists! f$ - л.н.з. власний вектор та $\dim L > 1$, то для нього $\exists h$ - приєднаний власний вектор\\
\textit{Доведення було перед означенням приєданого вектора}
\bigline
\defin{4.2.1.(2)} Задано $A: L \to L$ - лінійний оператор, в якому $f$ - власний вектор з власним числом $\lambda$\\
Елемент $h^{(k)} \in L$ називається \textbf{приєднаним вектором} до власного вектора $f$ \textbf{висоти $k$}, якщо
\begin{align*}
(A-\lambda I)h^{(k)} = h^{(k-1)}
\end{align*}
\\
\rm{4.2.1.(1)} $h^{(1)} = h$
\bigline
\rm{4.2.1.(2)} Рівняння для приєднаного висоти $k$ можна записати наступним чином:\\
$(A-\lambda I)f = 0$\\
$(A-\lambda I)h^{(1)} = f \Rightarrow (A-\lambda I)^2 h^{(1)} = 0$\\
$(A-\lambda I)h^{(2)} = h \Rightarrow (A-\lambda I)^3 h^{(2)} = 0$\\
$\dots$\\
$(A-\lambda I)^{k+1}h^{(k)} = 0$\\
Остаточно отримаємо таку форму:
\begin{align*}
(A-\lambda I)^{k+1}h^{(k)} = 0
\end{align*}
Взагалі-то кажучи, можна це проілюструвати ось так
\begin{figure}[H]
\centering
\begin{tikzcd}
0 & f \arrow{l}{A-\lambda I} & h^{(1)} \arrow{l}{A-\lambda I} & h^{(2)} \arrow{l}{A-\lambda I} & \dots \arrow{l}{A-\lambda I} & h^{(k)} \arrow{l}{A-\lambda I}
\end{tikzcd}
\end{figure}
\th{4.2.3.} Задано $A: L \to L$ - лінійний оператор, в якому $f$ - власний вектор з власним числом $\lambda$\\
$\{f,h,h^{(2)},\dots,h^{(k)}\}$ - ланцюг власного та приєднаних до нього векторів\\
Тоді $\{f,h,h^{(2)},\dots,h^{(k)}\}$ - л.н.з.\\
\proof
$\alpha_0 f + \alpha_1 h^{(1)} + \dots + \alpha_k h^{(k)} = 0$\\
Подіємо оператором $(A-\lambda I)$ покроково $k$ разів:\\
$(A-\lambda I)(\alpha_0 f + \alpha_1 h^{(1)} + \dots + \alpha_k h^{(k)}) = 0$\\
$\alpha_1 f + \alpha_2 h^{(1)} + \dots + \alpha_k h^{(k-1)} = 0$\\
$\alpha_2 f + \dots + \alpha_k h^{(k-2)} = 0$\\
$\dots$\\
$\alpha_{k-1} f + \alpha_k h^{(1)} = 0$\\
$\alpha_k f = 0$\\
$\Rightarrow \alpha_k = 0 \Rightarrow \alpha_{k-1} = 0 \Rightarrow \dots \Rightarrow \alpha_2 = 0 \Rightarrow \alpha_1 = 0 \Rightarrow \alpha_0 = 0$\\
Отже, л.н.з. \qed
\bigline
\th{4.2.4.} Задано $A: L \to L$ - лінійний оператор, в якому $f$ - єдиний власний вектор з власним числом $\lambda$\\
Тоді в $L$ існує базис з власного вектору $f$ та ланцюга приєднаних до них, тобто\\
$\{f,h,\dots,h^{(n-1)}\}$ - базис, $(\dim L = n)$\\
\proof
Лінійна незалежність вже є. Але єдине, що залишається довести, - це те, що існує ланцюг саме довжини $n$\\
Ми вже в курсі, що $\dim(\textrm{Ker}(A-\lambda I)) = 1$ та $\Im(A-\lambda I) \overset{\textrm{позн.}}{=} L_1$ - інваріантний підпростір для $A$, $\dim L_1 = n-1$\\
Більш того, $\textrm{Ker}(A-\lambda I) \subset \Im(A-\lambda I)$
\bigline
Розглянемо оператор $A_1 = A |_{L_1}: L_1 \to L_1$\\
У нього єдиний л.н.з. власний вектор $f$, оскільки $\ker(A-\lambda I) \subset L_1 \subset L$\\
Тоді $\textrm{Ker}(A_1-\lambda I) = \textrm{Ker}(A-\lambda I) = span\{f\}$\\
Тому $\dim(\textrm{Ker}(A_1 - \lambda I)) = 1 \Rightarrow \dim (\Im(A_1-\lambda I)) = (n-1)-1=n-2$\\
$L_2 = \Im(A_1-\lambda I)$ - інваріантний підпростір для $A_1$, а отже, й для $A$. Доводиться аналогічним чином як на початку цього пункту\\
Зауважимо, що $\forall y \in L_2: \exists z \in L_1: \\ y = (A_1 - \lambda I)z = (A-\lambda I)z \boxed{=}$\\
$z \in L_1 = \Im(A-\lambda I) \Rightarrow \exists x \in L: z = (A-\lambda I)x$\\
$\boxed{=} (A-\lambda I)^2 x$\\
Отримали, що $\Im(A_1 - \lambda I) = \Im(A-\lambda I)^2 = L_2$, $\dim L_2 = n-2$
\bigline
Розглянемо оператор $A_2 = A |_{L_2}: L_2 \to L_2$\\
У нього єдиний л.н.з. власний вектор $f$ за аналогічними міркуваннями\\
Тоді $\textrm{Ker}(A_2-\lambda I) = \textrm{Ker}(A-\lambda I) = span\{f\}$\\
Тому $\dim(\textrm{Ker}(A_2 - \lambda I)) = 1 \Rightarrow \dim (\Im(A_2-\lambda I)) = (n-2)-1=n-3$\\
$L_3 = \Im(A_2-\lambda I)$ - інваріантний підпростір для $A_2$, а отже, й для $A$\\
Отримаємо, що $\dim (A_2 - \lambda I) = \dim (A-\lambda I)^3$\\
І знову теж саме...
\bigline
Тоді остаточно, $L \supset \underset{=\Im(A-\lambda I)}{L_1} \supset \underset{=\Im(A-\lambda I)^2}{L_2} \supset \dots \supset \underset{=\Im(A-\lambda I)^{n-1}}{L_{n-1}} \supset \{0\}$\\
Зауважимо,\\
$\begin{cases}
\dim (\Im(A-\lambda I)^{n-1}) = 1\\
\dim (\textrm{Ker} (A-\lambda I)) = 1\\
\textrm{Ker} (A-\lambda I) \subset \Im(A-\lambda I)^{n-1}
\end{cases} \Rightarrow \Im(A-\lambda I)^{n-1} = \textrm{Ker}(A-\lambda I)
$\\
Знайдемо ланцюг власного та приєднаного векторів довжини $n$\\
$f$ - власний\\
$f \in L_{n-1} \Rightarrow f \in L_1 \Rightarrow \exists h^{(1)} \in L_1 \Rightarrow h^{(1)} \in L: (A-\lambda I)h = f$\\
$f \in L_{n-1} \Rightarrow f \in L_2 \Rightarrow \exists h^{(2)} \in L_2 \Rightarrow h^{(2)} \in L: (A-\lambda I)^2 h^{(2)} = f$\\
$\dots$\\
$f \in L_{n-1} \Rightarrow \exists h^{(n-1)} \in L_{n-1} \Rightarrow h^{(n-1)} \in L: (A-\lambda I)^{(n-1)}h^{(n-1)} = f$
 \qed
\\
\bigline
Тоді можемо отримати матрицю оператора $A: L \to L$ в базисі $\{f,h,h^{(2)},\dots,h^{(k)}\}$\\
$(A-\lambda I)f = 0$\\
$(A-\lambda I)h = f = f + 0h + \dots + 0h^{(k)}$\\
$(A-\lambda I)h^{(2)} = h = 0f + h + \dots + 0h^{(k)}$\\
$\dots$\\
$(A-\lambda I)h^{(k)} = h^{(k-1)} = 0f + 0h + \dots + h^{(k-1)} + 0h^{(k)}$\\
$(\mathbb{A}- \lambda \mathbb{I}) = \begin{pmatrix}
0 & 1 & 0 & 0 & \dots & 0 \\
0 & 0 & 1 & 0 & \dots & 0 \\
0 & 0 & 0 & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \dots & 1 \\
0 & 0 & 0 & 0 & \dots & 0 \\
\end{pmatrix}$\\
Ну а звідси випливає, що:\\
$\mathbb{A} = (\mathbb{A} - \lambda \mathbb{I}) + \lambda \mathbb{I}$\\
Тут $\lambda \mathbb{I} = \begin{pmatrix}
\lambda & \dots & 0\\
\vdots & \ddots & \vdots\\
0 & \dots & \lambda
\end{pmatrix}$\\
$\Rightarrow \mathbb{A} = \begin{pmatrix}
\lambda & 1 & 0 & 0 & \dots & 0 \\
0 & \lambda & 1 & 0 & \dots & 0 \\
0 & 0 & \lambda & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \dots & 1 \\
0 & 0 & 0 & 0 & \dots & \lambda \\
\end{pmatrix} \overset{\textrm{позн.}}{=} J(\lambda)$\\
Таку матрицю називають \textbf{клітиною Жордана}

\subsection{Теорема Жордана}
\th{4.3.1. Теорема Жордана}\\
Задано $A: L \to L$ - лінійний оператор\\
Тоді в $L$ є базис з власних та приєднаних векторів\\
$\{f_1, h_1^1, \dots ,h_1^{k_1}, \hspace{1cm} f_2, h_2^1, \dots, h_2^{k_2}, \hspace{1cm} \dots \hspace{1cm} f_m, h_m^{1}, \dots, h_m^{k_m}\}$\\
\proofMI
Індукція буде за $\dim L$\\
$A: L \to L$ - у нього існує власне число $\lambda$\\
Розглянемо оператор $B = A -\lambda I: L \to L$\\
База індукції: $\dim L = 1$\\
Тоді $L = span\{f\}$, $Af \in L \Rightarrow Af = \alpha f \Rightarrow f$ - власний вектор
\\
\\
Ще одна база: $\dim L = 2$\\
Тоді $\exists f: Af = \lambda f$\\
Далі є два варіанти:\\
1) $\exists f_2$ - другий власний вектор. Тоді $\{f_1,f_2\}$ - базис одразу\\
2) $f$ - єдиний власний вектор, тоді за попередньою теоремою, $\exists h$ - приєднаний. Тоді $\{f_1,h_1\}$ - базис\\
\\
Крок індукції: нехай твердження виконується для $\dim L < n$\\
Доведемо для $\dim L = n$\\
$B = A-\lambda I: L \to L$, $\lambda$ - власне число $\Rightarrow \ker B \neq \{0\}$\\
$\Rightarrow \dim (\Im B) < n$\\
Покажемо, що $\Im B$ - інваріантний для $A$\\
$\forall y \in \Im B = \Im (A-\lambda I): \exists x \in L: y = (A-\lambda I)x$\\
Тоді $Ay = A(A-\lambda I)x = (A-\lambda I)(Ax) \in \Im (A-\lambda I)$\\
Або $Ay \in \Im B$\\
За припущенням індукції, в $\Im B$ існує базис з власних та приєднаних для $A |_{\Im B}: \Im B\to \Im B$\\
$ \lambda: \begin{cases}
\begin{tikzcd}
0 & f_1 \arrow{l}{B} & h_1^1 \arrow{l}{B} & \dots \arrow{l}{B} & h_1^{k_1} \arrow{l}{B}
\end{tikzcd}\\
\vdots \\
\begin{tikzcd}
0 & f_s \arrow{l}{B} & h_s^1 \arrow{l}{B} & \dots \arrow{l}{B} & h_s^{k_s} \arrow{l}{B}
\end{tikzcd}
\end{cases}
\\
\lambda_2: f_{s+1}, h_{s+1}^1,\dots,h_{s+1}^{k_{s+1}}\\
\vdots\\
\lambda_m: f_{p}, h_{p}^1,\dots,h_{p}^{k_{p}}\\
$
Це все - базис в $\Im B$\\
Розширимо його до базису $L$\\
$ \lambda: \begin{cases}
\begin{tikzcd}
0 & f_1 \arrow{l}{B} & h_1^1 \arrow{l}{B} & \dots \arrow{l}{B} & h_1^{k_1} \arrow{l}{B} & h_1^{k_1+1} \arrow{l}{B}
\end{tikzcd}\\
\vdots \\
\begin{tikzcd}
0 & f_s \arrow{l}{B} & h_s^1 \arrow{l}{B} & \dots \arrow{l}{B} & h_s^{k_s} \arrow{l}{B} & h_s^{k_s+1} \arrow{l}{B}
\end{tikzcd}
\end{cases}
\\
\textrm{А тут не продовжуються ланцюги}
\\
\lambda_2: f_{s+1}, h_{s+1}^1,\dots,h_{s+1}^{k_{s+1}}\\
\vdots\\
\lambda_m: f_{p}, h_{p}^1,\dots,h_{p}^{k_{p}}\\
$
До того ж, є ще додатково $g_1,\dots,g_r$ - л.н.з., що належать $\ker (A-\lambda I)$\\
Все це лише 'заяви'. Нам треба визначитись, чи буде ОСЬ ЦЯ МАХИНА базисом $L$\\
\\
Розглянемо лінійні підпростори $L_j = \{f_j,h_j^1, \dots, h_j^{k_j} \}$ в $\Im B$\\
Покажемо, що $L_j$ - інваріантний для $A$ та $B$\\
$f_j$ - власне число $\lambda_j$, а $h_j^1, \dots, h_j^{k_j}$ - ланцюг приєднаних\\
$(A-\lambda_j I)h_j^q = h_j^{q-1}$\\
$(A-\lambda_j I)f_j = 0$\\
Тому\\
$Af_j = \lambda_j f_j$ \\
$Ah_j^q = h_j^{q-1}+\lambda_j h_j^q$\\
$\Rightarrow Bf_j = (A-\lambda I)f_j = (A-\lambda_j I + (\lambda_j-\lambda)I)f_j = (A-\lambda_j I)f_j + (\lambda_j - \lambda)f_j$\\
$\Rightarrow Bh_j^q = (A-\lambda_j I + (\lambda_j - \lambda)I)h_j^q = h_j^{q-1} + (\lambda_j-\lambda)h_j^q$\\
Отримані елементи, що подіяні оператором $A$ та $B$, належать $L_j$. Отже, інваріантні\\
\\
Покажемо, що $L_j \cap L_i = \{0\}, j \neq i$\\
$z \in L_j \cap L_i \Rightarrow z = \left[\begin{gathered} z^0_j f_j + z^1_j h^1_j + \dots + z_j^{k_j} h_j^{k_j} \\ z_i^0f_i + z_i^1 h_i^1 + \dots + z_i^{k_i} h_i^{k_i} \end{gathered} \right.$\\
$\Rightarrow z^0_j f_j + z^1_j h^1_j + \dots + z_j^{k_j} h_j^{k_j} + (-z_i^0)f_i + (-z_i^1) h_i^1 + \dots + (-z_i^{k_i}) h_i^{k_i} = 0$\\
За побудовою, $\{L_j, L_i\}$ - елементи з базису $\Im B$, тому є л.н.з.\\
$\Rightarrow z^0_j = z^1_j = \dots = z^{k_j}_j = z^0_i = z^1_i = \dots = z^{k_i}_i = 0$\\
Отже, $z = 0$, а тому $L_j \cap L_i = \{0\}$\\
Таким чином, отримали, що $\Im B = L_1 \dot{+} L_2 \dot{+} \dots \dot{+} L_p$ і кожна з цих множин інваріантна $\Im B$\\
\\
Тепер розглянемо оператор $B|_{L_j}$, тут $j \in \{s+1,\dots,p\}$\\
Покажемо, що $\ker B|_{L_j} = \{0\}$\\
$z \in \ker B|_{L_j} \Rightarrow B|_{L_j}z = 0 \Rightarrow B|_{\Im B}z = 0$\\
Отже, $z \in  \ker B|_{L_j}$ та $z \in L_j \Rightarrow z = \alpha_1 f_1 + \dots + \alpha_s f$\\
А елемент $z \in L_1 \dot{+} \dots \dot{+} L_s$\\
Оскільки $L_j \cap (L_1 \dot{+} \dots \dot{+} L_s) = \{0\}$, то $z = 0$\\
Остаточно, $\ker B|_{L_j} = \{0\}$ для оператора $B|_{L_j}: L_j \to L_j$\\
А це - гарант на існування оберненого оператора та $\Im B|_{L_j} = L_j$\\
\\
$h_{j}^{k_j} = B|_{L_j} B^{-1}|_{L_j} h_{j}^{k_j} = B|_{L_j}z_j^{k_j}$\\
$\dots$\\
$h_{j}^{q} = B|_{L_j} B^{-1}|_{L_j} h_{j}^{q} = B|_{L_j}z_j^{q}$\\
Всі елементи з ланцюгів $\{f_j, h_j^1, \dots, h_j^{k_j}\}$ є прообразами елментів з підпросторів $L_j$\\
Тому ланцюги не мають продовження за межами $\Im B$\\
\\
Розглянемо окремо $L_j$, $j = \{1,\dots,s\}$\\
$f_j = Bh^1_j, \dots, h_j^{k_j-1} = Bh_j^{k_j}$\\
$\ker B|_{L_j} = span\{f_j\} \Rightarrow \dim(\ker B|_{L_j}) = 1$\\
$\Rightarrow \dim(\Im B|_{L_j}) = \dim L_j - 1 = k_j$\\
Тому $h_j^{k_j} = Bh_j^{k_j + 1}$, де $h_j^{k_j+1} \not\in L_j$\\
Тобто продовження ланцюга все ж таки існує. Ба більше, \\ 
$\ker B|_{\Im B} = span\{f_1,\dots,f_s\}$\\
$\dim (\ker B|_{\Im B}) = s$\\
$\ker B \supset \ker B|_{\Im B}$\\
Тому $\ker B|_{\Im B} = span\{f_1,\dots,f_s, g_1 \dots, g_r\}$ - базис $\ker B$\\
Ми це лише побудували елементи\\
\\
Доведемо тепер, що все ПОБУДОВАНЕ є базисом, тобто\\
$\{f_1,h_1^1,\dots,h_1^{k_1},h_1^{k_1+1}, \hspace{0.5cm} \dots \hspace{0.5cm} f_s, h_s^{1}, \dots,h_s^{k_s}, h_s^{k_s+1}, \\ f_{s+1}, h_{s+1}^1, \dots, h_{s+1}^{k_{s+1}} \hspace{0.5cm} \dots \hspace{0.5cm} f_{p}, h_{p}^1, \dots, h_{p}^{k_p}, \hspace{0.5cm} g_1, \dots, g_r\}$\\
\\
I. Перевіримо на л.н.з.\\
$\alpha_1^0 f_1 + \alpha_1^1 h_1^1 + \dots + \alpha_1^{k_1}h_1^{k_1} + \alpha_1^{k_1+1} h_1^{k_1+1} + \dots \\
+\alpha_s^0 f_s + \alpha_s^1 h_s^1 + \dots + \alpha_s^{k_s}h_s^{k_s} + \alpha_s^{k_s+1} h_s^{k_s+1} + \\
+\alpha_{s+1}^0 f_{s+1} + \alpha_{s+1}^1 h_{s+1}^1 + \dots + \alpha_{s+1}^{k_{s+1}}h_{s+1}^{k_{s+1}} + \dots \\
+\alpha_p^0 f_p + \alpha_p^1 h_p^1 + \dots + \alpha_p^{k_p}h_p^{k_p} + \\
+\beta_1 g_1 + \dots + \beta_r g_r = 0$\\
Подіємо це чудо оператором $B = A - \lambda I$\\

$\alpha_1^0 0 + \alpha_1^1 f_1 + \dots + \alpha_1^{k_1}h_1^{k_1-1} + \alpha_1^{k_1+1} h_1^{k_1} + \dots \\
+\alpha_s^0 0 + \alpha_s^1 f_1 + \dots + \alpha_s^{k_s}h_s^{k_s-1} + \alpha_s^{k_s+1} h_s^{k_s} + \\
+\tilde{\alpha_{s+1}^0} f_{s+1} + \tilde{\alpha_{s+1}^1} h_{s+1}^1 + \dots + \tilde{\alpha_{s+1}^{k_{s+1}}} h_{s+1}^{k_{s+1}} + \dots \\
+\tilde{\alpha_p^0} f_p + \tilde{\alpha_p^1} h_p^1 + \dots + \tilde{\alpha_p^{k_p}}h_p^{k_p} + \\
+ 0 = 0$\\
Оскільки $\{f_1, h_1^1, \dots ,h_1^{k_1}, \hspace{0.5cm} f_2, h_2^1, \dots, h_2^{k_2}, \hspace{0.5cm} \dots \hspace{0.5cm} f_p, h_p^{1}, \dots, h_p^{k_p}\}$ - базиси $\Im B$, то звідси\\
$\alpha_1^1 = \dots = \alpha_1^{k_1} = \alpha_1^{k_1+1} = \dots = \alpha_s^1 = \dots = \alpha_s^{k_1} = \alpha_s^{k_1+1} = \\
=\tilde{\alpha_{s+1}^0} = \tilde{\alpha_{s+1}^1} = \dots = \tilde{\alpha_{s+1}^{k_{s+1}}} = \dots = \tilde{\alpha_p^0} = \tilde{\alpha_p^1} = \dots = \tilde{\alpha_p^{k_p}} = 0$\\
Оскільки $\exists B^{-1}|_{L_{s+1}}, \dots, \exists B^{-1}|_{L_{p}}$, то
$\alpha_{s+1}^0 = \alpha_{s+1}^1 = \dots = \alpha_{s+1}^{k_{s+1}} = \dots = \alpha_{p}^0 = \alpha_{p}^1 = \dots = \alpha_{p}^{k_{p}} = 0$\\
Отримані нулі підставимо в початкову рівність:\\
$\alpha_1^0 f_1 + \dots + \alpha_s^0 f_s + \beta_1 g_1 + \dots + \beta_r g_r = 0$\\
Оскільки $\{f_1, \dots, f_s, g_1, \dots, g_r\}$ - базис ядра, то тоді\\
$\alpha_1^0 = \dots = \alpha_s^0 = \beta_1 = \dots = \beta_r = 0$\\
Нарешті, доведено л.н.з.\\
\\
II. Перевіримо на повноту\\
$\forall z \in L: Bz \in \Im B \Rightarrow \\ Bz = \alpha_1^0 f_1 + \alpha_1^1 h_1^1 + \dots + \alpha_1^{k_1}h_1^{k_1} + \dots + \alpha_s^0 f_s + \alpha_s^1 h_s^1 + \dots + \alpha_s^{k_s} h_s^{k_s} + \\ + \alpha_{s+1}^0 f_1 + \alpha_{s+1}^1 h_{s+1}^1 + \dots + \alpha_{s+1}^{k_{s+1}}h_{s+1}^{k_{s+1}} + \dots + \alpha_p^0 f_p + \alpha_p^1 h_p^1 + \dots + \alpha_p^{k_p}h_p^{k_p}$\\
Розглянемо елемент $w \in L$:\\
$w = \alpha_1^0 h_1^1 + \alpha_1^1 h_1^2 + \dots + \alpha_1^{k_1}h_1^{k_1+1} + \dots + \alpha_s^0 h_s^1 + \alpha_s^1 h_s^2 + \dots + \alpha_s^{k_s}h_s^{k_s+1} + \\
+ \tilde{\alpha_{s+1}^0} f_{s+1} + \tilde{\alpha_{s+1}^1} h_{s+1}^1 + \dots + \tilde{\alpha_{s+1}^{k_{s+1}}} h_{s+1}^{k_{s+1}} + \dots + \\
+ \tilde{\alpha_{p}^0} f_{p} + \tilde{\alpha_{p}^1} h_{p}^1 + \dots + \tilde{\alpha_{p}^{k_{p}}} h_{p}^{k_{p}}$\\
Спеціально ми так підібрали, щоб подіявши оператором $B$, ми могли отримати елемент $z$\\
Тут $\tilde{\alpha}$ підібрані так, що:\\
$B(\tilde{\alpha_j^0} f_j + \dots + \tilde{\alpha_j^{k_j}} h_j^{k_j}) = \alpha_j^0 f_j + \dots + \alpha_j^{k_j}h_j^{k_j}, j = \{s+1, \dots, p\}$\\
$\Rightarrow B(z-w) = Bz - Bw = 0$, отже, $z-w \in \ker B$\\
$\Rightarrow z = w + \tau_1 f_1 + \dots + \tau_s f_s + \gamma_1 g_1 + \dots + \gamma_r g_r$\\
Завершальний етап:\\
$z = \tau_1 f_1 + \alpha_1^0 h_1^1 + \alpha_1^1 h_1^2 + \dots + \alpha_1^{k_1}h_1^{k_1+1} + \dots \\ + \tau_s f_s + \alpha_s^0 h_s^1 + \alpha_s^1 h_s^2 + \dots + \alpha_s^{k_s}h_s^{k_s+1} + \\
+ \tilde{\alpha_{s+1}^0} f_{s+1} + \tilde{\alpha_{s+1}^1} h_{s+1}^1 + \dots + \tilde{\alpha_{s+1}^{k_{s+1}}} h_{s+1}^{k_{s+1}} + \dots + \\
+ \tilde{\alpha_{p}^0} f_{p} + \tilde{\alpha_{p}^1} h_{p}^1 + \dots + \tilde{\alpha_{p}^{k_{p}}} h_{p}^{k_{p}}+\\
+\gamma_1 g_1 + \dots + \gamma_r g_r$\\
Тобто елемент $z$ розклався як лінійна комбінація нашої системи\\
Фінал: $\{f_1,h_1^1,\dots,h_1^{k_1},h_1^{k_1+1}, \hspace{0.5cm} \dots \hspace{0.5cm} f_s, h_s^{1}, \dots,h_s^{k_s}, h_s^{k_s+1}, \\ f_{s+1}, h_{s+1}^1, \dots, h_{s+1}^{k_{s+1}} \hspace{0.5cm} \dots \hspace{0.5cm} f_{p}, h_{p}^1, \dots, h_{p}^{k_p}, \hspace{0.5cm} g_1, \dots, g_r\}$ - базис \qed
(CHECK)
\bigline
\\
Заданий $A: L \to L$ - лінійний оператор\\
В $L$ є базис з власних на ланцюга приєднаних векторів\\
$\{\underset{\lambda_1}{f_1, h_1^1, \dots ,h_1^{k_1}}, \hspace{1cm} \underset{\lambda_2}{f_2, h_2^1, \dots, h_2^{k_2}}, \hspace{1cm} \dots \hspace{1cm} \underset{\lambda_m}{f_m, h_m^{1}, \dots, h_m^{k_m}}\}$\\
$L_j = span\{f_j, h_j^1, \dots, h_j^{k_j}\}$ - інваріантний відносно $A$ (вже доведено)\\
$L = L_1 \dot{+} \dots + \dot{+} L_m$\\
Тому матриця оператора $A$ в цьому базисі має вигляд:\\
$ \mathbb{A}_{J} =
  \tikz[baseline=(M.west)]{%
    \node[matrix of math nodes,matrix anchor=west,left delimiter=(,right delimiter=),ampersand replacement=\&] (M) {%
      \mathbb{A}_{|_{L_1}} \& \mathbb{O} \& \dots \& \mathbb{O} \\
      \mathbb{O} \& \mathbb{A}_{|_{L_2}} \& \dots \& \mathbb{O} \\
      \vdots \& \vdots \& \ddots \& \vdots \\
      \mathbb{O} \& \mathbb{O} \& \dots \& \mathbb{A}_{|_{L_m}} \\
    };
    \node[draw,fit=(M-1-1)(M-1-1),inner sep=-1pt] {};
    \node[draw,fit=(M-2-2)(M-2-2),inner sep=-1pt] {};
    \node[draw,fit=(M-4-4)(M-4-4),inner sep=-1pt] {};
  }
$\\ 
Розглянемо матриці звужених операторів $A|_{L_j}$, $j = 1,\dots,m$\\
$L_j = span\{f_j,h_j^1,\dots,h_j^{k_j}\}$ - базис з одного власного вектора та приєднаних до нього\\
Тоді матриця $A|_{L_j}$ в цьому базисі має вигляд:\\
$\mathbb{A}|_{L_j} = J(\lambda_j)$ - клітина Жордана\\
Остаточний вигляд матриці:\\
$ \mathbb{A}_{J} =
  \tikz[baseline=(M.west)]{%
    \node[matrix of math nodes,matrix anchor=west,left delimiter=(,right delimiter=),ampersand replacement=\&] (M) {%
      J(\lambda_1) \& \mathbb{O} \& \dots \& \mathbb{O} \\
      \mathbb{O} \& J(\lambda_2) \& \dots \& \mathbb{O} \\
      \vdots \& \vdots \& \ddots \& \vdots \\
      \mathbb{O} \& \mathbb{O} \& \dots \& J(\lambda_m) \\
    };
    \node[draw,fit=(M-1-1)(M-1-1),inner sep=-1pt] {};
    \node[draw,fit=(M-2-2)(M-2-2),inner sep=-1pt] {};
    \node[draw,fit=(M-4-4)(M-4-4),inner sep=-1pt] {};
  }
$\\
Її ще називають \textbf{Жордановою формою матриці}
\\
\bigline
Зв'язок матриці оператора $A: L \to L$ в деякому базисі та жордановою формою\\
\begin{tikzcd}
\mathbb{C}^n_e \arrow{rrr}{\mathbb{A}_e} \arrow{dd}[swap]{\mathbb{U}} & & & \mathbb{C}^n_e \arrow{dd}{\mathbb{U}} \\
& \arrow{lu} L \arrow{r}{A} \arrow{ld} & L \arrow{ru} \arrow{rd} \\
\mathbb{C}^n_{J} \arrow{rrr}{\mathbb{A}_{J}} & & & \mathbb{C}^n_{J}
\end{tikzcd}
\\
Розглядаємо базисні елементи жорданового базису. Будуємо матрицю $\mathbb{U}$ оператора переходу від одного базису до іншого\\
Отримаємо зв'язок:\\
$\mathbb{A}_e = \mathbb{U} \mathbb{A}_{J} \mathbb{U}^{-1}$\\
\subsection{Властивості жорданової форми матриці}
Задано $A: L \to L$ - лінійний оператор\\
1. Кількість клітин Жордана, що відповідають власному числу $\lambda_0$, дорівнює кількістю л.н.з. власних векторів з власним числом $\lambda_0$\\
\proof
Кожна клітина Жордана задається ланцюгом $\{f, h^1, \dots, h^k\}$ з базису власних та приєднаних. Тому кількість клітин $=$ кількість л.н.з. власних для $\lambda_0$ $= \dim(\ker (A-\lambda_0 I))$ \qed
\bigline
2. Кількість клітин Жордана для власного числа $\lambda_0$ розмірністю не менше за $\left[ \begin{gathered} 2 \times 2 \\ m \times m \end{gathered} \right.$ дорівноює $\left[ \begin{gathered} r_2 = \dim(\ker(A-\lambda_0 I)^2) - \dim(\ker(A-\lambda_0 I)) \\ r_m = \dim(\ker(A-\lambda_0 I)^m) - \dim(\ker(A-\lambda_0 I)^{m-1}) \end{gathered} \right.$\\
\proof
Кількість клітин Жордана для власного числа $\lambda_0$ розмірністю $2 \times 2$ дорівнює кількістю приєднаних векторів для $\lambda_0$ висоти $1$ в базисі $L$. Кількість л.н.з. власних та приєднаних висоти $1$ дорівнює \\ $\dim(\ker(A-\lambda_0 I)^2)$\\
$\begin{cases}
(A-\lambda_0 I)f = 0 \\
(A-\lambda_0 I)h^1 = f
\end{cases} \Rightarrow (A-\lambda_0 I)^2 f = 0, (A-\lambda_0 I)^2 h^1 = 0
$\\
$(A-\lambda_0 I)h^2 = h^1 \Rightarrow (A-\lambda_0 I)^2 h^2 = f \neq 0$\\
Із кількості всіх власних та приєднаних векторів висоти $1$ для $\lambda_0$ вилучаємо кількість власних для $\lambda_0$. Отримуємо \\ $r_2 = \dim(\ker(A-\lambda_0 I)^2) - \dim(\ker(A-\lambda_0 I))$
\bigline
Кількість клітин Жордана для власного числа $\lambda_0$ розмірністю $m \times m$ дорівнює кілкістю приєднаних висоти $m-1$ для $\lambda_0$ в базисі $L$. Кількість власних та приєднаних висоти $1,2,\dots,m-1$ дорівнює  \\ $\dim (\ker(A-\lambda_0 I)^m)$\\
Із кількості всіх власних та приєднаних аж до висоти $m-1$ для $\lambda_0$ треба вилучити кількість власних та приєднаних аж до $m-2$ для $\lambda_0$\\
Тобто $r_m = \dim(\ker(A-\lambda_0 I)^m) - \dim(\ker(A-\lambda_0 I)^{m-1})$ \qed
\bigline
3. Кількість клітин Жордана для власного числа $\lambda_0$ розмірності $m \times m$ дорівнює $r_m - r_{m+1} = R_m$\\
\proof
Комбінаторне міркування: $'=m \times m' = '\geq m \times m' - '\geq (m-1) \times (m-1)'$ \qed
\bigline
4. Нехай $\lambda_0$ - власне число\\
Сумарна розмірність клітин Жордана дорівнює кратності власних чисел як кореня характеристичного полінома $\det (\mathbb{A} - \lambda \mathbb{I})$\\
\proof
$\det (\mathbb{A} - \lambda \mathbb{I}) = \det (\mathbb{A}_{J} - \lambda I) = \det \begin{pmatrix}
J(\lambda_1) - \lambda I & \dots & 0 \\
\vdots & \ddots & \vdots \\
0 & \dots & J(\lambda_p) - \lambda I
\end{pmatrix} = \\ = \det(J(\lambda_1)-\lambda I) \det(J(\lambda_2)-\lambda I) \dots \det(J(\lambda_p)-\lambda I) \boxed{=} \\
$
$J(\lambda_j)-\lambda I = \begin{pmatrix}
\lambda_j & 1 & 0 & \dots & 0 \\
0 & \lambda_j & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \dots & \lambda_j
\end{pmatrix} - \lambda \begin{pmatrix}
1 & \dots & 0 \\
\vdots & \ddots & \vdots \\
0 & \dots & 1 \\
\end{pmatrix} = \\ = \begin{pmatrix}
\lambda_j - \lambda & 1 & 0 & \dots & 0 \\
0 & \lambda_j - \lambda & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \dots & \lambda_j - \lambda
\end{pmatrix}$\\
Звідси якщо розмірність клітин $J(\lambda_j)$ дорівнює $k_j \times k_j$, то \\ $\det (J(\lambda_j) - \lambda I) = (\lambda_j - \lambda)^{k_j}$\\
$\boxed{=} (\lambda_1-\lambda)^{k_1}(\lambda_2-\lambda)^{k_2} \dots (\lambda_p-\lambda)^{k_p}$ \qed
\bigline
\th{4.4.1. Єдиність форми}\\
Жорданова форма оператора $A$ визначена єдиним чином із точністю до перестановок клітин Жордана\\
\proof
Із попередніх властивостей випливає, що власні числа та їхня кратінсть - незмінні фактори. Кількість клітин Жордана даного розміру для кожного власного числа $\lambda_j$ є число, що залежить від розмірності ядер $\dim (\ker(A-\lambda_0 I)^k)$ і не залежить від базису.\\
Наостанок: переставленню клітин у Жорданової формі відповідає переставлення ланцюжків з власного та башти приєднаних до нього векторів \qed


\subsection{Застосування жорданової форми: функції від операторів, матриць}
I. Многочлен від оператора, матриці\\
Задано $A: L \to L$ - лінійний оператор, $\mathbb{A} \in Mat(n \times n)$ - матриця\\
Є у нас многочлен:\\
$f(x) = a_n x^n + \dots + a_1 x + a_0$\\
Визначимо, чому дорівнює $f(A)$\\
$f(A) = a_n A^n + \dots + a_1 A + a_o \underset{=I}{A^0}$\\
Обчислення:\\
$A = U A_{J} U^{-1}$\\
$A^2 = (U A_{J} U^{-1}) (U A_{J} U^{-1}) = U A^2_{J} U^{-1}$\\
$\dots$\\
$A^k = U A^k_{J} U^{-1}$\\
$\Rightarrow f(A) = U(a_n A^n_{J} + \dots + a_1 A_{J} + a_o I)U^{-1} = Uf(A_{J})U^{-1}$\\
Ми вже знаємо, що $ \mathbb{A}_{J} =
  \tikz[baseline=(M.west)]{%
    \node[matrix of math nodes,matrix anchor=west,left delimiter=(,right delimiter=),ampersand replacement=\&] (M) {%
      J(\lambda_1) \& \mathbb{O} \& \dots \& \mathbb{O} \\
      \mathbb{O} \& J(\lambda_2) \& \dots \& \mathbb{O} \\
      \vdots \& \vdots \& \ddots \& \vdots \\
      \mathbb{O} \& \mathbb{O} \& \dots \& J(\lambda_m) \\
    };
    \node[draw,fit=(M-1-1)(M-1-1),inner sep=-1pt] {};
    \node[draw,fit=(M-2-2)(M-2-2),inner sep=-1pt] {};
    \node[draw,fit=(M-4-4)(M-4-4),inner sep=-1pt] {};
  }
$\\
Тоді $ \mathbb{A}^k_{J} =
  \tikz[baseline=(M.west)]{%
    \node[matrix of math nodes,matrix anchor=west,left delimiter=(,right delimiter=),ampersand replacement=\&] (M) {%
      J^k(\lambda_1) \& \mathbb{O} \& \dots \& \mathbb{O} \\
      \mathbb{O} \& J^k(\lambda_2) \& \dots \& \mathbb{O} \\
      \vdots \& \vdots \& \ddots \& \vdots \\
      \mathbb{O} \& \mathbb{O} \& \dots \& J^k(\lambda_m) \\
    };
    \node[draw,fit=(M-1-1)(M-1-1),inner sep=-1pt] {};
    \node[draw,fit=(M-2-2)(M-2-2),inner sep=-1pt] {};
    \node[draw,fit=(M-4-4)(M-4-4),inner sep=-1pt] {};
  }
$\\
Таким чином, $ f(\mathbb{A}_{J}) =
  \tikz[baseline=(M.west)]{%
    \node[matrix of math nodes,matrix anchor=west,left delimiter=(,right delimiter=),ampersand replacement=\&] (M) {%
      f(J(\lambda_1)) \& \mathbb{O} \& \dots \& \mathbb{O} \\
      \mathbb{O} \& f(J(\lambda_2)) \& \dots \& \mathbb{O} \\
      \vdots \& \vdots \& \ddots \& \vdots \\
      \mathbb{O} \& \mathbb{O} \& \dots \& f(J(\lambda_m)) \\
    };
    \node[draw,fit=(M-1-1)(M-1-1),inner sep=-1pt] {};
    \node[draw,fit=(M-2-2)(M-2-2),inner sep=-1pt] {};
    \node[draw,fit=(M-4-4)(M-4-4),inner sep=-1pt] {};
  }
$\\
І це ще не все, ми знайдемо $f(J(\lambda_j))$\\
Нашу початкову функцію ще можна записати як таким чином:\\
$f(x) = f(\lambda_j) + \dfrac{f'(\lambda_j)}{1!}(x-\lambda_j) + \dots + \dfrac{f^{(n)}(\lambda_j)}{n!}(x-\lambda_j)^n$\\
$\Rightarrow f(J(\lambda_j)) = f(\lambda_j)I + \dfrac{f'(\lambda_j)}{1!}(J(\lambda_j) - \lambda_j I) + \dots + \dfrac{f^{(n)}(\lambda_j)}{n!}(J(\lambda_j)-\lambda_j I)^n \boxed{=}$\\
Зауважимо, що $J(\lambda_j) - \lambda_j I = \begin{pmatrix}
\lambda_j-\lambda_j & 1 & 0 & 0 & \dots & 0 \\
0 & \lambda_j-\lambda_j & 1 & 0 & \dots & 0 \\
0 & 0 & \lambda_j-\lambda_j & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \dots & 1 \\
0 & 0 & 0 & 0 & \dots & \lambda_j-\lambda_j \\
\end{pmatrix} = \\ =
\begin{pmatrix}
0 & 1 & 0 & 0 & \dots & 0 \\
0 & 0 & 1 & 0 & \dots & 0 \\
0 & 0 & 0 & 1 & \dots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \dots & 1 \\
0 & 0 & 0 & 0 & \dots & 0 \\
\end{pmatrix} = J(0)$\\
$\boxed{=} f(\lambda_j)I + \dfrac{f'(\lambda_j)}{1!}J(0) - \lambda_j I) + \dots + \dfrac{f^{(n)}(\lambda_j)}{n!}J^n(0)$\\
Знайдемо $J^k(0)$ тепер (або просто згадаю д/з)\\
Збільшуючи степінь, ми зсуваємо діагональ з одиничок. А там буде степінь, починаючи з якого, всі матриці будуть нулевими\\
А далі в формулі два випадки:\\
$k \geq n$:
$\Rightarrow f(J(\lambda_j)) = f(\lambda_j)J(0) + \dots + \dfrac{f^{(k-1)}(\lambda_j)}{(k-1)!}J^{k-1}(0)$\\
$k < n:$
$\Rightarrow f(J(\lambda_j)) = f(\lambda_j)J(0) + \dots + \dfrac{f^{(n)}(\lambda_j)}{n!}J^{n}(0)$\\
Але в цьому випадку $f^{(n+1)}(\lambda_j) = \dots = f^{(k)}(\lambda_j) = 0$. Все одно буде матриця той самої форми, як в першому випадку\\
$\Rightarrow f(J(\lambda_j)) = \begin{pmatrix}
 f(\lambda_j) & \dfrac{f'(\lambda_j)}{1!} & \dfrac{f''(\lambda_j)}{2!} & \dots & \dfrac{f^{(k-1)}(\lambda_j)}{(k-1)!} \\
 0 & f(\lambda_j) & \dfrac{f'(\lambda_j)}{1!} & \dots & \dfrac{f^{(k-2)}(\lambda_j)}{(k-2)!} \\
 0 & 0 & f(\lambda_j) & \dots & \dfrac{f^{(k-3)}(\lambda_j)}{(k-3)!} \\
 \vdots & \vdots & \vdots & \ddots & \vdots \\
 0 & 0 & 0 & \dots & f(\lambda_j) 
\end{pmatrix}$\\
Ну а далі просто підсумуємо і отримуємо остаточні дані

\newpage
\section{Евклідові простори}
\defin{5.0.1.} Задано $L$ - лінійний простір над $\mathbb{C}$\\
Відображення $\varphi : L \times L \to \mathbb{C}$ називається \textbf{півторалінійним} \\ \textbf{(білінійним) функціоналом}, якщо для нього виконано такі властивості:\\
1) $\forall x,y,z \in L: \forall \alpha,\beta \in \mathbb{C}: \varphi (\alpha x + \beta y, z) = \alpha \varphi (x,z) + \beta \varphi (y,z)$\\
2) $\forall x,y,z \in L: \forall \alpha, \beta \in \mathbb{C}: \varphi (x, \alpha y + \beta z) = \overline{\alpha} \varphi (x,y) + \overline{\beta} \varphi (x,z)$\\
(якщо поле $\mathbb{R}$, то 2 пункту нема - це білінійний)
\bigline
\ex{5.0.2.} Наступні функціонали є білінійними\\
1) $L = \mathbb{R}^3, \varphi(\vec{x},\vec{y}) = (\vec{x},\vec{y})$\\
2) $L = \mathbb{R}_n[x], \varphi(f,g) = \huge \int_a^b f(x)g(x)\,dx$\\
3) $L = Mat(n \times n), \varphi(A,B) = tr(AB)$\\
Приклади комплексного випадку:\\
4) $L = \mathbb{C}^2, \varphi(\vec{z},\vec{w}) = z_1 \overline{w_1} + z_2 \overline{w_2}$\\
5) $L = \mathbb{C}_n[x], \varphi(f,g) = \huge \int_a^b f(x) \overline{g}(x)\,dx$\\
6) $L = Mat(n \times n), \varphi(A,B) = tr(A \overline{B}^T)$
\bigline
\defin{5.0.3. Евклідовим простором} називають лінійний простір $E$, на якому задано півторалінійний функціонал $\varphi: E \times E \to \mathbb{C} (\mathbb{R})$, для якого виконуються такі властивості:\\
1) $\forall x \in E: \varphi(x,x) \geq 0$\\
2) $\varphi(x,x) = 0 \iff x = 0$\\
3) $\forall x,y \in E: \varphi(x,y) = \overline{\varphi(y,x)}$
\bigline
\ex{5.0.4.} Приклади 1,2,4,6) лінійні простори є евклідовими
\bigline
\subsection{Ортогональність, процес Грама-Шмідта}
\defin{5.1.1.(1).} Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Елементи $x,y \in E$ називаються \textbf{ортогональними}, якщо $(x,y) = 0$\\
Позначення: $x \perp y$
\bigline
\defin{5.1.1.(2).} Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Система елементів $\{x_1,\dots,x_n\}$ називається \textbf{ортогональною}, якщо \\ $\forall j \neq k: (x_j,x_k) = 0$\\
Позначення: $x_j \perp x_k$
\bigline
\defin{5.1.1.(3).} Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Система елементів $\{x_1,\dots,x_n\}$ називається \textbf{ортонормованою}, якщо \\ $\forall j \neq k: (x_j,x_k) = 0$, а також $(x_j,x_j) = 1$\\
Скорочено: $(x_j,x_k) = \delta_{jk}$ - символ Кронекера
\bigline
\prp{5.1.2.} Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Система $\{x_1,\dots,x_m\}$ - ортогональна. Тоді вона ж - л.н.з.\\
\proof
$\alpha_1 x_1 + \dots + \alpha_m x_m = 0 \Rightarrow \forall j: (\alpha_1 x_1 + \dots + \alpha_n x_n, x_j) = 0$\\
$\Rightarrow \alpha_1 (x_1,x_j) + \dots + \alpha_j (x_j,x_j) + \dots + \alpha_m (x_m,x_j) = 0$\\
Отримали, що $\alpha_j (x_j,x_j) = 0 \Rightarrow \alpha_j = 0$\\
І це $\forall j$. Отже, л.н.з. \qed
\bigline
\crl{5.1.2.} Ортонормована система - л.н.з.
\bigline
\\
Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Нехай є система $\{x_1,\dots,x_m\}$. Побудуємо еквівалентну їй ортонормовану систему\\
0) $\tilde{e_1}=x_1$\\
1) $\tilde{e_2} = x_2 - \alpha_{21} \tilde{e_1}$\\
Знайдемо $\alpha_{21}$ з умови $(\tilde{e_2}, \tilde{e_1}) = 0$\\
$(\tilde{e_2}, \tilde{e_1}) = (x_2-\alpha_{21}\tilde{e_1}, \tilde{e_1}) = (x_2, \tilde{e_1})-\alpha_{21} (\tilde{e_1},\tilde{e_1})$\\
$\Rightarrow \alpha_{21} = \dfrac{(x_2,\tilde{e_1})}{(\tilde{e_1},\tilde{e_1})}$\\
Зауважимо, що $\{x_1,x_2\} \sim \{\tilde{e_1},\tilde{e_2}\}$\\
\\
2) $\tilde{e_3} = x_3 - \alpha_{31} \tilde{e_1} - \alpha_{32} \tilde{e_2}$\\
Знайдемо $\alpha_{31}, \alpha_{32}$ з умов $\tilde{e_3} \perp \tilde{e_1}, \tilde{e_2} \perp \tilde{e_1}$\\
$\begin{cases}
(\tilde{e_3}, \tilde{e_1}) = 0 \\
(\tilde{e_3}, \tilde{e_2}) = 0
\end{cases}
$
Аналогічним чином отримаємо:\\
$\alpha_{31} = \dfrac{(x_3, \tilde{e_1})}{(\tilde{e_1},\tilde{e_1})} \hspace{1cm} \alpha_{32} = \dfrac{(x_3, \tilde{e_2})}{(\tilde{e_2},\tilde{e_2})}$\\
Зауважимо, що $\{x_1,x_2,x_3\} \sim \{\tilde{e_1},\tilde{e_2},\tilde{e_3}\}$\\
$\vdots$\\
Узагальнюючи, отримаємо наступне:\\
$\alpha_{ks} = \dfrac{(x_k, \tilde{e_s})}{(\tilde{e_s},\tilde{e_s})}$, тут $s = {1,\dots,k-1}$\\
Більш того, $\{x_1,\dots,x_k\} \sim \{\tilde{e_1},\dots, \tilde{e_k}\}$
\bigline
Важливі властивості:\\
1) $\{x_1,\dots,x_k\}$ - л.н.з.\\
$\{x_1,\dots,x_k\} \sim \{\tilde{e_1},\dots, \tilde{e_k}\} \Rightarrow \forall j: \tilde{e_j} \neq 0$\\
$\textrm{rank} = k$
\bigline
2) $\{x_1,\dots,x_{k-1}\}$ - л.н.з\\
$\{x_1,\dots,x_{k-1},x_k \}$ - л.з.\\
$\{\tilde{e_1}, \dots, \tilde{e_{k-1}}, \tilde{e_k}\} \sim \{x_1,\dots,x_{k-1},x_k\} \sim \{x_1,\dots,x_{k-1}\} \sim \{\tilde{e_1},\dots, \tilde{e_{k-1}}\}$
Остання система містить $\textrm{rank} = k-1$\\
Тому перша система містить $\textrm{rank} = k-1$\\
Більш того, $\{\tilde{e_1},\dots, \tilde{e_{k-1}}\}$ - л.н.з.\\
Якщо $\tilde{e_k} \neq 0$, то наша система буде л.н.з., що суперечить рангу\\
Отже, $\tilde{e_k} = 0$
\bigline
Остаточний висновок:\\
$\{x_1,\dots,x_m\} \overset{\textrm{Гр-Шм}}{\rightarrow} \{\tilde{e_1},\dots,\tilde{e_m}\}$ - ортогональна\\
$\forall k: \{x_1,\dots,x_k\} \sim \{\tilde{e_1},\dots, \tilde{e_k}\}$\\
Якщо $\{x_1,\dots,x_{k-1}\}$ - max. л.н.з., то $\tilde{e_k} = 0$
\bigline
Остання дія, ортонормуємо нашу систему:\\
$\forall k = \{1,\dots,m\}: e_k = \dfrac{\tilde{e_k}}{\sqrt{(\tilde{e_k},\tilde{e_k})}}$\\
Тоді $(e_k,e_j) = \dfrac{(\tilde{e_k},\tilde{e_j})}{\sqrt{(\tilde{e_k},\tilde{e_k})} \sqrt{(\tilde{e_j},\tilde{e_j})}} = 0$\\
$(e_k,e_k) = \dfrac{(\tilde{e_k},\tilde{e_k})}{(\tilde{e_k},\tilde{e_k})} = 1$
\bigline
\th{5.1.3. Нерівність Коші-Буняковського}\\
Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$\\
$\forall x,y \in E: |(x,y)|^2 \leq (x,x)(y,y)$\\
\proof
I. Випадок $\mathbb{R}$\\
Зауважимо, що $\forall t \in \mathbb{R} (x+ty, x+ty) \geq 0$\\
$\Rightarrow (x,x) + t(x,y) + t(y,x) + t^2(y,y) = t^2(y,y) + 2t(x,y) + (x,x) \geq 0$\\
$D = 4(x,y)^2 - 4(x,x)(y,y) \leq 0$\\
$\Rightarrow (x,y)^2 \leq (x,x)(y,y)$
\bigline
II. Випадок $\mathbb{C}$\\
$\forall z \in \mathbb{C}: z = |z|e^{i \varphi}$\\
$\Rightarrow |z| = e^{i \varphi} z$\\
$(x,y) = |(x,y)|e^{i \varphi}$\\
Розглянемо $\forall t \in \mathbb{R}: (x+te^{i\varphi} + x + t e^{i\varphi}) \geq 0$\\
$\Rightarrow (x,x)+(x,te^{i\varphi}y) + (te^{i\varphi}y,x)+(te^{i\varphi}y, te^{i\varphi}y) =\\
= (x,x) + \overline{t e^{i\varphi}}(x,y) + te^{i \varphi} (y,x) + te^{i \varphi} \overline{t e^{i\varphi}} (y,y) = \\ $
Зауважимо, що $\overline{e^{i\varphi}} = e^{-i\varphi}$\\
$= (x,x) + te^{-i\varphi}(x,y) + te^{i\varphi}(y,x) + t^2(y,y) =$\\
Далі $(x,y) = |(x,y)|e^{i \varphi} \Rightarrow e^{-i \varphi}(x,y) = |(x,y)|$\\
$\Rightarrow e^{i\varphi}(y,x) = \overline{e^{-i\varphi}} \overline{(x,y)} = \overline{|(x,y)|} = |(x,y)|$\\
$= (x,x) + 2t|(x,y)| + t^2(y,y) \geq 0$\\
$D = 4|(x,y)|^2 - 4(x,x)(y,y) \leq 0$\\
$\Rightarrow |(x,y)|^2 \leq (x,x)(y,y)$ \qed
\bigline
\subsection{Нормований простір та інші поняття}
\defin{5.2.1.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$\\
\textbf{Нормаллю} елемента $x$ називають величину
\begin{align*}
||x|| = \sqrt{(x,x)}
\end{align*}
\prp{5.2.2.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$\\
Для нормалі виконуються умови:\\
1) $\forall x \in E: ||x|| \geq 0$\\
2) $||x|| = 0 \iff x = 0$\\
3) $\forall x \in E: \forall \lambda \in \mathbb{C}: ||\lambda x|| = |\lambda| \cdot ||x||$\\
4) $\forall x,y \in E: ||x+y|| \leq ||x||+ ||y||$\\
\proof
1),2) все зрозуміло
\bigline
3) $||\lambda x|| = \sqrt{(\lambda x, \lambda x)} = |\lambda| \sqrt{(x,x)} = |\lambda| \cdot ||x||$
\bigline
4) $||x+y||^2 = (x+y,x+y) = (x,x)+(x,y)+(y,x)+(y,y) =$\\
$(y,x) = \overline{(x,y)}$\\
$\Rightarrow (x,y) + (y,x) = 2 \Re (x,y)$\\
$= ||x||^2 + 2 \Re (x,y) + ||y||^2 \leq ||x||^2 + 2|(x,y)|+||y||^2 \leq \\ \leq ||x||^2 + 2||x||||y|| + ||y||^2 = (||x||+||y||)^2$ \qed
\bigline
\defin{5.2.3.} \textbf{Нормованим простором} називають лінійний простір $N$ із заданою на ньому функцією $|| \cdot ||: N \to \mathbb{R}$, що задовільняють умовам 1)-4)
\bigline
\ex{5.2.4.(1).} $E, (\cdot,\cdot)$, евклідовий, $||x|| = \sqrt{(x,x)}$ - евклідова норма\\
\ex{5.2.4.(2).} $N = \mathbb{R}^n$, $||\vec{x}|| = \huge \sum_{j=1}^n |x_j|$\\
\ex{5.2.4.(3).} $N = \mathbb{C}^n$, $||\vec{z}|| = \huge \sqrt[p]{\sum_{j=1}^n |z_j|^p}$, $p>1$\\
\ex{5.2.4.(4).} $N = C([a,b])$, $||f|| = \huge \max_{[a,b]} |f(x)|$
\bigline
\defin{5.2.5. Відстанню між елементами} $x$ \textbf{та} $y$ евклідового простору $E$ із $(\cdot,\cdot)$ (або нормованого простору $N$) називають число
\begin{align*}
\rho(x,y) = ||x-y||
\end{align*}
\prp{5.2.6. Властивості}\\
1) $\forall x,y: \rho(x,y) \geq 0$\\
2) $\rho(x,y) = 0 \iff x = y$\\
3) $\rho(x,y) = \rho(y,x)$\\
4) $\forall x,y,z: \rho(x,y) \leq \rho(x,z) + \rho(z,x)$
\bigline
\defin{5.2.7.} Задано $E$ - дійсний евклідовий простір із $(\cdot,\cdot)$\\
\textbf{Косінусом кута між} $x,y$ називається число:
\begin{align*}
\cos \alpha = \dfrac{(x,y)}{||x|| \cdot ||y||}
\end{align*}
\\
\subsection{Ортонормований базис, побудова}
Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Нехай $\{f_1,\dots,f_n\}$ - базис в $E$\\
Застосуємо до цієї системи ортогоналізацію Грама-Шмідта\\
Отримаємо ортонормовану систему $\{e_1,\dots,e_n\}$\\
$\{f_1,\dots,f_n\} \sim \{e_1,\dots,e_n\} \Rightarrow span\{f_1,\dots,f_n\} = E = span\{e_1,\dots,e_n\}$\\
Отже, $\{e_1,\dots,e_n\}$ - ортонормований базис $E$\\
Крім того, $(e_j,e_k) = \delta_{jk} = \begin{cases} 0, j \neq k \\ 1, j = k \end{cases}$
\bigline
\lm{5.3.1. Розклад Фур'є}\\
Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $\{e_1,\dots,e_n\}$ - ортонормований базис\\
Тоді $\forall x \in E: x = (x,e_1)e_1 + \dots + (x,e_n)e_n$\\
\proof
$x = \alpha_1 e_1 + \dots + \alpha_n e_n = \huge \sum_{j=1}^n \alpha_j e_j$\\
$\forall e_k: (x,e_k) = \huge \left(\sum_{j=1}^n \alpha_j e_j, e_k \right) = \sum_{j=1}^n \alpha_j (e_j,e_k) = \alpha_k$\\
І все \qed
\bigline
Тепер розглянемо розклад елемента евклідового простору за довільним базисом\\
$\{f_1,\dots,f_n\}$ - базис\\
$e \in E: x = \alpha_1 f_1 + \dots + \alpha_n f_n = \huge \sum_{j=1}^n \alpha_j f_j$\\
Знайдемо коефіцієнти:\\
$(x,f_1) = \huge \left(\sum_{j=1}^n \alpha_j f_j, f_1 \right) = \sum_{j=1}^n \alpha_j (f_j,f_1)$\\
$(x,f_2) = \huge \sum_{j=1}^n \alpha_j (f_j,f_2)$\\
$\dots$\\
$(x,f_n) = \huge \sum_{j=1}^n \alpha_j (f_j, f_n)$\\
Отримали систему рівнянь відносно $\alpha_1,\dots,\alpha_n$:\\
$\begin{cases}
\alpha_1 (f_1,f_1) + \alpha_2 (f_2,f_1) + \dots + \alpha_n (f_n,f_1) = (x,f_1) \\
\alpha_1 (f_1,f_2) + \alpha_2 (f_2,f_2) + \dots + \alpha_n (f_n,f_2) = (x,f_2) \\
\dots \\
\alpha_n (f_1,f_n) + \alpha_2 (f_2,f_n) + \dots + \alpha_n (f_n,f_n) = (x,f_n) \\
\end{cases}
$\\
Або маємо матричний вид:\\
$\Gamma = \begin{pmatrix}
(f_1,f_1) & (f_2,f_1) & \dots & (f_n,f_1) \\
(f_1,f_2) & (f_2,f_2) & \dots & (f_n,f_2) \\
\vdots & \vdots & \ddots & \vdots \\
(f_1,f_n) & (f_2,f_n) & \dots & (f_n,f_n)
\end{pmatrix}$ - матриця Грама\\
$\vec{\alpha} = \begin{pmatrix}
\alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_n
\end{pmatrix}$ \hspace{1cm}
$[\vec{x}] = \begin{pmatrix}
(x,f_1) \\ (x,f_2) \\ \vdots \\ (x,f_n)
\end{pmatrix}$
\\
$\Rightarrow \Gamma \vec{\alpha} = [\vec{x}]$\\
Оскільки $\forall x: \exists! \alpha_1,\dots,\alpha_n$, то система має єдиний розв'язок, тому $\exists \Gamma^{-1}$\\
Тоді:\\
$\vec{\alpha} = \Gamma^{-1} [\vec{x}]$
\bigline
\subsection{Ортогональні підпростори, ортогональне доповнення}
\defin{5.4.1.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$\\
Підпростори $L_1,L_2$ називаються \textbf{ортогональними}, якщо
\begin{align*}
\forall x \in L_1, \forall y \in L_2: (x,y) = 0
\end{align*}
Позначення: $L_1 \perp L_2$
\bigline
\prp{5.4.2.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$\\
$L_1 \perp L_2$ - два підпростори. Тоді $L_1 \cap L_2 = \{0\}$\\
\proof
$z \in L_1 \cap L_2 \Rightarrow \begin{cases} z \in L_1 \\ z \in L_2 \end{cases} \Rightarrow (z,z) = 0 \Rightarrow z = 0$ \qed \\
З цього випливає, що ортогональні простори є прямою сумою: $L_1 \bigoplus L_2$
\bigline
\defin{5.4.3.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L$ - підпростір\\
\textbf{Ортогональним доповненням до} $L$ називається множина
\begin{align*}
L^{\perp} = \{y \in E: \forall x \in L: (x,y) = 0\}
\end{align*}
\prp{5.4.4.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L$ - підпростір\\
Тоді $L^{\perp}$ - теж лінійний підпростір\\
\proof
$\forall y_1,y_2 \in L^{\perp}: \forall \alpha,\beta \in \mathbb{R} (\mathbb{C}):$\\
$\forall x \in L: (x, \alpha y_1+ \beta y_2) = \overline{\alpha} (x,y_1) + \overline{\beta} (x,y_2) = \overline{\alpha} \cdot 0 + \overline{\beta} \cdot 0 = 0$\\
$\Rightarrow \alpha y_1 + \beta y_2 \in L^{\perp}$ \qed
\bigline
\th{5.4.5. Ортогональний розклад евклідового простору}\\
Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L$ - підпростір\\
Тоді $E = L \bigoplus L^{\perp}$\\
\proof
$\{f_1,\dots,f_k\}$ - базис $L$\\
$\{f_1,\dots,f_k\} \overset{\textrm{Гр.-Шм.}}{\rightarrow} \{e_1,\dots,e_k\}$ - базис $L$\\
Доповнимо його до базису $E$: $\{e_1,\dots,e_k,f_{k+1},f_n\}$\\
$\{e_1,\dots,e_k,f_{k+1},f_n\} \overset{\textrm{Гр.-Шм.}}{\rightarrow} \{e_1,\dots,e_k, e_{k+1},\dots,e_n\}$ - ортонормований базис $E$\\
(перші $k$ елементи взагалі не змінюються)\\
Перевіримо, що $\forall \alpha_{k+1},\dots,\alpha_{n} \in \mathbb{R} (\mathbb{C}):$\\
$\alpha_{k+1}e_{k+1}+\dots+\alpha_n e_n \in L^{\perp}$\\
$\forall x \in L: x = \huge \sum_{j=1}^k \alpha_j e_j$\\
$y = \huge \sum_{m=k+1}^n \alpha_m e_{m}$\\
Перемножимо ці два елементи:\\
$(x,y) = \huge \left(\sum_{j=1}^k \alpha_j e_j, \sum_{m=k+1}^n \alpha_m e_m \right) = \sum_{j=1}^k \sum_{m=1}^n \alpha_j \overline{\alpha_m} (e_j,e_m) =$\\
$j \leq k, m \geq k+1 \Rightarrow j \neq m \Rightarrow (e_j,e_m) = 0$\\
$= 0$\\
Отже, $y = \alpha_{k+1}e_{k+1} + \dots + \alpha_n e_n \in L^{\perp}$\\
Тому $span\{e_{k+1},\dots,e_k\} \subset L^{\perp}$\\
$\dim L^{\perp} \geq n-k$\\
Крім того, $L,L^{\perp}$ - підпростори, $L \perp L^{\perp}$, тому $L \bigoplus L^{\perp}$ - ортогональна сума\\
Тому $L \bigoplus L^{\perp} \subset E$\\
$\Rightarrow \dim (L \bigoplus L^{\perp}) = \dim L + \dim L^{\perp} \leq n$\\
$\Rightarrow \dim L^{\perp} \leq n-k$\\
Остаточно, $\dim L^{\perp} = n-k$\\
Підсумовуючи, отримаємо, що $L^{\perp} = span\{e_{k+1},\dots, e_{n}\}$\\
І нарешті, $E = L \bigoplus L^{\perp}$ \qed
\bigline
\th{5.4.6. Єдиність ортогонального розкладу}\\
Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L,M$ - такі підпростри, що $E = L \bigoplus M$\\
Тоді $M = L^{\perp}$\\
\proof
За умовою, $M \perp L$, тож $M \subset L^{\perp}$\\
$\begin{cases}
\dim M = \dim E - \dim L \\
\dim L^{\perp} = \dim E - \dim L
\end{cases} \Rightarrow M = L^{\perp}$ \qed
\bigline
\rm{5.4.6.} Інколи використовують позначення: $E \ominus L = L^{\perp}$
\bigline
\th{5.4.7.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L, L_1,L_2$ - підпростори\\
Тоді:\\
0) $E^{\perp} = \{0\} \hspace{1cm} \{0\}^{\perp} = E$\\
1) $(L^{\perp})^{\perp} = L$\\
2) $L_1 \subset L_2 \Rightarrow L_2^{\perp} \subset L_1^{\perp}$\\
3) $(L_1 \cap L_2)^{\perp} = L_1^{\perp} + L_2^{\perp}$\\
4) $(L_1+L_2)^{\perp} = L_1^{\perp} \cap L_2^{\perp}$\\
\proof
0) $y \in E^{\perp} \Rightarrow \forall z \in E: (y,z) = 0$\\
Беремо $z = y \Rightarrow (y,y) = 0 \Rightarrow y = 0$\\
$\{0\}^{\perp} = E$ - зрозуміло
\bigline
1) $E = L \bigoplus L^{\perp} \hspace{1cm} E = L^{\perp} \bigoplus (L^{\perp})^{\perp}$\\
З єдиності розкладу, маємо: $(L^{\perp})^{\perp} = L$
\bigline
2) $\forall y \in L_2^{\perp}$ маємо:\\
$\forall x \in L_1 \Rightarrow x \in L_2: (y,x) = 0 \Rightarrow y \in L_1^{\perp}$\\
Отже, $L_2^{\perp} \subset L_1^{\perp}$
\bigline
4) $\forall z \in (L_1+L_2)^{\perp}: \forall x \in L_1, y \in L_2: x+y \in L_1+L_2: (z,x+y) = 0$\\
Тому $(z,x+y) = 0 \iff \begin{cases} (z,x) = 0 \\ (z,y) = 0 \end{cases} \iff \begin{cases} z \in L_1^{\perp} \\ z \in L_2^{\perp} \end{cases} \iff z \in L_1^{\perp} \cap L_2^{\perp}$
\bigline
3) $L_1^{\perp} = M_1, L_2^{\perp} = M_2$\\
$\Rightarrow L_1 = M_1^{\perp}, L_2 = M_2^{\perp}$\\
З властивості 4) маємо:\\
$(M_1+M_2)^{\perp} = M_1^{\perp} \cap M_2^{\perp}$\\
$(L_1^{\perp} + L_2^{\perp})^{\perp} = L_1 \cap L_2$\\
$L_1^{\perp} + L_2^{\perp}=((L_1^{\perp} + L_2^{\perp})^{\perp})^{\perp} = (L_1 \cap L_2)^{\perp}$ \qed
\bigline
\defin{5.4.8.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L$ - підпростір\\
$E = L \bigoplus L^{\perp}$, тобто $\forall z \in E: \exists! x \in L: \exists! y \in L^{\perp}: z = x+y$\\
Елемент $x$ називають \textbf{ортогональною проєкцією} елемента $z$ на $L$\\
Позначення: $x = pr_L z$\\
Елемент $y$ називають \textbf{ортогональною складовою} елемента $z$ відносно $L$\\
Позначення: $y = ort_L z$\\
$\Rightarrow z = pr_L z + ort_L z$\\
$pr_L z \in L, ort_L z \in L^{\perp}$\\
Тому розклад є єдиним \bigline
\ex{5.4.9.} $E = \mathbb{R}^3$, $L = span\{\vec{a_1} = \begin{pmatrix} 1 & -2 & 3 \end{pmatrix} \vec{a_2} = \begin{pmatrix} 3 & 1 & 1 \end{pmatrix} \}$\\
$\vec{z} = (5,2,-1)$\\
$pr_{L} \vec{z} = \alpha_1 \vec{a_1} + \alpha_2 \vec{a_2}$\\
$ort_L \vec{z} = z - pr_L \vec{z} = z - \alpha_1 \vec{a_1} - \alpha_2 \vec{a_2} \perp \vec{a_1}, \vec{a_2}$\\
$\Rightarrow \begin{cases} (ort_L \vec{z}, \vec{a_1}) = 0 \\ (ort_L \vec{z}, \vec{a_2}) = 0 \end{cases} \Rightarrow \begin{cases} (\vec{z}, \vec{a_1}) - \alpha_1 (\vec{a_1},\vec{a_1}) - \alpha_2 (\vec{a_2}, \vec{a_1}) = 0 \\ (\vec{z}, \vec{a_2}) - \alpha_1 (\vec{a_1},\vec{a_2}) - \alpha_2 (\vec{a_2}, \vec{a_2}) = 0 \end{cases}$\\
Знайдемо всі скалярні добутки:\\
$(\vec{a_1}, \vec{a_1}) = 14, (\vec{a_1}, \vec{a_2}) = 4, (\vec{a_2}, \vec{a_2}) = 11$\\
$(\vec{z}, \vec{a_1}) = -2, (\vec{z},\vec{a_2}) = 16$\\
Отримуємо:\\
$\begin{cases} 14 \alpha_1 + 4 \alpha_2 = -2 \\ 4 \alpha_1 + 11 \alpha_2 = 16 \end{cases}$\\
$\alpha_1 = -\dfrac{43}{69}, \alpha_2 = \dfrac{116}{69}$\\
$\Rightarrow pr_L \vec{z} = -\dfrac{43}{69} \vec{a_1} + \dfrac{116}{69} \vec{a_2} = \dots$\\
$\Rightarrow ort_L \vec{z} = \vec{z} - pr_L \vec{z}$
\bigline
Загальний пошук проєкції та складової:\\
Маємо $E$, $(\cdot, \cdot)$\\
$L = span\{a_1,\dots,a_m\}$ (вже нехай буде л.н.з.)\\
$z \in E \Rightarrow z = pr_L z + ort_L z$\\
$pr_L z = \huge \sum_{j=1}^m \alpha_j a_j$\\
$ort_L z = z - pr_L z = \huge z - \sum_{j=1}^m \alpha_j a_j$\\
Причому $\forall k = 1,\dots,m: ort_L z \perp a_k \Rightarrow$\\
$\begin{cases}
(ort_L z, a_1) = 0 \\
\dots \\
(ort_L z, a_m) = 0 \\
\end{cases} \Rightarrow
\begin{cases}
(\huge z - \sum_{j=1}^m \alpha_j a_j, a_1) = 0 \\
\dots \\
(\huge z - \sum_{j=1}^m \alpha_j a_j, a_m) = 0 \\
\end{cases} \Rightarrow
\begin{cases}
\huge \sum_{j=1}^m \alpha_j (a_{j}, a_1) = (z,a_1) \\
\dots \\
\huge \sum_{j=1}^m \alpha_j (a_{j}, a_m) = (z,a_m)
\end{cases}
$
Матриця системи: $\begin{pmatrix}
 (a_1,a_1) & \dots & (a_m,a_1) \\
 \vdots & \ddots & \vdots \\
 (a_1,a_m) & \dots & (a_m,a_m)
\end{pmatrix} = \Gamma$ - матриця Грама\\
Оскільки $\{a_1,\dots,a_m\}$ - л.н.з., то $\exists \Gamma^{-1}$, а тому існує єдиний розв'язок
\\
\subsection{Застосування, спряжений оператор}
Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $L$ - лінійний підпростір, $z \in E$\\
\defin{5.5.1.} \textbf{Відстань від} $z$ до $L$ називаєтья число:
\begin{align*}
\rho(z,L) = \inf_{y \in L} ||z-y||
\end{align*}
\lm{5.5.2.} $\rho(z, L) = ||ort_L z||$ і ця відстань досягається на елементі $y = pr_L z$\\
\proof
$||z-y||^2 = (z-y,z-y) = (\underbrace{{ort_L} z}_{\in L^{\perp}} + \underbrace{pr_L z - y}_{\in L}, ort_L z + pr_L z - y) = \\ = (ort_L z, ort_L z) + \underbrace{(ort_L z, prt_L z - y)}_{=0} + \underbrace{(pr_L z - y, ort_L z)}_{= 0} + \\ + (pr_L z - y, pr_L z - y) = ||ort_L z||^2 + ||pr_L z - y||^2 \geq ||ort_L z||^2$\\
$\Rightarrow \forall y: ||z-y|| \geq ||ort_L z||$\\
А рівність досягається при $y = pr_L z$\\
Тому $\huge \inf_{y \in L} ||z-y|| = ||ort_L z|| = \rho(z,L)$ \qed
\bigline
\defin{5.5.3.} Задано $L$ - лінійний простір\\
Множина всіх лінійних функціоналів над $L$ утворює \textbf{спряжений лінійний простір}\\
Позначення: $L^*$
\bigline
\rm{5.5.3.} В $E$, $(\cdot, \cdot)$\\
$\forall f \in E:$ відображення $\varphi: E \to \mathbb{R} (\mathbb{C}): \varphi(x) = (x,f)$ - є лінійним функціоналом
\bigline
\th{5.5.4. Теорема Ріса} (для лінійних функціоналів)\\
Задано $E$ - евклідовий простір із $(\cdot,\cdot)$\\
$\forall \varphi \in E^*: \exists! f \in E: \forall x \in E: \varphi(x) = (x,f)$\\
\proof
Для $\varphi \equiv 0 \Rightarrow f = 0$\\
Тепер $\varphi \not\equiv 0$:\\
1-й спосіб: нехай $\{e_1,\dots,e_n\}$ - ортонормований базис в $E$\\
Тоді покладемо $f = \overline{\varphi(e_1)}e_1 + \dots + \overline{\varphi(e_n)}e_n$\\
$\forall x \in L: \varphi(x) = \varphi \huge \left( \sum_{j=1}^n x_j e_j \right) = \sum_{j=1}^n x_j \varphi(e_j)$\\
$(x,f) = \huge \left( \sum_{j=1}^n x_j e_j, \sum_{k=1}^n \overline{\varphi(e_k)}e_k \right) = \sum_{j=1}^n \sum_{k=1}^n x_j \overline{\overline{\varphi(e_k)}} (e_j,e_k) = \sum_{j=1}^n x_j \varphi(e_j) \cdot 1$\\
Отже, $\varphi(x) = (x,f)$
\bigline
2-й спосіб: $\varphi: E \to \mathbb{R} (\mathbb{C})$, $L = \ker \varphi$, $\dim L = n-1$\\
Розглянемо $L^{\perp}, \dim L^{\perp} = 1$\\
Нехай $w \in L^{\perp}, w \neq 0$\\
Оберемо $f \in L$\\
$f(w) = (w,f), f = \alpha w$\\
$\varphi(w) = (w, \alpha w) = \overline{\alpha} (w,w)$\\
$\Rightarrow \overline{\alpha} = \dfrac{\varphi(w)}{(w,w)} \Rightarrow \alpha = \dfrac{\overline{\varphi(w)}}{(w,w)}$\\
Покажемо, що $f = \alpha w$ для знайденого щойно $\alpha$ є шуканою\\
$\forall x \in E: x = pr_L x + ort_L x = pr_L x + \beta f$\\
$\varphi(x) = \varphi(pr_L x + \beta f) = \beta \varphi(f)$\\
$(x,f) = (pr_L x + \beta f, f) = (pr_L x, f) + \beta (\alpha w, f) = \beta \alpha (w,f) = \beta \alpha \varphi(w) = \beta \varphi(\alpha w) = \beta \varphi(f)$\\
Отже, $\varphi(x) = (x,f)$
\bigline
Доведемо єдиність\\
Нехай $\exists f' \in E: \varphi(x) = (x,f')$\\
В той же час, $\varphi(x) = (x,f)$\\
$\Rightarrow \forall x \in E: (x,f)-(x,f') = (x,f-f') = 0$\\
$\Rightarrow f-f' \in E^{\perp} = \{0\} \Rightarrow f' = f$ \qed
\bigline
\th{5.5.5. Теорема Ріса} (для півторалінійних функціоналів)\\
Задано $E$ - евклідовий простір із $(\cdot, \cdot)$\\
$\varphi(\cdot, \cdot): E \times E \to \mathbb{R} (\mathbb{C})$ - наш півторалінійний функціонал\\
Тоді $\exists! A: E \to E$ - такий лінійний оператор, що:\\
$\forall x,y \in E: \varphi(x,y) = (x, Ay)$\\
\proof
Зафіксуємо $y \in E$, тоді $\varphi(x,y) = \psi_y(x)$ - лінійний функціонал над $E$\\
За попередньою теоремою, для нього $\exists! f_y \in E: \psi_y(x) = (x,f_y)$\\
Отримаємо відображення $E \ni y \overset{A}{\to} f_y \in E$\\
$Ay = f_y$, тобто\\
$\varphi(x,y) = \psi_y(x) = (x,f_y) = (x, Ay)$
\bigline
Доведемо, що побудоване відображення $A$ є лінійним оператором\\
$\forall y_1, y_2 \in E: \forall \alpha \in \mathbb{R} (\mathbb{C}):$\\
$y = \alpha y_1 + y_2$\\
З одного боку:\\
$\varphi(x,y) = (x,Ay)$\\
З іншого боку:\\
$\varphi(x,y) = \varphi(x, \alpha y_1 + y_2) = \alpha \varphi(x,y_1) + \varphi(x,y_2) = \alpha(x,Ay_1) + (x, Ay_2) = (x, \alpha Ay_1) + (x, Ay_2) = (x, \alpha Ay_1 + Ay_2)$\\
Таким чином: $Ay = A(\alpha Ay_1 + Ay_2) = \alpha Ay_1 + Ay_2$
\bigline
Доведемо єдиність
Нехай $\exists A': \forall x,y \in E: \varphi(x,y) = (x,A'y)$\\
Тоді $\forall x,y \in E: (x, Ay) = \varphi(x,y) = (x, A'y)$\\
$\Rightarrow 0 = (x,Ay) - (x,A'y) = (x,(A-A')y)$\\
$\Rightarrow (A - A')y=0 \Rightarrow A=A'$ \qed
\bigline
\defin{5.5.6.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $A: E \to E$ - лінійний опреатор\\
За теоремою Ріса, $\exists !B: E \to E: \forall x,y \in E: (Ax,y) = \varphi(x,y) = (x,By)$\\
Оператор $B$ називається \textbf{спряженим до} $A$\\
Позначення: $A^*$\\
Тобто якщо $\forall A: E \to E: \exists! A^*: E \to E:$\\
$\forall x,y \in E: (Ax,y)=(x,A^*y)$
\bigline
\prp{5.5.7. Властивості}\\
0) $I: E \to E: I^* = I$ \hspace{1cm} $0: E \to E: 0^* = 0$\\
1) $(A+B)^* = A^* + B^*$\\
2) $(\alpha A)^* = \overline{\alpha} A^*$\\
3) $(AB)^* = B^* A^*$\\
4) $(x,Ay) = (A^*x,y)$\\
5) $(A^*)^* = A$\\
\proof
0) $\forall x,y \in E: (Ix,y) = (x,y) = (x, Iy)$\\
З іншого боку,\\
$(Ix,y) = (x,I^*y)$\\
$\Rightarrow I = I^*$\\
Так само й для $0$
\bigline
1) $(x,(A+B)^*y)=((A+B)x,y) = (Ax+Bx,y) = (Ax,y) + (Bx, y) = (x,A^* y)+(x,B^* y) = (x,(A^*+B^*)y)$\\
$\Rightarrow (A+B)^* = A^* + B^*$\\
2) аналогічно
\bigline
3) $(x,(AB)^*y)=(ABx, y) \overset{Bx = z}{=} (Az,y) = (z, A^*y) = (Bx, A^*y) \overset{A^* y = w}{=} (Bx,w) = (x, B^* w) = (x, B^* A^* y)$\\
$\Rightarrow (AB)^* = B^* A^*$
\bigline
4) $(x,Ay) = \overline{Ay, x} = \overline{y, A^*x} = (A^*x, y)$
\bigline
5) $((A^*)^*x,y)=(x,A^*y) = (Ax,y) \Rightarrow (A^*)^* = A$ \qed
\bigline
\th{5.5.8.} Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $A: E \to E$ - лінійний оператор\\
Тоді $E = \ker A^* \bigoplus \Im A$\\
Або $E = \ker A \bigoplus \Im A^*$\\
\proof
$\forall x \in \ker A^*: A^* x = 0$\\
$\iff$ $\forall y \in E: 0 = (A^*x,y) = (x, Ay) \iff x \in (\Im A)^{\perp}$\\
$\ker A^* = (Im A)^{\perp} \Rightarrow E = \Im A \bigoplus (\Im A)^{\perp} = ker A^* \bigoplus \Im A$\\
Друга рівність аналогічна \qed
\bigline
\subsection{Матриця спряженого оператора, зв'язок}
Пригадаємо дещо:\\
Задано $E$ - евклідовий простір із $(\cdot, \cdot)$ та $\{f_1,\dots,f_n\}$ - деякий базис\\
$x = \alpha_1 f_1 + \dots + \alpha_n f_n$ - розклад\\
Вже отримували, що $\Gamma \vec{\alpha} = [\vec{x}]$\\
$\Gamma = \begin{pmatrix}
(f_1,f_1) & (f_2,f_1) & \dots & (f_n,f_1) \\
(f_1,f_2) & (f_2,f_2) & \dots & (f_n,f_2) \\
\vdots & \vdots & \ddots & \vdots \\
(f_1,f_n) & (f_2,f_n) & \dots & (f_n,f_n)
\end{pmatrix}$ \hspace{1cm}
$\vec{\alpha} = \begin{pmatrix}
\alpha_1 \\ \alpha_2 \\ \vdots \\ \alpha_n
\end{pmatrix}$ \hspace{1cm}
$[\vec{x}] = \begin{pmatrix}
(x,f_1) \\ (x,f_2) \\ \vdots \\ (x,f_n)
\end{pmatrix}$
\\
Розглянемо оператор $A: E \to E$\\
Побудуємо його матрицю в базисі $\{f_1,\dots,f_n\}$\\
$Af_1 = a_{11}f_1 + a_{21}f_2 + \dots + a_{n1}f_n$\\
Коефіцієнти $a_{11},a_{21},\dots,a_{n1}$ знаходяться за алгоритмом: $\Gamma \vec{\alpha} = [\vec{x}]$\\
Тут $\vec{a_1} = \begin{pmatrix}
a_{11} \\ a_{21} \\ \vdots \\ a_{n1}
\end{pmatrix}$\\
$\Gamma \vec{a_1} = [\vec{Af_1}] \Rightarrow \vec{a_1} = \Gamma^{-1} [\vec{Af_1}]$\\
де $[\vec{Af_1}] = \begin{pmatrix}
(Af_1,f_1) \\ (Af_1,f_2) \\ \vdots \\ (Af_1,f_n)
\end{pmatrix}$\\
Такі самі процедури для $\vec{a_2}, \dots, \vec{a_n}$\\
Тоді $\Gamma \mathbb{A} = [A] \iff \mathbb{A} = \Gamma^{-1} [A]$\\
$[A] = ([\vec{Af_1}],[\vec{Af_2}],\dots,[\vec{Af_n}])$\\
Аналогічні побудови проведемо для спряженого оператора $A^*: E \to E$\\
Тоді $\Gamma \mathbb{A}^* = [A^*] \Rightarrow \mathbb{A}^* = \Gamma^{-1} [A^*]$\\
$[A^*] = ([\vec{A^*f_1}],[\vec{A^*f_2}],\dots,[\vec{A^*f_n}])$\\
Пограємось з ним більш детально:\\
$[A^*] = \begin{pmatrix}
(A^*f_1, f_1) & (A^*f_2, f_1) & \dots & (A^*f_n, f_1) \\
(A^*f_1, f_2) & (A^*f_2, f_2) & \dots & (A^*f_n, f_2) \\
\vdots & \vdots & \ddots & \vdots \\
(A^*f_1, f_n) & (A^*f_2, f_n) & \dots & (A^*f_n, f_n) \\
\end{pmatrix} = \\ =
\begin{pmatrix}
(f_1, Af_1) & (f_2, Af_1) & \dots & (f_n, Af_1) \\
(f_1, Af_2) & (f_2, Af_2) & \dots & (f_n, Af_2) \\
\vdots & \vdots & \ddots & \vdots \\
(f_1, Af_n) & (f_2, Af_n) & \dots & (f_n, Af_n) \\
\end{pmatrix} = 
\begin{pmatrix}
\overline{(Af_1, f_1)} & \overline{(Af_2, f_1)} & \dots & \overline{(Af_n, f_1)} \\
\overline{(Af_1, f_2)} & \overline{(Af_2, f_2)} & \dots & \overline{(Af_n, f_2)} \\
\vdots & \vdots & \ddots & \vdots \\
\overline{(Af_1, f_n)} & \overline{(Af_2, f_n)} & \dots & \overline{(Af_n, f_n)} \\
\end{pmatrix}^T \\ =
\overline{\begin{pmatrix}
(Af_1, f_1) & (Af_2, f_1) & \dots & (Af_n, f_1) \\
(Af_1, f_2) & (Af_2, f_2) & \dots & (Af_n, f_2) \\
\vdots & \vdots & \ddots & \vdots \\
(Af_1, f_n) & (Af_2, f_n) & \dots & (Af_n, f_n) \\
\end{pmatrix}}^T = [\overline{A}]^T$\\
Тоді маємо:\\
$[A^*] = [\overline{A}]^T = \overline{\Gamma \mathbb{A}}^T$\\
$\Rightarrow \mathbb{A}^* = \Gamma^{-1} [A^*] = \Gamma^{-1} \overline{\mathbb{A}}^T \overline{\Gamma}^T$\\
$\overline{\Gamma}^T = \overline{\begin{pmatrix}
(f_1,f_1) & (f_2,f_1) & \dots & (f_n,f_1) \\
(f_1,f_2) & (f_2,f_2) & \dots & (f_n,f_2) \\
\vdots & \vdots & \ddots & \vdots \\
(f_1,f_n) & (f_2,f_n) & \dots & (f_n,f_n)
\end{pmatrix}}^T = \begin{pmatrix}
\overline{(f_1,f_1)} & \overline{(f_2,f_1)} & \dots & \overline{(f_n,f_1)} \\
\overline{(f_1,f_2)} & \overline{(f_2,f_2)} & \dots & \overline{(f_n,f_2)} \\
\vdots & \vdots & \ddots & \vdots \\
\overline{(f_1,f_n)} & \overline{(f_2,f_n)} & \dots & \overline{(f_n,f_n)} \\
\end{pmatrix}^T = \begin{pmatrix}
(f_1,f_1) & (f_1,f_2) & \dots & (f_1,f_n) \\
(f_2,f_1) & (f_2,f_2) & \dots & (f_2,f_n) \\
\vdots & \vdots & \ddots & \vdots \\
(f_n,f_1) & (f_n,f_2) & \dots & (f_n,f_n)
\end{pmatrix}^T = \Gamma$\\
Отримали:\\
1) $\overline{\Gamma}^T = \Gamma$\\
2) $\mathbb{A^*} = \Gamma^{-1} \mathbb{\overline{A}}^T \Gamma$
\bigline
\rm{5.6.} Тепер в евкілдовому просторі нехай $\{e_1,\dots,e_n\}$ - ортонормований базис. Тоді $\Gamma = I$, а отже, $\mathbb{A^*} = \mathbb{\overline{A}}^T$\\
\subsection{Унітарний оператор}
\defin{5.7.1.}Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$\\
Оператор $U: E \to E$ називають \textbf{унітарним}, якщо
\begin{align*}
\forall x,y \in E: (Ux,Uy) = (x,y)
\end{align*}
\prp{5.7.2. Властивості}\\
1) $\ker U = \{0\}$ \hspace{1cm} $\Im U = E$\\
\proof
1) $x \in \ker U \Rightarrow Ux = 0 \Rightarrow 0 = (Ux, Ux) = (x,x) \Rightarrow x = 0$\\
$\dim(\Im U) = \dim E - \dim(\ker U) = \dim E$\\
$\Im U \subset E \Rightarrow \Im U = E$
\bigline
\rm{5.7.2.} У випадку дійсного евклідового простору унітарний оператор ще називають ортогонаьним
\bigline
2) $U$ - унітарний $\iff U^* = U^{-1}$\\
\proof
$\boxed{\Rightarrow}$ Дано: $U$ - унітарний\\
$\ker U = \{0\}, \Im U = E \Rightarrow \exists U^{-1}$\\
Далі $\forall x,y \in E: (Ix,y) = (x,y) = (Ux,Uy) = (U^*(Ux), y) = (U^*Ux,y)$\\
$\Rightarrow U^* U = I$
\bigline
$\boxed{\Leftarrow}$ Дано: $U^* = U^{-1}$\\
$\forall x,y \in E: (x,y) = (Ix, y) = (U^{-1}Ux, y) = (U^*Ux,y) = (Ux, Uy)$\\
$\Rightarrow U$ - унітарний
\bigline
3) Якщо $U$ - унітарний, то $U^*$ - унітарний теж\\
\proof
$\forall x,y \in E: (x,y) = (Ix,y) = (UU^{-1}x,y) = (UU^* x,y) = (U^*x,U^*y)$
\bigline
4) $U$ - ортонормований $\iff$ $U$ переводить ортонормований базис в ортонормований\\
\proof
$\boxed{\Rightarrow}$ Дано: $U$ - унітарний\\
Нехай $\{f_1,\dots,f_n\}$ - якийсь ортонормований базис\\
$(f_j,f_k) = \delta_{jk}$\\
Перевіримо, чи буде ця система $\{g_1 = Uf_1, \dots, f_n = Uf_n\}$ - ортонормованою\\
Дійсно, $(g_j,g_k) = (Uf_j, Uf_k) = (f_j,f_k) = \delta_{jk}$
\bigline
$\boxed{\Leftarrow}$ Дано: $\{f_1,\dots,f_n\}$, $\{g_1,\dots,g_n\}$ - два ортонормованих базиси\\
$Uf_j = g_j$\\
$\forall x \in E: x = \huge \sum_{j=1}^n x_j f_j$
\hspace{1cm}
$\forall y \in E: y = \huge \sum_{k=1}^n y_k f_k$\\
$Ux = \huge U\left(\sum_{j=1}^n x_j f_j \right) = \sum_{j=1}^n x_j g_j$\\
$Uy = \huge U\left(\sum_{k=1}^n y_k f_k \right) = \sum_{k=1}^n y_k g_k$\\
$\huge (Ux, Uy) = \left(\sum_{j=1}^n x_j g_j, \sum_{k=1}^n y_k g_k \right) = \sum_{j=1}^n \sum_{k=1}^n x_j \overline{y_k} (g_j,g_k) =$\\
$(g_j,g_k) = \delta_{jk} = (f_j,f_k)$\\
$= \huge \sum_{j=1}^n \sum_{k=1}^n x_j \overline{y_k} (f_j,f_k) = \left(\sum_{j=1}^n x_jf_j, \sum_{k=1}^n y_k f_k \right) = (x,y)$ \qed
\bigline
\subsection{Самоспряжений оператор}
\defin{5.8.1.} Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$\\
Оператор $A: E \to E$ називають \textbf{самоспряженим}, якщо
\begin{align*}
A^* = A
\end{align*}
\prp{5.8.2. Властивості}\\
Задані $A,B$ - самоспряжені, тоді\\
0) $I,0$ - самоспряжені\\
1) $A+B$ - самоспряжений \hspace{1cm} $\forall \alpha \in \mathbb{R}: \alpha A$ - самоспряжений\\
2) $AB$ - самоспряжений, якщо $AB = BA$\\
3) $\forall x,y: (Ax,y) = (x,Ay)$\\
\proof
0) див. вл. 5.5.7. 0)
\bigline
1) $(A+B)^* = A^* + B^* = A + B$ \hspace{1cm} $(\alpha A)^* = \overline{\alpha} A^* = \alpha A$
\bigline
2) $(AB)^* = B^* A^* = BA = AB$
\bigline
3) $(Ax,y) = (x,A^*y) = (x, Ay)$ \qed
\bigline
\crl{5.8.2. Наслідок Th. 5.5.8.}\\
Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$ та $A: E \to E$ - самоспряжений\\
Тоді $E = \ker A \bigoplus \Im A$
\bigline
\prp{5.8.3. Властивості власних чисел та власних векторів}\\
1) Якщо $\lambda$ - власне число $A$, тоді $\lambda \in \mathbb{R}$\\
2) Якщо $f_1,f_2$ - власні вектори з різними власними числами $\lambda_1, \lambda_2$, то $f_1 \perp f_2$\\
\proof
1) $f$ - власний вектор для власного числа $\lambda$:\\
$Af = \lambda f$\\
Оскільки $f \neq 0$, то $(f,f) \neq 0$\\
$\Rightarrow \lambda (f,f) = (\lambda f, f) = (Af,f) = (f,Af) = (f, \lambda f) = \overline{\lambda} (f,f)$\\
$\Rightarrow \lambda = \overline{\lambda} \in \mathbb{R}$
\bigline
2) $\lambda_1 (f_1,f_2) = (\lambda_1 f_1, f_2) = (Af_1, f_2) = (f_2, Af_1) = (f_1, \lambda_2 f_2) = \overline{\lambda_2} (f_1,f_2) = \lambda_2 (f_1,f_2)$\\
$\Rightarrow (f_1,f_2) = 0$ \qed
\bigline
\th{5.8.4. Спектральна теорема}\\
Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$ та $A: E \to E$ - самоспряжений\\
Тоді в $E$ існує ортонормований базис із власних векторів $A$\\
\proofMI
Індукція за $\dim E$\\
База: $\dim E = 1$\\
$E = span\{f\}: Af = \lambda f$\\
$||f|| = 1 \Rightarrow \{f\}$ - ортонормований
\bigline
Крок: нехай для $\dim E < n$ теорема вкионується\\
Перевіримо для $\dim E = n$\\
$\lambda_0$ - власне число $A$, розглянемо $B = A - \lambda_0 I$ - теж самоспряжений\\
$E = \ker B \bigoplus \Im B$\\
1) $\ker B \neq \{0\}$, $\{e_1,\dots,e_k\}$ - базис $\ker B$\\
Зауважимо, що $\{e_1,\dots,e_k\}$ - власні вектори для $A$ із власним числом $\lambda_0$\\
2) $\Im B$ є інваріантним для $A$. Дійсно:\\
$\forall y \in \Im B: y = Bx = (A-\lambda_0 I)x$\\
$\Rightarrow Ay = A(A-\lambda_0 I)x = (A-\lambda_0 I)(Ax) = B(Ax) \in \Im B$\\
$\dim \Im B < \dim E$\\
Розглянемо  $A|_{\Im B}$ - звужений оператор - теж самоспряжений\\
Дійсно, $\forall y_1,y_2 \in \Im B: (A|_{\Im B} y_1, y_2) = (Ay_1, y_2) = (y_1, Ay_2) = (y_1, A|_{\Im B} y_2)$\\
За припущенням індукції, $\exists \{e_{k+1},\dots,e_n\}$ - ортонормований базис власних векторів $A|_{\Im B}$\\
$\lambda_j e_j = A|_{\Im B} e_j = Ae_j$\\
Отже, $\{e_{k+1},\dots,e_n\}$ - ортонормований базис власних векторів $A$ в $\Im B$\\
Розглянемо $\{e_1,\dots,e_k,e_{k+1},\dots,e_n\}$\\
Оскільки $E = \ker B \bigoplus \Im B$, то $\{e_1,\dots,e_k,e_{k+1},\dots,e_n\}$ - ортонормований базис в $E$ та всі вони є власними векторами для $A$ \qed
\bigline
\subsection{Квадратичні форми}
\defin{5.9.1.} Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$ та $A: E \to E$ - лінійний оператор\\
\textbf{Квадратичною формою} на $E$ називають відображення: $S: E \to \mathbb{R} (\mathbb{C})$, таке, що:
\begin{align*}
\forall x \in E: S(x) = (x,Ax)
\end{align*}
Інший варіант: $S(x) = \varphi(x,x)$ - півторалінійний функціонал
\bigline
\textbf{Відновлення оператора за квадратичною формою}\\
\prp{5.9.2. Поляризаційна тотожність}\\
Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$ та $S(x)$ - квадратична форма на $E$, що задається півторалінійним фукнціоналом $\varphi(x,y)$ на $\mathbb{C}$\\
Тоді\\
$\forall x,y \in E: 4 \varphi(x,y) = S(x+y) - S(x-y) + i(S(x+iy)-S(x-iy))$\\
В дійсному випадку:\\
$2\varphi(x,y) - 2\varphi(y,x) = S(x+y)- S(x-y)$\\
\proof
1) Випадок $\mathbb{C}$\\
$S(x+y) - S(x-y) + i(S(x+iy)-S(x-iy)) = \\ \varphi(x+y, x+y) - \varphi(x-y,x-y) + i(\varphi(x+iy,x+iy)-\varphi(x-iy,x-iy)) = \\
= \varphi(x,x) + \varphi(x,y) + \varphi(y,x) + \varphi(y,y) - \\
- (\varphi(x,x)-\varphi(x,y)-\varphi(y,x)+\varphi(y,y)) + \\
+ i(\varphi(x,x)-i\varphi(x,y)-i\varphi(y,x)-i i\varphi(y,y)) - \\
- i(\varphi(x,x)+i\varphi(x,y)-i\varphi(y,x)-ii\varphi(y,y)) = \\
= 2 \varphi(x,y) + 2 \varphi(y,x) + 2 \varphi(x,y) - 2 \varphi(y,x) = 4 \varphi(x,y)$
\bigline
2) Випадок $\mathbb{R}$ - аналогічно \qed
\bigline
\crl{5.9.2.} В комплексному випадку в нас виникає однозначна відповідність\\
 \begin{tikzcd}[every arrow/.append style={shift left}, column sep = huge]
\underset{\textrm{лін. опер.}}{A} \arrow{r}{\textrm{побудова}} & \underset{\textrm{півторалінійний ф-л}}{\varphi(x,y) = (x,Ay)} \arrow{r}{\textrm{побудова}} \arrow{l}{\textrm{Th. Ріса}} & \underset{\textrm{квадр. форма}}{S(x) = \varphi(x,x)} \arrow{l}{\textrm{поляр. тотожн.}} \\
\end{tikzcd}
\bigline
Випадок дійсно значної квадратичної форми:\\
$\forall x \in E: S(x) = \varphi(x,x) = (x,Ax) \in \mathbb{R}$\\
Покажемо, що $A$ - самоспряжений\\
$\boxed{\Rightarrow}$ Дано: $A$ - самоспряжений\\
$S(x) = (x,Ax)$\\
$\overline{S(x)} = \overline{(x,Ax)} = \overline{(Ax,x)} = (x,Ax) = S(x)$\\
Тобто $S(x) \in \mathbb{R}$
\bigline
$\boxed{\Leftarrow}$ Дано: $(x,Ax) \in \mathbb{R}$\\
Скористаємось розкладом: $\forall B: E \to E: \exists ! B_1,B_2$ - самоспряжені: $B = B_1 + i B_2$ (згодом доведу)\\
$A = A_1 + i A_2$\\
$S(x) = (x,Ax)= (x,A_1x) + (x,iA_2x) = (x,A_1x) - i(x,A_2x) \in \mathbb{R}$\\
$\Rightarrow (x,A_2x) = 0 \Rightarrow A_2 = 0$\\
Отже, $A = A_1$ - самоспряжений
\bigline
\prp{5.9.3.} Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$ над $\mathbb{C}$\\
Тоді $\forall B: E \to E: \exists! B_1,B_2$ - самоспряжені: $B = B_1 + i B_2$\\
\proof
Розпишемо самоспряжений оператор $B$ таким чином:\\
$B = \dfrac{B+B^*}{2}+ i \dfrac{B-B^*}{2i}$\\
$B_1 = \dfrac{B+B^*}{2} \Rightarrow (B_1)^* = \left( \dfrac{B+B^*}{2} \right)^* = \dfrac{B+B^*}{2} = B_1$\\
$B_2 = \dfrac{B-B^*}{2i} \Rightarrow (B_2)^* = \left( \dfrac{B^*-B}{2i} \right)^* = \dfrac{B^*-B}{-2i} = \dfrac{B-B^8}{2i} = B_2$\\
\\
Доведемо єдиність:\\
Припустимо, що $B = B_3 + i B_4$\\
Тоді $B_1 + iB_2 = B_3 + iB_3 \iff B_1-B_3 = i(B_4-B_2)$\\
Тоді $B_1-B_3=(B_1-B_3)^* = (i(B_4-B_2))^* = -i(B_4-B_2)^* = -i(B_4-B_2) = -(B_1+B_3)$\\
$\Rightarrow B_1 = B_3$, а тому $B_2 = B_4$ \qed
\bigline
Заданий $E$ - евклідовий простір із $(\cdot, \cdot)$ над $\mathbb{R}$\\
$S(X) = \varphi(x,x)$\\
Ми отримали рівність:\\
$S(x+y)-S(x-y) = 2\varpi(x,y) + 2\varphi(y,x)$\\
Таким чином, за квадратичною формою відновлюється симетрична частина півторалінійного (білінійного) функціоналу:\\
$\varphi(x,y)$ - білінійний\\
$\varphi(x,y) =  \underbrace{\dfrac{1}{2} \left(\varphi(x,y) + \varphi(y,x) \right)}_{= \varphi_{sim}} + \underbrace{\dfrac{1}{2} \left(\varphi(x,y) - \varphi(y,x) \right)}_{= \varphi_{cosim}}$\\
Маємо, що $\varphi_{sim}(y,x) = \varphi_{sim}(x,y)$ - симетричний\\
А $\varphi_{cosim}(y,x) = -\varphi_{cosim}(x,y)$ - кососиметричний\\
Отже, $\varphi = \varphi_{sim} + \varphi_{cosim}$\\
Пригадаємо, що $\varphi(x,y) = (x,Ay)$\\
$\Rightarrow \varphi_{sim}(x,y) = \dots = \left(x, \dfrac{A+A^*}{2}x \right)$\\
Отже, отримали, що в дійсному випадку квадратичній формі однозначно відповідає\\
\begin{tikzcd}[every arrow/.append style={shift left}, column sep = huge]
S(x) \arrow{r}{\textrm{поперед.}} & \varphi_{sim}(x,y) \arrow{l}{\textrm{побудова}} \arrow{r}{\textrm{Th. Ріса}} & \underset{самоспряжений}{A} \arrow{l}{\textrm{побудова}}
\end{tikzcd}
\bigline
\prp{5.9.4.} Заданий $E$ - евклідовий простір із $(\cdot,\cdot)$\\
Тоді $\forall B: \exists! B_1$ - самоспряжений, $\exists! B_2$ - кососпряжений, тобто $B_2^* = -B_2$: $B = B_1 + B_2$\\
\proof
Запишемо $B$ таким чином:\\
$B = \dfrac{B+B^*}{2} + \dfrac{B-B^*}{2} = B_1 + B_2$\\
Зрозуміло, що перший - сампоспряжений, а другий - кососпряжений\\
Єдиність доводиться аналогічно \qed
\bigline
Розглянемо таку квадратичну форму:\\
$S_B(x) = (x,Bx) = (x,B_1x) + (x,B_2x) \boxed{=} $\\
$(x,B_2x) = (B_2*x,x) = -(B_2x,x) = -(x,B_2x) \Rightarrow (x,B_2x) = 0$\\
Тобто квадратична форма для кососиметричного оператору $\equiv 0$\\
$\boxed{=} (x,B_1x)$
\bigline
\textbf{Приведення квадратичної форми до канонічного вигляду}\\
Заданий $E$ - евклідовий простір із $(\cdot,\cdot)$\\
$S(x) = (x,Ax)$ - дійсно значна, і $A$ - самоспряжений\\
Тоді в $E$ існує ортонормований базис з власних векторів $A$ - $\{f_1,\dots,f_n\}$\\
$\mathbb{A}_f = \begin{pmatrix}
\lambda_1 & \dots & 0 \\
\vdots & \ddots & \vdots \\
0 & \dots & \lambda_n
\end{pmatrix}$\\
$U$ - перехід від розкладу за $\{f_1,\dots,f_n\}$ до розкладу в стандартний базис\\
Тоді\\
$A = U \mathbb{A}_{f} U^{-1} = U \mathbb{A}_{f} U^{*}$\\
Тоді\\
$S(x) = (x,Ax) = (x,U \mathbb{A}_{f} U^{*} x) = (U^*x, \mathbb{A}_{f} U^{*} x) =$\\
$U^* x = y = y_1f_1 + \dots + y_nf_n$\\
$= \huge \left(\sum_{j=1}^n y_jf_j, \mathbb{A}_{f} \sum_{k=1}^n y_k f_k \right) \sum_{j=1}^n \sum_{k=1}^n y_j \overline{y_k} (f_j, \mathbb{A}_f f_k) = \sum_{j=1}^n \sum_{k=1}^n y_j \overline{y_k} \lambda_k (f_j,f_k) = \sum_{j=1}^n \lambda_j (y_j)^2$\\
Висновок: дійснозначна квадратична форма $S(x) = (x,Ax)$ має канонічний вигляд:\\
$S(x) = \huge \sum_{j=1}^n \lambda_j (y_j)^2$\\
$U^*x = y = \huge \sum_{j=1}^n y_j f_j$\\
\subsection{Знаковизначеність лінійного оператора, матриці}
Заданий $E$ - евклідовий простір із $(\cdot,\cdot)$ і $A$ - самоспряжений оператор\\
(Або заданий $E = \mathbb{R}^n (\mathbb{C}^n)$ - евклідовий простір із $(\cdot,\cdot)$ і $\mathbb{A}$ - симетрична матриця)\\
\defin{5.10.1.} Оператор $A$ (матриця $\mathbb{A}$) називається:\\
- \textbf{строго додатньо визначеною}, якщо $\forall x \neq 0: S(x) = (x,Ax) > 0$\\
- \textbf{строго від'ємно визначеною}, якщо $\forall x \neq 0: S(x) = (x,Ax) < 0$\\
- \textbf{невід'ємно визначеною}, якщо $\forall x \neq 0: S(x) = (x,Ax) \geq 0$\\
- \textbf{недодатньо визначеною}, якщо $\forall x \neq 0: S(x) = (x,Ax) \leq 0$\\
Позначення: $A > 0$ і т.д.
\bigline
\th{5.10.2. Критерій знаковизначеності}\\
Заданий $E$ - евклідовий простір із $(\cdot,\cdot)$ і $A$ - самоспряжений оператор\\
Тоді:\\
$A > 0 \iff$ всі власні числа $\lambda_j > 0$\\
$A < 0 \iff$ всі власні числа $\lambda_j < 0$\\
Для нестрогих нерівностей теж саме\\
\proof
$S(x) = (Ax,x) = \huge \sum_{j=1}^n \lambda_j |y_j|^2$\\
$A > 0 \Rightarrow \forall x \Rightarrow \forall \vec{y} = \begin{pmatrix}
y_1 \\ \dots \\ y_n
\end{pmatrix}: \huge \sum_{j=1}^n \lambda_j |y_j|^2 > 0 \Rightarrow$\\
$\vec{y} = \begin{pmatrix}
1 \\ 0 \\ \dots \\ 0
\end{pmatrix}, \lambda_1 > 0 \dots \vec{y} = \begin{pmatrix}
0 \\ 0 \\ \dots \\ 1
\end{pmatrix}, \lambda_n > 0$\\
А якщо $\lambda_1,\dots,\lambda_n > 0$, то автоматично $S(x) > 0$, тоді $A>0$\\
Решта випадків аналогічні \qed
\bigline
\prp{5.10.3.} $A \leq 0 \iff (-A) \geq 0$\\
\textit{За визначенням}
\bigline
\th{5.10.4. Критерій Сільвестра} (знаковизначеність матриці)\\
Задана матриця $A$ - симетрична\\
Обчислимо $\Delta_1 = M_1^1, \Delta_2 = M_{12}^{12}, \dots, \Delta_k = M^{12\dots k}_{12 \dots, k}$ - головні кутові мінори\\
$A>0 \iff \forall k: \Delta_k > 0$\\
$A < 0 \iff \forall k: (-1)^k \Delta_k > 0$\\
Для нестрогої визначеності теж саме\\
\textit{Без доведення (див. підручник Гантмахер "Теория матриц")}
\bigline
\subsection{Зведення кривих та поверхень другого порядку до канонічного вигляду}
Маємо загальний вигляд кривої другого порядку:\\
$a_{11}x^2 + 2a_{12}xy + a_{22}y^2 + b_1x + b_2y + c = 0$\\
Розглянемо квадратну частину:\\
$a_{11}x^2 + 2a_{12}xy + a_{22}y^2 = \left( \begin{pmatrix}
x \\ y
\end{pmatrix} \begin{pmatrix}
 a_{11} & a_{12} \\
 a_{12} & a_{22}
\end{pmatrix}, \begin{pmatrix}
x \\ y
\end{pmatrix} \right)$ - квадратична форма, а матриця $A = \begin{pmatrix}
a_{11} & a_{12} \\
a_{12} & a_{22}
\end{pmatrix}$ - відповідно самоспряжена матриця
\bigline
Також маємо загальний вигляд поверхну другого порядку:\\
$a_{11}x^2 + a_{22}y^2 + a_{33}z^2 + 2a_{12}xy + 2a_{13}xz + 2a_{23}yz + b_1x + b_2y + b_3z + c = 0$\\
Аналогічно розглянемо квадратну частину:\\
$a_{11}x^2 + a_{22}y^2 + a_{33}z^2 + 2a_{12}xy + 2a_{13}xz = \left( \begin{pmatrix}
x \\ y \\ z
\end{pmatrix}, \begin{pmatrix}
a_{11} & a_{12} & a_{13} \\
a_{12} & a_{22} & a_{23} \\
a_{13} & a_{23} & a_{33}
\end{pmatrix} \begin{pmatrix}
x \\ y \\ z
\end{pmatrix} \right)$ - квадратична форма, з матрицею $A = \begin{pmatrix}
a_{11} & a_{12} & a_{13} \\
a_{12} & a_{22} & a_{23} \\
a_{13} & a_{23} & a_{33}
\end{pmatrix}$
\bigline
Тоді рівняння кривої (випадок $\mathbb{R}^2$) та поверхні (випадок $\mathbb{R}^3$) другого порядку записується таким чином:\\
$(\vec{x}, A \vec{x}) + (\vec{b}, \vec{x}) + c = 0$\\
Це рівняння зведемо до канонічного вигляду:\\
1. Оскільки $A$ - самоспряжений, то існує ортонормований базис із власних векторів $A$\\
$U$ - унітарна матриця переходу: $A = U A_{\textrm{diag}} U^*$\\
$(\vec{x}, A\vec{x}) = (\vec{x}, U A_{\textrm{diag}} U^* \vec{x}) = (U^* \vec{x}, A_{\textrm{diag}} U^* \vec{x}) = (\vec{y}, A_{\textrm{diag}} \vec{y}) = \left[ \begin{gathered} \lambda_1 y_1^2 + \lambda_2 y_2^2 \\
\lambda_1 y_1^2 + \lambda_2 y_2^2 + \lambda_3 y_3^2
 \end{gathered} \right.$

2. $(\vec{b}, \vec{x}) = (U^* \vec{b}, U^* \vec{x}) = (U^*\vec{b}, \vec{y})$
Знаходимо $\vec{\tilde{b}} = U^* \vec{b}$, тоді\\
$(\vec{b}, \vec{x}) = (\vec{\tilde{b}}, \vec{y}) = \left[ \begin{gathered} \tilde{b_1}y_1 + \tilde{b_2}y_2 \\ \tilde{b_1}y_1 + \tilde{b_2}y_2 + \tilde{b_3}y_3 \end{gathered} \right.$\\
Остаточно отримаємо\\
$\lambda_1 y_1^2 + \lambda_2 y_2^2 + \lambda_3 y_3^2 + \tilde{b_1}y_1 + \tilde{b_2}y_2 + \tilde{b_3}y_3 + c = 0$
\bigline
Нехай $\lambda_1, \lambda_2, \lambda_3 \neq 0$\\
Виділимо повні квадрати:\\
$\lambda_1 \left( y_1 + \dfrac{\tilde{b_1}}{2\lambda_1} \right)^2 + \lambda_2 \left( y_2 + \dfrac{\tilde{b_2}}{2\lambda_2} \right)^2  + \lambda_3 \left( y_3 + \dfrac{\tilde{b_3}}{2\lambda_3} \right)^2 = - c + \dfrac{\tilde{b_1}^2}{4 \lambda_1} + \dfrac{\tilde{b_2}^2}{4 \lambda_2} + \dfrac{\tilde{b_3}^2}{4 \lambda_3}$\\
Зробимо заміни:\\
$
z_1 = y_1 + \dfrac{\tilde{b_1}}{2\lambda_1} \hspace{0.5cm}
z_2 = y_2 + \dfrac{\tilde{b_2}}{2\lambda_2} \hspace{0.5cm}
z_3 = y_3 + \dfrac{\tilde{b_3}}{2\lambda_3} \hspace{0.5cm}
\tilde{c} = -c + \dfrac{\tilde{b_1}^2}{4 \lambda_1} + \dfrac{\tilde{b_2}^2}{4 \lambda_2} + \dfrac{\tilde{b_3}^2}{4 \lambda_3}
$\\
Отримаємо:\\
$\lambda_1 z_1^2 + \lambda_2 z_2^2 + \lambda_3 z_3^2 = \tilde{c}$
\bigline
Випадок, коли лише $\lambda_1 = 0$:\\
Робимо ті самі процедури та отримаємо:\\
$\lambda_2 \left( y_2 + \dfrac{\tilde{b_2}}{2\lambda_2} \right)^2  + \lambda_3 \left( y_3 + \dfrac{\tilde{b_3}}{2\lambda_3} \right)^2 + \tilde{b_1}y_1 = - c + \dfrac{\tilde{b_1}^2}{4 \lambda_1} + \dfrac{\tilde{b_2}^2}{4 \lambda_2} + \dfrac{\tilde{b_3}^2}{4 \lambda_3}$\\
Зробимо заміни:\\
$
z_2 = y_2 + \dfrac{\tilde{b_2}}{2\lambda_2} \hspace{0.5cm}
z_3 = y_3 + \dfrac{\tilde{b_3}}{2\lambda_3} \hspace{0.5cm}
\tilde{c} = -c + \dfrac{\tilde{b_2}^2}{4 \lambda_2} + \dfrac{\tilde{b_3}^2}{4 \lambda_3} \hspace{0.5cm}
z_1 = y_1 - \dfrac{\tilde{c}}{\tilde{b_1}}
$\\
$\lambda_2 z_2^2 + \lambda_3 z_3^2 + \tilde{b_1}z_1 = 0$ - а це є параболоїдом\\
Випадок $\tilde{b_1} = 0$: в $\mathbb{R}^3$ - циліндр, а в $\mathbb{R}^2$ - пара прямих
\bigline
Випадок, коли $\lambda_1 = \lambda_2 = 0$ (це вже лише для $\mathbb{R}^3$):\\
$\lambda_3 y_3^2 + \tilde{b_1}y_1 + \tilde{b_2}y_2 + \tilde{b_3}y_3 + c = 0$\\
Виникає одна мрія: $\tilde{b_1} = 0$\\
$\vec{\tilde{b}} = U^* \vec{b}$\\
$U = (\vec{f_1}, \vec{f_2}, \vec{f_3})$, де $\vec{f_1}, \vec{f_2}$ - власні числа для $\lambda_1 = \lambda_2$, а $\vec{f_3}$ - для $\lambda_3 \neq 0$\\
$U^* \vec{b} = \begin{pmatrix}
 \overset{\leftarrow}{f_1} \cdot \vec{b} \\ \overset{\leftarrow}{f_2} \cdot \vec{b} \\ \overset{\leftarrow}{f_3} \cdot \vec{b}
\end{pmatrix} = \begin{pmatrix}
 (\vec{f_1}, \vec{b}) \\ (\vec{f_2}, \vec{b}) \\ (\vec{f_3}, \vec{b})
\end{pmatrix} = \begin{pmatrix}
 \tilde{b_1} \\ \tilde{b_2} \\ \tilde{b_3}
\end{pmatrix}$\\
Щоб здійснити мрію, треба, щоб $(\vec{f_1}, \vec{b}) = 0$\\
Знаходимо $\vec{f_3}$ - власний для $\lambda_3$\\
Тоді $span\{e_3\}^{\perp}$ - простір власних векторів для $\lambda_1 = \lambda_2 = 0$\\
Тоді $\vec{f_1} = [\vec{f_3}, \vec{b}] \perp \vec{b} \Rightarrow \tilde{b_1} = 0$\\
$f_1$ - власний для $\lambda = 0$ та $f_2 = [\vec{f_1}, \vec{f_3}] \perp \vec{f_1}, \vec{f_3}$\\
Параметризуємо $\vec{f_1}, \vec{f_2}, \vec{f_3}$ - отримаємо ортонормований базис\\
$U$ - матриця перехода $\vec{\tilde{b}} = \begin{pmatrix}
0 \\ \tilde{b_2} \\ \tilde{b_3}
\end{pmatrix}$\\
Тоді:\\
$\lambda_3 y_3^2 + \tilde{b_3} y_3 + \tilde{b_2} y_2 + c = 0$\\
$\lambda_3 \left(y_3 + \dfrac{\tilde{b_3}}{2 \lambda_3} \right)^2 + \tilde{b_2} \left(y_2 + \dfrac{c - \dfrac{\tilde{b_3}^2}{4\lambda_3}}{\tilde{b_2}} \right) = 0$\\
Зробимо заміни:\\
$z_1 = y_1 \hspace{0.5cm}
z_2 = y_2 + \dfrac{c - \dfrac{\tilde{b_3}^2}{4\lambda_3}}{\tilde{b_2}} \hspace{0.5cm}
z_3 = y_3 + \dfrac{\tilde{b_3}}{2 \lambda_3}
$\\
Отримаємо:\\
$\lambda_3 z_3^2 + \tilde{b_2} z_2 = 0$ - а це є параболічним циліндром\\
При $\tilde{b_2} = 0$ отримаємо пару площин
\bigline
\textbf{The end}
$\scaleobj{5}{\blacksquare}$\\
\newpage
\section{Альтернативні пояснення}
\th{1.5.5.} Якщо $\underset{\textrm{є лінійно незалежною}}{\{y_1, \dots, y_n \}} \prec \{x_1, \dots, x_m \}$, то $n \leq m$\\
\proof (вже не МІ)\\
\textbf{!}Припустимо, що все ж таки $n > m$\\
Розглянемо елемент $y_1$. За умовою теореми, \\
$y_1 = \alpha_1 x_1 + \dots + \alpha_m x_m$\\
Оскільки система $\{y_1,\dots,y_n\}$ - л.н.з., то $y_1 \neq 0$\\
Тоді, не втрачаючи загальності, $\alpha_1 \neq 0$. Виразимо тепер $x_1$, маємо:\\
$x_1 = \alpha_1^{-1}y_1 - \alpha_1^{-1}\alpha_2 x_2 - \dots - \alpha_1^{-1} \alpha_m x_m$. Для довідки, $x_1 \neq 0$\\
З цього рівняння випливає, що $\{x_1, x_2, \dots,x_m\} \prec \{y_1, x_2, \dots,x_m\}$\\
Розглянемо елемент $y_2$. За щойно отриманою умовою та властивості транзитивності, \\
$y_2 = \beta_1 y_1 + \beta_2 x_2 + \dots + \beta_m x_m$\\
Аналогічно $y_2 \neq 0$, отже, не втрачаючи загальності знову, $\beta_2 \neq 0$. Виражаємо $x_2$:\\
$x_2 = \beta_2^{-1}y_2 - \beta_2^{-1}\beta_1 y_1 - \dots - \beta_2^{-1} \beta_m x_m$. І теж $x_2 \neq 0$\\
З цього рівняння випливає, що $\{y_1,x_2,\dots,x_m\} \prec \{y_1,y_2,\dots,x_m\}$\\
І так можемо продовжувати допоки не дістанемося до ланцюга:\\ $\{y_1,\dots, y_{n-1}, x_m\} \prec \{y_1,\dots,y_n\}$\\
Остаточно: $\{y_1,\dots,y_n\} \prec \{y_1,\dots,y_n\}$ - суперечність\textbf{!} Тому що система ліворуч - л.н.з., тому жодний елемент не виражається через лінійну комбінацію системи праворуч\\
Тому $n \leq m$ \qed
\bigline
\section*{Про власні числа та вектори}
\defin{} \textbf{Алгебраїчною кратністю} власного числа $\lambda_0$ ми будемо називати степінь дужки $(\lambda - \lambda_0)$, яка виникає в результаті розв'язання характеристичного полінома
\bigline
\defin{} \textbf{Геометричною кратністю} власного числа $\lambda_0$ ми будемо називати кількість л.н.з. власних векторів $\vec{f}$, пов'язаних з ним\\
Або $r = \dim L_{\lambda}$
\bigline
\ex{} Дано $A = \begin{pmatrix}
1 & 1 \\
0 & 1
\end{pmatrix}$\\
$\det(A-\lambda I) = (1-\lambda)^2$\\
Розглянемо $\lambda = 1$:\\
$(A-I)\vec{f} = \vec{0}$\\
$\begin{pmatrix}
0 & 1 \\
0 & 1
\end{pmatrix} \vec{f} = \vec{0}$\\
$\Rightarrow f_2 = 0$\\
Тому маємо вектор $\vec{f} = \begin{pmatrix}
f_1 \\ 0
\end{pmatrix} = f_1 \begin{pmatrix}
1 \\ 0
\end{pmatrix}$\\
Отже: алгебраічна кратність $= 2$, а геометрична $= 1$
\bigline
\crl{} Нехай в нас є матриця оператора $A$ розміром $n \times n$. Якщо для кожного власного числа геометрична кратність дорівнює алгебраїчної, то тоді $\mathbb{A}_f$ - діагоналізована матриця
\bigline
\th{} Якщо алгебраїчна кратність власного числа $\lambda$ дорівнює $k$, то її геометрична кратність принаймні $1$, але не більше $k$
\bigline
\defin{} Задано $A: L \to L$ - лінійний оператор, $\dim L = n$\\
\textbf{Ланцюгом узагальнених власних векторів} для $A$ із власним числом $\lambda$ називають послідовність векторів $h_1, \dots, h_k$, такі, що:\\
$f(h_1) = \lambda h_1$\\
$f(h_i) = \lambda h_i + h_{i-1}, i=2,\dots,k$\\
\textit{Це по суті означення приєднаних векторів}
\bigline
\lm{} Задано $A: L \to L$ - лінійний оператор, $\dim L = n$\\
Тоді існує ланцюги $C_1,\dots,C_m$ узагальнених власних векторів такі що вони формують базис $L$\\
\proofMI
Задано $\lambda$ - власне число для $f$\\
Нехай $B: L \to L$ визначене наступним чином:\\
$Bx = Ax - \lambda x = (A - \lambda I)x$\\
Оскільки існує ненульовий власний вектор для власного числа $\lambda$, то $\dim (\ker B) \neq 0$\\
Тому $\dim (\Im B) \neq n$\\
\newpage
\section*{Чернетка}
$A: \underset{= \mathbb{R}^8}{L} \to L$, $\dim L = 8$\\
$A = \begin{pmatrix}
2 & 0 & 1 & 0 & -1 & 0 & 0 & 0 \\
0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 5 & 0 & -9 & 0 & 0 \\
2 & 0 & 1 & 0 & 3 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0 & -1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 4 & 4 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 4 \\
\end{pmatrix}$\\
$\det (A - \lambda I) = -(\lambda - 2)^6 (\lambda - 4)^2 = 0$\\
Оберемо $\lambda = 2$\\
$B = (A - 2I): L \to L$\\
$\Im B = span \left\{ \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 2 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 1 \\ 0 \\ -1 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 0 \\ 3 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 2 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 4 \\ 2 \end{pmatrix} \right\}$\\
$\dim \Im B = 5 < \dim L$, $\Im B$ - інваріантний до $A$\\
Розширимо $\Im B$ до базису $L$ цими векторами: $\left\{ \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix} \right\}$\\
Тоді отримаємо нову матрицю нашого оператора:\\
$\mathbb{A}_f = \begin{pmatrix}
4 & 2 & 0 & 0 & 0 \vline & 0 & 0 & 0\\
-2 & 0 & 0 & 0 & 0 \vline & 0 & 0 & 1 \\
0 & 0 & 2 & 0 & 0 \vline & 0 & 1 & 0 \\
0 & 0 & 0 & 4 & 4 \vline & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 4 \vline & 0 & 0 & 0\\
\hline
0 & 0 & 0 & 0 & 0 \vline & 2 & 0 & 0\\
0 & 0 & 0 & 0 & 0 \vline & 0 & 2 & 0 \\
0 & 0 & 0 & 0 & 0 \vline & 0 & 0 & 2\\
\end{pmatrix}$\\
Замість початкової матриці будемо розглядувати щойно отриману: все рівно власні числа не змінюються від цього\\
$\Rightarrow$ створимо $A|_{\Im B}: \Im B \to \Im B$\\
$A|_{\Im B} = \begin{pmatrix}
4 & 2 & 0 & 0 & 0 \\
-2 & 0 & 0 & 0 & 0 \\
0 & 0 & 2 & 0 & 0 \\
0 & 0 & 0 & 4 & 4 \\
0 & 0 & 0 & 0 & 4 \\
\end{pmatrix}$
\newpage
\section*{Чернетка 2}
$A: \underset{= \mathbb{R}^4}{L} \to L, \dim L = 4$\\
$A = \begin{pmatrix}
0 & 1 & 0 & 0 \\
-1 & 2 & 0 & 0 \\
-2 & 2 & 1 & 0 \\
0 & 1 & 0 & -1
\end{pmatrix}$\\
$\det(A-\lambda I) = (\lambda - 1)^3(\lambda + 1) = 0$\\
$\lambda = 1$\\
$B = A - I = \begin{pmatrix}
-1 & 1 & 0 & 0 \\
-1 & 1 & 0 & 0 \\
-2 & 2 & 0 & 0 \\
0 & 1 & 0 & -2
\end{pmatrix}$\\
$\Im B = span\left\{ \begin{pmatrix} -1 \\ -1 \\ -2 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 0 \\ 0 \\ -2 \end{pmatrix} \right\}$ - інваріантний підпростір, \\ $\dim (\Im B) = 2$\\
Розширимо до базису $L$ векторами $\begin{pmatrix} 1 \\ 0 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \end{pmatrix}$\\
Отримаємо матрицю:\\
$A = \begin{pmatrix}
1 & 0 & \vline & 1 & -1 \\
\dfrac{1}{2} & -1 & \vline & 0 & -\dfrac{1}{2} \\
\hline
0 & 0 & \vline & 1 & 0 \\
0 & 0 & \vline & 0 & 1
\end{pmatrix}$\\
Оскільки $\Im B$ - інваріантний до $A$, то створимо звужений оператор $A|_{\Im B}: \Im B \to \Im B$\\
$A|_{\Im B} = \begin{pmatrix}
1 & 0 \\
\dfrac{1}{2} & -1
\end{pmatrix}$
$\lambda = 1:$\\
$(A|_{\Im B} - I)\vec{f} = \begin{pmatrix}
0 & 0 \\
\dfrac{1}{2} & -2
\end{pmatrix} \vec{f} = \vec{0}$\\
$\Rightarrow \vec{f} = \begin{pmatrix}
-4f_2 \\ f_2
\end{pmatrix} = f_2 \begin{pmatrix}
-4 \\ 1
\end{pmatrix}$\\
$(A-I)\vec{f} = \begin{pmatrix}
-1 & 1 & 0 & 0 \\
-1 & 1 & 0 & 0 \\
-2 & 2 & 0 & 0 \\
0 & 1 & 0 & -2
\end{pmatrix} \vec{f} = \vec{0}$\\
$\Rightarrow \vec{f} = f_3 \begin{pmatrix}
0 \\ 0 \\ 1 \\ 0
\end{pmatrix} + f_4 \begin{pmatrix}
2 \\ 2 \\ 0 \\ 1
\end{pmatrix}$

\section{Трошки про матриці}
    	\subsection{Основні означення}
    	\defin{1.1.1. Матрицею} називають прямокутну таблицю з чисел\\
    	Позначення: $A = \begin{pmatrix}
    	a_{11} & a_{12} & a_{13} & \dots & a_{1n} \\
    	a_{21} & a_{22} & a_{23} & \dots & a_{2n} \\
    	\vdots & \vdots & \vdots & \ddots & \vdots\\
    	a_{m1} & a_{m2} & a_{m3} & \dots & a_{mn} \\
    	\end{pmatrix}$\\
    	Тут матриця містить такий розмір: \textbf{$m$ рядків $\times$ $n$ стовпчиків}\\
    	$a_{ij}$ - \textbf{елемент} матриці, $i=\overline{1,m}; i=\overline{1,n};$
    	\bigline
    	Якщо кількість рядків та стовпчиків однакова, то така матриця - \textbf{квадратна}
    	\bigline
    	\defin{1.1.2.} Дві матриці $A,B$ однакових розмірів називають \textbf{рівними}, якщо $a_{ij} = b_{ij}$ , тут $i=\overline{1,m}; i=\overline{1,n};$\bigline
    	\defin{1.1.3.} \textbf{Одиничну матрицю} визначають таку квадратну матрицю\\
    	Позначення: $I = \begin{pmatrix}
    	1 & 0 & \dots & 0 \\
    	0 & 1 & \dots & 0 \\
    	\vdots & \vdots & \ddots & \vdots \\
    	0 & 0 & \dots & 1 \\
    	\end{pmatrix}$
    	\bigline
    	\defin{1.1.4.} \textbf{Нульову матрицю} називають матрицю (не обов'язково квадратну), де всі елементи нулеві\\
    	Позначення: $O = \begin{pmatrix}
    	0 & \dots & 0 \\
    	\vdots & \ddots & \vdots \\
    	0 & \dots & 0
    	\end{pmatrix}$
    	\bigline
    	\defin{1.1.5.} Задані операції над матрицями:\\
    	\textbf{- додавання};\\
    	$\forall A,B: A = \begin{pmatrix}
    	a_{11} & \dots & a_{1n} \\
    	\vdots & \ddots & \vdots \\
    	a_{m1} & \dots & a_{mn}
    	\end{pmatrix}, B = \begin{pmatrix}
    	b_{11} & \dots & b_{1n} \\
    	\vdots & \ddots & \vdots \\
    	b_{m1} & \dots & b_{mn}
    	\end{pmatrix}$\\
    	$A + B = \begin{pmatrix}
    	a_{11}+b_{11} & \dots & a_{1n} + b_{1n} \\
    	\vdots & \ddots & \vdots \\
    	a_{m1}+b_{m1} & \dots & a_{mn} + b_{mn}
    	\end{pmatrix}$
    	\bigline
    	\textbf{- множення на скаляр};\\
    	$\forall A: A = \begin{pmatrix}
    	a_{11} & \dots & a_{1n} \\
    	\vdots & \ddots & \vdots \\
    	a_{m1} & \dots & a_{mn}
    	\end{pmatrix}$\\
    	$\forall \lambda \in \mathbb{R}: \lambda A = \begin{pmatrix}
    	\lambda a_{11} & \dots & \lambda a_{1n} \\
    	\vdots & \ddots & \vdots \\
    	\lambda a_{m1} & \dots & \lambda a_{mn}
    	\end{pmatrix}$
    	\bigline
    	А також задані наступні властивості (як доводити, думаю, зрозуміло):\\
    	$\forall A,B,C: \forall \lambda,\mu \in \mathbb{R}:$\\
    	1) $A + B = B + A$\\
	2) $(A + B) + C = A + (B + C)$\\
	3) $\exists O: A + 0 = A$\\
	4) $\exists (-A): A + (-A) = O$\\
	5) $\lambda(A+B) = \lambda A + \lambda B$\\
	6) $A (\lambda + \mu) = \lambda A + \mu A$\\
	7) $\lambda (\mu A) = (\lambda \mu) A)$\\
	8) $1 \cdot A = A$
	\bigline
	\defin{1.1.6. Узгодженими} називають матриці $A$, $B$, якщо кількість стовпчиків $A$ співпадає із кількістю рядків $B$
	\bigline
	\defin{1.1.7.(1)} Визначається \textbf{множення матриць} для $1 \times m$ та $m \times 1$\\
	$p_{11} = \begin{pmatrix}
	a_{11} & a_{12} & \dots a_{1m}
	\end{pmatrix} \cdot \begin{pmatrix}
	b_{11} \\ b_{21} \\ \vdots \\ b_{m1} 
	\end{pmatrix} = a_{11} \cdot b_{11} + a_{12} \cdot b_{21} + \dots + a_{1m} \cdot b_{m1}$
	\bigline
	\defin{1.1.7.(2)} Для довільних узгоджених матриць визначено \textbf{множення матриць}:\\
	$A = \underset{\textbf{m} \times n}{\begin{pmatrix}
	a_{11} & a_{12} & \dots & a_{1n} \\
	a_{21} & a_{22} & \dots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \dots & a_{mn} \\
	\end{pmatrix}}, \hspace{1cm} B = \underset{n \times \textbf{k}}{\begin{pmatrix}
	b_{11} & b_{12} & \dots & b_{1k} \\
    	b_{21} & b_{22} & \dots & b_{2k} \\
    	\vdots & \vdots & \ddots & \vdots \\
    	b_{n1} & b_{n2} & \dots & b_{nk} \\
	\end{pmatrix}}$\\
	$A \cdot B = \underset{\textbf{m} \times \textbf{k}}{\begin{pmatrix}
	p_{11} & p_{12} & \dots & p_{1k} \\
	p_{11} & p_{12} & \dots & p_{1k} \\
	\vdots & \vdots & \ddots & \vdots \\
	p_{m1} & p_{m2} & \dots & p_{mk} \\
	\end{pmatrix}}$\\
	де, за \textbf{Def. 1.1.7.(1)}, $p_{ij}$ - множення $i$-го рядка матриці $A$ на $j$-ий стовпчик матриці $B$\\
	Розмір матриці $A \cdot B$ становить $m \times k$
	\bigline
	\rm{1.1.7.} $A \cdot B \neq B \cdot A$\\
	Один із таких прикладів - це матриці $A = \begin{pmatrix}
	1 & 2 \\
	3 & 4
	\end{pmatrix}$, $B = \begin{pmatrix}
	0 & 1 \\
	0 & 0
\end{pmatrix}$\\
$A \cdot B = \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} = \begin{pmatrix} 0 & 1 \\ 0 & 3 
\end{pmatrix}$\\
$B \cdot A = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} = \begin{pmatrix} 3 & 4 \\ 0 & 0 
\end{pmatrix}$
	\bigline
	Для множення виконуються такі властивості:\\
	1) $(A \cdot B) \cdot C = A \cdot (B \cdot C)$\\
	2) $A \cdot I = I \cdot A$\\
	3) $(\lambda A) \cdot B = A \cdot (\lambda B)$\\
	4) $A \cdot (B+C) = A\cdot B + A\cdot C \hspace{0.5 cm} (A+B)\cdot C = A\cdot C + B \cdot C$\\
	\proof
	Зроблю деякі позначення: \\ $(A \cdot B) = \begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \dots & a_{mn} \\
	\end{pmatrix} \begin{pmatrix}
	b_{11} & \dots & b_{1k} \\
	\vdots & \ddots & \vdots \\
	b_{n1} & \dots & b_{nk} \\
	\end{pmatrix} = \begin{pmatrix}
	q_{11} & \dots & q_{1k} \\
	\vdots & \ddots & \vdots \\
	q_{m1} & \dots & q_{mk}
	\end{pmatrix} = Q$\\
	де $q_{ij} = a_{i1}b_{1j} + \dots + a_{in}b_{nj}$ $(*)$\\
	$(B \cdot C) = \begin{pmatrix}
	b_{11} & \dots & b_{1k} \\
	\vdots & \ddots & \vdots \\
	b_{n1} & \dots & b_{nk} \\
	\end{pmatrix} \begin{pmatrix}
	c_{11} & \dots & c_{1l} \\
	\vdots & \ddots & \vdots \\
	c_{k1} & \dots & c_{kl}
	\end{pmatrix} = \begin{pmatrix}
	r_{11} & \dots & r_{1l} \\
	\vdots & \ddots & \vdots \\
	r_{k1} & \dots & r_{nl}
	\end{pmatrix} = R$ \\
	де $r_{ij} = b_{i1}c_{1j} + \dots + b_{ik}c_{kj}$ $(**)$\\
	Фактично ми доводимо, що:\\
	$Q \cdot C = A \cdot R$\\
	Розглянемо ліву частину:\\
	$Q \cdot C = \begin{pmatrix}
	q_{11} & \dots & q_{1k} \\
	\vdots & \ddots & \vdots \\
	q_{m1} & \dots & q_{mk}
	\end{pmatrix} \begin{pmatrix}
	c_{11} & \dots & c_{1l} \\
	\vdots & \ddots & \vdots \\
	c_{k1} & \dots & c_{kl}
	\end{pmatrix} = \\ = \begin{pmatrix}
	q_{11}c_{11} + \dots + q_{1k}c_{k1} & \dots & q_{11}c_{1l} + \dots + q_{1k}c_{kl} \\
	\vdots & \ddots & \vdots \\
	q_{m1}c_{11} + \dots + q_{mk}c_{k1} & \dots & q_{m1}c_{1l} + \dots + q_{mk}c_{kl} \\
	\end{pmatrix} \boxed{\boxed{=}}$\\
	Візьмемо один з елементів матриці (для решти аналогічно):\\
	$q_{11}c_{11} + \dots + q_{1k}c_{k1} \overset{(*)}{=} \\ \overset{(*)}{=} (a_{11}b_{11} + \dots + a_{1n}b_{n1})c_{11} + \dots + (a_{11}b_{1k} + \dots + a_{1n}b_{nk})c_{k1} \boxed{=}$\\
	Розкриємо та винесемо по черзі за дужки $a_{11}, \dots, a_{1n}$\\
	$\boxed{=} a_{11}(b_{11}c_{11} + \dots + b_{1k}c_{k1}) + \dots + a_{1n}(b_{n1}c_{11} + \dots + b_{nk}c_{k1}) \overset{(**)}{=} \\ \overset{(**)}{=} a_{11}r_{11} + \dots + a_{1n}r_{n1}$\\
	Тоді продовжимо рівність:\\
	$\boxed{\boxed{=}} \begin{pmatrix}
	a_{11}r_{11} + \dots + a_{1n}r_{n1} & \dots & a_{11}r_{1l} + \dots + a_{1n}r_{nl} \\
	\vdots & \ddots & \vdots \\
	a_{m1}r_{11} + \dots + a_{mn}r_{n1} & \dots & a_{m1}r_{1l} + \dots + a_{mn}r_{nl} \\
	\end{pmatrix} = \\ = 
	\begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \dots & a_{mn} \\
	\end{pmatrix} \begin{pmatrix}
	r_{11} & \dots & r_{1l} \\
	\vdots & \ddots & \vdots \\
	r_{k1} & \dots & r_{nl}
	\end{pmatrix} = A \cdot R$\\
	Остаточно $(A \cdot B) \cdot C = A \cdot (B \cdot C)$
	\bigline
	2) \textit{Вказівка: перемножити $A$ на $I$, а потім навпаки}
	\bigline
	3), 4) \textit{Зрозуміло} \qed
	\bigline
	\defin{1.1.9. Транспонованою} називають наступну матрицю:\\
	$A = \begin{pmatrix}
	a_{11} & a_{12} & \dots & a_{1n} \\
	a_{21} & a_{22} & \dots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \dots & a_{mn} \\
	\end{pmatrix}$\\
	$A^T = \begin{pmatrix}
	a_{11} & a_{21} & \dots & a_{m1} \\
	a_{12} & a_{22} & \dots & a_{m2} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{1n} & a_{2n} & \dots & a_{mn} \\
	\end{pmatrix}$\\
	Тобто кожний рядок матриці перетворюється в стовпчик
	\bigline
	Для транспонування виконуються такі властивості:\\
	1) $(A^T)^T = A$\\
	2) $(A+B)^T = A^T + B^T$\\
	3) $(\lambda A)^T = \lambda A^T$\\
	4) $(A \cdot B)^T = B^T \cdot A^T$\\
	\proof
	1), 2), 3) \textit{Зрозуміло} \bigline
	4) $(A \cdot B)^T = \begin{pmatrix}
	a_{11}b_{11} + \dots + a_{1n}b_{n1} & \dots & a_{11}b_{1k} + \dots + a_{1n}b_{nk} \\
	\vdots & \ddots & \vdots \\
	a_{m1}b_{11} + \dots + a_{mn}b_{n1} & \dots & a_{m1}b_{1k} + \dots + a_{mn}b_{nk} \\
	\end{pmatrix}^T = \\
	= \begin{pmatrix}
	a_{11}b_{11} + \dots + a_{1n}b_{n1} & \dots & a_{m1}b_{11} + \dots + a_{mn}b_{n1}\\
	\vdots & \ddots & \vdots \\
	a_{11}b_{1k} + \dots + a_{1n}b_{nk} & \dots & a_{m1}b_{1k} + \dots + a_{mn}b_{nk} \\
	\end{pmatrix} = \\ = \begin{pmatrix}
	b_{11}a_{11} + \dots + b_{n1}a_{1n} & \dots & b_{11}a_{m1} + \dots + b_{n1}a_{mn}\\
	\vdots & \ddots & \vdots \\
	b_{1k}a_{11} + \dots + b_{nk}a_{1n} & \dots & b_{1k}a_{m1} + \dots + a_{mn}b_{nk} \\
	\end{pmatrix} = \\ = \begin{pmatrix}
	b_{11} & \dots & b_{1k} \\
	\vdots & \ddots & \vdots \\
	b_{n1} & \dots & b_{nk} \\
	\end{pmatrix} \begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{m1} & \dots & a_{mn} \\
	\end{pmatrix}
	= \begin{pmatrix}
	b_{11} & \dots & b_{n1} \\
	\vdots & \ddots & \vdots \\
	b_{1k} & \dots & b_{nk}
	\end{pmatrix}^T \begin{pmatrix}
	a_{11} & \dots & a_{m1} \\
	\vdots & \ddots & \vdots \\
	a_{1n} & \dots & a_{mn}
	\end{pmatrix}^T = B^T A^T$ \qed
	\bigline
	\defin{1.1.10. Головною діагоналлю} матриці $A$ розміру $m \times n$ називають всі елементи $a_{ii}$, тут $i = \overline{1,n}$ (якщо $n<m$)\\
	$A =$
	\begin{tikzpicture}[baseline=-0.5ex]
    \matrix[matrix of math nodes, left delimiter=(, right delimiter=)] (m) {
      a_{11} & a_{12} & \dots & a_{1n} \\
      a_{21} & a_{22} & \dots & a_{2n} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{n1} & a_{n2} & \dots & a_{nn} \\
      \vdots & \vdots & \ddots & \vdots \\
      a_{m1} & a_{m2} & \dots & a_{mn} \\
    };
   \draw (m-1-1.center) -- (m-4-4.center);
  \end{tikzpicture}
  \bigline
  \defin{1.1.11. Слідом} матриці $A$ назвемо величину
  \begin{align*}
  \tr A = a_{11} + a_{22} + \dots + a_{nn}
  \end{align*}
  Тобто сума всіх елементів головної діагоналі\\
  	\subsection{Трошки про визначники}
	\defin{1.2.1.(1)} Задана матриця $A = \begin{pmatrix} a_{11} \end{pmatrix}$\\
	\textbf{Визначником} матриці $1 \times 1$ називають число:
	\begin{align*}
	\det A = a_{11}
	\end{align*}
	\defin{1.2.1.(2)} Задана матриця $A = \begin{pmatrix}
	a_{11} & a_{12} \\
	a_{21} & a_{22}
	\end{pmatrix}$\\
	\textbf{Визначником} матриці $2 \times 2$ називають число:
	\begin{align*}
	\det A = a_{11}a_{22} - a_{21}a_{12}
	\end{align*}
	Цю формулу можна звести до інакшого вигляду, щоб надати ідею, як обчислювати визначники вищих порядків, але спочатку наведу означення\\
	\bigline
	\defin{1.2.2. Мінором} матриці $A$ називають визначник, в якому викреслені $i$-ий рядок та $j$-ий стовпчик:\\
	Позначення: $M_{ij}$\bigline
	\defin{1.2.3. Алгебраїчним доповненням} матриці $A$ називають число:\\
	Позначення: $A_{ij} = (-1)^{i+j} M_{ij}$\bigline
	У випадку $2 \times 2$ маємо наступне: \\
	$a_{22} = A_{11}$, $-a_{21} = A_{12}$. Тоді
	\begin{align*}
	\det A = a_{11}A_{11} + a_{12}A_{12}
	\end{align*}
	Це - розклад визначника через перший рядок матриці. Так само й для вищих порядків можна розписати\\
	\defin{1.2.1.(n)} Задана матриця $A = \begin{pmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{n1} & \dots & a_{nn}
	\end{pmatrix}$\\
	\textbf{Визначник} матриці $n \times n$ рахується ща розкладом в алгебраїчне доповнення через перший рядок
	\begin{align*}
	\det A = a_{11} A_{11} + \dots + a_{1n} A_{1n}
	\end{align*}
  %\begin{tikzpicture}
   % \matrix[
    %  matrix of math nodes,
     % left delimiter=(,
     % right delimiter=)
    %] (m) {
     % a_{11} & a_{12} \\
      %a_{21} & a_{22} \\
    %};
   % \draw (m-1-2.east) -- (m-1-1.center) -- (m-2-1.south);
  %\end{tikzpicture}
	Для визначників є ще таке позначення: $|A| = \begin{vmatrix}
	a_{11} & \dots & a_{1n} \\
	\vdots & \ddots & \vdots \\
	a_{n1} & \dots & a_{nn}
	\end{vmatrix}$
	\bigline
	\defin{1.2.4.} Якщо $\det A = 0$, то матриця $A$ називається \textbf{виродженою} \\ Інакше - \textbf{невироджена}
	\bigline
	Строге означення визначника $n \times n$ та звідки взялась формула розкладу, ми надамо вже в іншому PDF файлі. Так само властивості детермінантів будуть вже там
	\bigline

	\subsection{Обернена матриця}
	\defin{1.3.1.} Матриця $A^{-1}$ називається \textbf{оберненою}, якщо
	\begin{align*}
	A^{-1} A = A A^{-1} = I
	\end{align*}
	,якщо вона існує\\
	Водночас матрицю $A$ називають \textbf{оборотною}
	\bigline
	\rm{1.3.1.} Із означення випливає, що матриці $A$ та $A^{-1}$ мають бути квадратними 
	\bigline
	\ex{1.3.2.(1)} Для матриці $A = \begin{pmatrix}
	2 & 3 \\
	1 & 2
	\end{pmatrix}$ існує обернена матриця $A^{-1} = \begin{pmatrix}
	2 & -3 \\
	-1 & 2
	\end{pmatrix}$, оскільки за означенням,\\
	$AA^{-1} = \begin{pmatrix}
	2 & 3 \\
	1 & 2
	\end{pmatrix} \begin{pmatrix}
	2 & -3 \\
	-1 & 2
	\end{pmatrix} = \begin{pmatrix}
	1 & 0 \\
	0 & 1
	\end{pmatrix} = I$\\
	$A^{-1}A = \begin{pmatrix}
	2 & -3 \\
	-1 & 2
	\end{pmatrix} \begin{pmatrix}
	2 & 3 \\
	1 & 2f
	\end{pmatrix} = \begin{pmatrix}
	1 & 0 \\
	0 & 1
	\end{pmatrix} = I$
	\bigline
	\ex{1.3.2.(2)} А ось для матриці $A = \begin{pmatrix}
	1 & 2 \\
	1 & 2
	\end{pmatrix}$ не існує оберненої\\
	Припустимо, що така матриця $B = \begin{pmatrix}
	a & b \\
	c & d
	\end{pmatrix}$ існує, що є оберненою, тобто\\
	$AB = \begin{pmatrix}
	1 & 2 \\
	1 & 2
	\end{pmatrix} \begin{pmatrix}
	a & b \\
	c & d
	\end{pmatrix} = \begin{pmatrix}
	a + 2c & b + 2d \\
	a + 2c & b + 2d \\
	\end{pmatrix} = \begin{pmatrix}
	1 & 0 \\
	0 & 1
	\end{pmatrix}$\\
	Звідси маємо, що $1 = a + 2c = 0$ - суперечність!\\
	Такий підхід не завжди зручний для визначення неіснування оберненої матриці, проте для цієї мети існує критерій, доведення якої буде лише в наступному PDF
	\bigline
	\th{1.3.3.} Матриця $A$ - оборотна $\iff \det A \neq 0$
	\bigline
	Отже, в \textbf{Ex. 1.3.2.(2)} оскільки $\det A = 1 \cdot 2 - 1 \cdot 2 = 0$, то звідси оберненої матриці не існує
	\bigline
	\prp{1.3.4. Властивості}\\
	1) Існуюча обернена матриця є єдиною\\
	2) $I^{-1} = I$\\
	3) $(A^{-1})^{-1} = A$\\
	4) $(A^{-1})^k = (A^k)^{-1}$\\
	%5) $\det A^{-1} = \dfrac{1}{\det A}$\\
	5) $(A^T)^{-1} = (A^{-1})^T$\\
	6) $(A \cdot B)^{-1} = B^{-1} \cdot A^{-1}$\\
	наслідок) $(A_1 \dots A_n)^{-1} = A_n^{-1} \dots A_1^{-1}$\\
	7) $(\alpha A)^{-1} = \alpha^{-1} A^{-1}$\\
	%9) Якщо $A = \begin{pmatrix}
	%a_{11} & 0 & 0 \\
	%0 & a_{22} & 0 \\
	%0 & 0 & a_{33}
	%\end{pmatrix}$, то $A^{-1} = \begin{pmatrix}
	%\frac{1}{a_{11}} & 0 & 0 \\
	%0 & \frac{1}{a_{22}} & 0 \\
	%0 & 0 & \frac{1}{a_{33}}
	%\end{pmatrix}$\\
	\proof
	1) Припустимо, що $\exists A^{-1}_1, A^{-1}_2$ - дві обернені матриці\\
	Тоді $AA^{-1}_1 = A_1^{-1}A = I$\\
	Тоді $AA^{-1}_2 = A_2^{-1}A = I$\\
	Але отримаємо такий ланцюг:\\
	$A^{-1}_1 = A^{-1}_1 I = A^{-1}_1 (A A^{-1}_2) = (A^{-1}_1 A) A^{-1}_2 = I A_2^{-1} = A_2^{-1}$\\
	Суперечність!
	\bigline
	2) Нехай є одинична матриця $I$\\
	І нехай існує обернена матриця $T$. Тоді,\\
	$T = I \cdot T = T \cdot I = I$\\
	Тоді $T = I^{-1} = I$
	\bigline
	3) Нехай для $A$ існує $A^{-1}$, тобто $AA^{-1} = A^{-1}A = I$\\
	Перевіримо, що для матриці $A^{-1}$ існує обернена матриця $T = (A^{-1})^{-1}$, що:\\
	$A^{-1} T = T A^{-1} = I$\\
	І дійсно, вона існує, якщо $T = A$, тоді тотожність виконується за умовою
	\bigline
	4) Відомо, що $AA^{-1} = A^{-1}A = I$\\
	Перевіримо, що для $A^{k}$ матриця $(A^{k})^{-1} = (A^{-1})^k$ є оберненою. Справді\\
	$A^{k} (A^{k})^{-1} = A^{k} (A^{-1})^{k} = A^{k-1} A A^{-1} (A^{k-1})^{-1} = A^{k-1} (A^{k-1})^{-1} = A^{k-2} A A^{-1} (A^{k-2})^{-1} \\ = \dots = AA^{-1} = I$
	\bigline
	5) $A^{T} (A^{T})^{-1} = A^{T} (A^{-1})^T = (A^{-1} A)^{T} = I^T = I$
	\bigline
	6) $(AB) \cdot (AB)^{-1} = (AB) \cdot (B^{-1} A^{-1}) = A(B B^{-1})A^{-1} = I$
	\bigline
	7) $(\alpha A) \cdot (\alpha A)^{-1} = (\alpha A) \cdot (\alpha^{-1} A^{-1}) = I$ \qed
	\bigline
	
	\subsection{Елементарні матриці}
	\defin{1.4.1.} \textbf{Елементарною матрицею} назвемо матрицю $E$, якщо її можна отримати із одиничної матриці $I$ наступними шляхами:\\
	- зміною рядків місцями $E_{i \leftrightarrow j}$\\
	- множенню рядка на скаляр $E_{i \rightarrow \lambda i}$\\
	- додаванню одного рядка на друге, що помножене на число $E_{i \rightarrow i + \lambda j}$
	\bigline
	\ex{1.4.2.} У нас є матриця $I = \begin{pmatrix}
	1 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1
	\end{pmatrix}$. Наступні перелічені матриці будуть елементарними\\
	1. $E_{1 \leftrightarrow 2} = \begin{pmatrix}
	0 & 1 & 0 \\
	1 & 0 & 0 \\
	0 & 0 & 1 
	\end{pmatrix}$, ми змінили перший та другий рядки місяцми\\
	2. $E_{1 \rightarrow '3' \cdot 1} = \begin{pmatrix}
	3 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1
	\end{pmatrix}$, перший рядок помножили на скаляр $3$\\
	3. $E_{2 \rightarrow 2 + '2'\cdot 3} = \begin{pmatrix}
	1 & 0 & 0 \\
	0 & 1 & 2 \\
	0 & 0 & 1 \\
	\end{pmatrix}$, до другого рядка додали третій, що помножений на $2$
	\bigline
	\prp{1.4.3.} Задана матриця $A$. Тоді:\\
	$E_{i \leftrightarrow j}A$ - матриця, для якої рядки $i$ та $j$ змінились місцями\\
	$E_{i \rightarrow \lambda i}A$ - матриця, для якої $i$-ий рядок помножиться на скаляр $\lambda \neq 0$\\
	$E_{i \rightarrow i + \lambda j}A$ - матриця, для якої до $i$-ого рядка додасть рядок $j$, помножений на скаляр $\lambda$\\
	\proof
	Зафіксуємо елементарну матрицю $E_{i \rightarrow i \lambda} = \begin{pmatrix}
	1 & 0 & \dots & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & \lambda & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 1
\end{pmatrix}$\\
	Нехай $A = \begin{pmatrix}
	a_{11} & a_{12} & \dots & a_{1n} \\
	a_{21} & a_{22} & \dots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{i1} & a_{i2} & \dots & a_{in} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \dots & a_{mn}
	\end{pmatrix}$ \\
	Тоді $E_{i \rightarrow i\lambda} A \overset{\textrm{перемножуємо}}{=} \begin{pmatrix}
	a_{11} & a_{12} & \dots & a_{1n} \\
	a_{21} & a_{22} & \dots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	\lambda a_{i1} & \lambda a_{i2} & \dots & \lambda a_{in} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \dots & a_{mn}
	\end{pmatrix}$\\
	Решта випадків - аналогічно \qed
	\bigline
	\prp{1.4.4.} Матриці $E_{i \leftrightarrow j}$, $E_{i \rightarrow \lambda i}$,$E_{i \rightarrow i + \lambda j}$ є оборотними\\
	\proof
	Для перестановки $E_{i \leftrightarrow j} = \begin{pmatrix}
	1 & 0 & \dots & 0 & \dots & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 1 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 1 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 0 & \dots & 1 \\
	\end{pmatrix}$ \\ фіксуємо $E_{i \leftrightarrow j}^{-1} = E_{i \leftrightarrow j}$\\
	Для множення на скаляр $E_{i \rightarrow i \lambda} = \begin{pmatrix}
	1 & 0 & \dots & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & \lambda & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 1
\end{pmatrix}$ \\ фіксуємо $E_{i \rightarrow i \lambda}^{-1} = E_{i \rightarrow i \frac{1}{\lambda}} = \begin{pmatrix}
	1 & 0 & \dots & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & \dfrac{1}{\lambda} & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 1
\end{pmatrix} $\\
	Для додаванню $E_{i \rightarrow i+ \lambda j} = \begin{pmatrix}
	1 & 0 & \dots & 0 & \dots & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 1 & \dots & \lambda & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 1 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 0 & \dots & 1 \\
	\end{pmatrix}$\\
	фіксуємо $E_{i \rightarrow i+ \lambda j}^{-1} = E_{i \rightarrow i - \lambda j} = \begin{pmatrix}
	1 & 0 & \dots & 0 & \dots & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 & \dots & 0 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 1 & \dots & -\lambda & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 1 & \dots & 0 \\
	\vdots & \vdots &\ddots & \vdots & \ddots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 0 & \dots & 0 & \dots & 1 \\
	\end{pmatrix}$\\
	Якщо обережно їх перемножити для кожного випадку, то $E \cdot E^{-1} = E^{-1} \cdot E = I$ \qed
	\bigline
	Зокрема, в \textbf{Ex. 1.4.2.} маємо:\\
	$E_{1 \rightarrow 2}^{-1} = \begin{pmatrix}
	0 & 1 & 0 \\
	1 & 0 & 0 \\
	0 & 0 & 1
	\end{pmatrix}$, $E_{1 \rightarrow '3' \cdot 1}^{-1} = \begin{pmatrix}
	\dfrac{1}{3} & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1
	\end{pmatrix}$, $E_{2 \rightarrow '2'\cdot 3} = \begin{pmatrix}
	1 & 0 & 0 \\
	0 & 1 & -2 \\
	0 & 0 & 1
	\end{pmatrix}$
	\bigline
	\th{1.4.5.} Будь-яка оборотна матриця $A$ може бути представлена як добуток елементарних матриць\\
	\proof
	Ідея доведення полягає у використанні факту із \textbf{Prp. 1.4.3.}\\
	Нехай
	$A = \begin{pmatrix}
	a_{11} & a_{12} & \dots & a_{1n} \\
	a_{21} & a_{22} & \dots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \dots & a_{nn} \\
	\end{pmatrix}$ \\ Зведемо її до одиничної матриці, використовуючи перетворення\\
	Позначу $T = \left[ \begin{gathered} E_{i \leftrightarrow j} \\ E_{i \rightarrow \lambda i} \\ E_{i \rightarrow i + \lambda j} \end{gathered} \right.$ - тобто матриця, що є одним з перетворень. Тоді\\
	$T_n \dots T_2 T_1 A = \begin{pmatrix}
	a'_{11} & a'_{12} & \dots & a'_{1n} \\
	0 & a'_{22} & \dots & a'_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & a'_{nn} \\
	\end{pmatrix}$\\
	Отримана матриця шляхом елементарних перетворень називається \textbf{методом Гаусса}, коли під діагональними елементами залишаються нулі. Це ще називають "прямим ходом"\\
	$T_m' \dots T_2' T_1' \begin{pmatrix}
	a'_{11} & a'_{12} & \dots & a'_{1n} \\
	0 & a'_{22} & \dots & a'_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & a'_{nn} \\
	\end{pmatrix} = \begin{pmatrix}
	a''_{11} & 0 & \dots & 0 \\
	0 & a''_{22} & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & a''_{nn} \\
	\end{pmatrix}$\\
	А це вже називають "зворотнім ходом" \textrm{} метода Гаусса\\
	$T_k''\dots T_2'' T_1'' \begin{pmatrix}
	a''_{11} & 0 & \dots & 0 \\
	0 & a''_{22} & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & a''_{nn} \\
	\end{pmatrix} = \begin{pmatrix}
	1 & 0 & \dots & 0 \\
	0 & 1 & \dots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \dots & 1 \\
	\end{pmatrix} = I$\\
	Підсумовуючи, ми маємо:\\
	$I = T_k'' \dots T_2'' T_1'' \cdot T_m' \dots T_2' T_1' \cdot T_n \dots T_2 T_1 A$ $(*)$\\
	Залишилось знайти матрицю $A$\\
	$A = T_1^{-1} T_2^{-1} \dots T_n^{-1} \cdot T_1'^{-1} T_2'^{-1} \dots T_m'^{-1} T_1''^{-1} T_2''^{-1} \dots T_k''^{-1}$
	\qed
	\bigline
	Ба більше, за означенням оберненої матриці та з рівняння $(*)$, ми можемо отримати, що\\
	$A^{-1} = T_k'' \dots T_2'' T_1'' \cdot T_m' \dots T_2' T_1' \cdot T_n \dots T_2 T_1 \cdot \textcolor{red}{I}$\\
	Допоки ми матрицю $A$ зводили перетвореннями до матриці $I$, матриця $I$ водночас зводилась цими самими перетвореннями цією самою послідовністю до якоїсь іншої матриці, що й є $A^{-1}$\\
	\bigline
	\ex{1.4.6.} Нехай є матриця $A = \begin{pmatrix} 1 & 2 \\ 1 & 3 \end{pmatrix}$\\
	Розкладемо її на композицію елементарних:\\
	$E_1 A = \begin{pmatrix}1 & 0 \\ -1 & 1 \end{pmatrix} \begin{pmatrix}1 & 2 \\ 1 & 3 \end{pmatrix} = \begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix}$\\
	$E_2 (E_1 A) = \begin{pmatrix} 1 & -2 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix}
	1 & 0 \\
	0 & 1
	\end{pmatrix} = I$\\
	Таким чином, ми маємо:\\
	$E_2 E_1 A = I$\\
	$E_1 = \begin{pmatrix}
	1 & 0 \\
	-1 & 1
	\end{pmatrix} \Rightarrow E_1^{-1} = \begin{pmatrix}
	1 & 0 \\
	1 & 1
\end{pmatrix}	 \\ E_2 = \begin{pmatrix}
	1 & -2 \\
	0 & 1
	\end{pmatrix} \Rightarrow E_2^{-1} = \begin{pmatrix}
	1 & 2 \\
	0 & 1
	\end{pmatrix}$\\
	Тоді $A = E_1^{-1} E_2^{-1} = \begin{pmatrix}
	1 & 0 \\
	1 & 1
	\end{pmatrix} \begin{pmatrix}
	1 & 2\\
	0 & 1
	\end{pmatrix}$
	\bigline
	Знайдемо також обернену матрицю $A^{-1}$\\
	$A^{-1} = E_2 E_1 I = \begin{pmatrix}
	1 & -2 \\
	0 & 1
	\end{pmatrix} \begin{pmatrix}
	1 & 0 \\
	-1 & 1
	\end{pmatrix} \begin{pmatrix}
	1 & 0 \\
	0 & 1
\end{pmatrix}	 = \begin{pmatrix}
	3 & -2 \\
	-1 & 1
	\end{pmatrix}$\\
	Ще раз спробуємо побачити, якими шляхами ми знайшли $A^{-1}$\\
	Ми $A$ зводили перетвореннями до $I$, а $I$ - до якоїсь матриці, що й є $A^{-1}$\\
	Не обов'язково намагатись розписувати матрицю $A$ як декомпозицію елементарних матриць\\
	Запишемо ось таку матрицю $(A | I)$ - \textbf{розширену матрицю}\\
	$\begin{pmatrix}
	1 & 2 & \vline & 1 & 0 \\
	1 & 3 & \vline & 0 & 1
	\end{pmatrix}$\\
	І тепер замість того, щоб ми писали елементрані матриці, ми будемо просто почергово вказувати, яке перетворення було зроблено, та оновлювати таким чином вигляд обох матриць. Зокрема\\
	$\begin{pmatrix}
	1 & 2 & \vline & 1 & 0 \\
	1 & 3 & \vline & 0 & 1
	\end{pmatrix} \overset{l_2 \rightarrow l_2 + (-1)l_1}{\rightarrow} \begin{pmatrix}
	1 & -2 & \vline & 1 & 0 \\
	0 & 1 & \vline & -1 & 1
	\end{pmatrix} \overset{l_1 \rightarrow l_1 + (-2)l_2}{\rightarrow} \begin{pmatrix}
	1 & 0 & \vline & 3 & -2 \\
	0 & 1 & \vline & -1 & 1
	\end{pmatrix}$\\
	Отримали розширену матрицю $(I | A^{-1})$
	\bigline
\end{document}